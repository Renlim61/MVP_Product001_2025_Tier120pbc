{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renlim61/MVP_Product001_2025_Tier120pbc/blob/version-history/Phase1_RAG_MVP_v14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omsjzn0uin23"
      },
      "source": [
        "<details>\n",
        "<summary><strong>ðŸ“˜ RAG MVP â€“ Version 13 Overview (Click to Expand)</strong></summary>\n",
        "\n",
        "### ðŸ”‘ Key Enhancements in v13\n",
        "\n",
        "#### **1. Persistent Chat History (7-Day Retention)**\n",
        "All user interactions are stored in SQLite with timestamps, user IDs, roles, original/improved queries, selected prompt type, RAG answer, and chat model.  \n",
        "Automatic pruning removes entries older than 7 days to prevent growth.\n",
        "\n",
        "#### **2. ICAM-Ready User & Role Scaffolding**\n",
        "Users can now specify a **User ID** and **Role** (user/admin).  \n",
        "This information is persisted, forming the basis for future role-based access control, audit logging, and permission policies.\n",
        "\n",
        "#### **3. Robust Cohort-Based Document Ingestion**\n",
        "- Reliable `filepath` uploads  \n",
        "- PDF, DOCX, TXT support  \n",
        "- Chunking, embedding, and FAISS indexing per document  \n",
        "- Metadata and SQLite document tracking\n",
        "\n",
        "Each document is independently searchable while belonging to a cohort.\n",
        "\n",
        "#### **4. Key & Model Validation**\n",
        "A dedicated button validates:\n",
        "- API key correctness  \n",
        "- Chat model availability  \n",
        "- Embedding model availability  \n",
        "\n",
        "Prevents misconfiguration before indexing or retrieval.\n",
        "\n",
        "#### **5. Prompt Coach (Query Improvement)**\n",
        "Automatically rewrites user queries to improve RAG retrieval quality.  \n",
        "Users may choose **Original** or **Improved** versions before running RAG.\n",
        "\n",
        "#### **6. Expanded Admin Dashboard**\n",
        "Provides visibility into:\n",
        "- Total docs  \n",
        "- Total cohorts  \n",
        "- Known users  \n",
        "- Recent chat record count  \n",
        "- User profiles and cohort inventory  \n",
        "\n",
        "#### **7. Enhanced Chat History Viewer**\n",
        "Filter by:\n",
        "- User ID  \n",
        "- Cohort  \n",
        "- Max records  \n",
        "\n",
        "Displays complete history with timestamps, queries, answers, and roles.\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸŽ¯ Summary\n",
        "v13 elevates the MVP into a **persistent**, **auditable**, **multi-user**, and **cohort-aware** RAG system.  \n",
        "It establishes the technical foundation for future ICAM controls, analytics, multi-model routing, and scalable enterprise features.\n",
        "\n",
        "</details>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaaip4QfN5NT"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 0 / STEP 0 â€“ Install & Imports\n",
        "# ============================================================\n",
        "# Run this once at the top of the notebook (Colab style).\n",
        "\n",
        "%pip install -q faiss-cpu openai gradio PyPDF2 python-docx\n",
        "\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import pickle\n",
        "import sqlite3\n",
        "from uuid import uuid4\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "import gradio as gr\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document as DocxDocument\n",
        "\n",
        "# Colab detection\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive as colab_drive\n",
        "\n",
        "# OpenAI client (v1 library)\n",
        "from openai import OpenAI\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-tWoyzqO_lD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# CELL 1 / STEP 1 â€“ Paths, Defaults, and OpenAI Client\n",
        "# ============================================================\n",
        "\n",
        "# Base directory for everything (indexes, DB, etc.)\n",
        "BASE_DIR = \"/content/rag_mvp\" if IN_COLAB else os.path.join(os.getcwd(), \"rag_mvp\")\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "# SQLite DB path (for saved documents, cohorts, users, chat history)\n",
        "DB_PATH = os.path.join(BASE_DIR, \"rag_documents.db\")\n",
        "\n",
        "# Directory to store FAISS indexes and metadata\n",
        "INDEX_DIR = os.path.join(BASE_DIR, \"indexes\")\n",
        "os.makedirs(INDEX_DIR, exist_ok=True)\n",
        "\n",
        "# Chunking parameters\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 200\n",
        "\n",
        "# Defaults â€“ you can change these if you like\n",
        "EMBED_MODEL_DEFAULT = \"text-embedding-3-small\"\n",
        "CHAT_MODEL_DEFAULT = \"gpt-4.1-mini\"\n",
        "\n",
        "def build_openai_client(api_key: str) -> OpenAI:\n",
        "    \"\"\"\n",
        "    Build a new OpenAI client from an API key.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI API key is required.\")\n",
        "    return OpenAI(api_key=api_key)\n",
        "\n",
        "def resolve_models(chat_model: str, embed_model: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Resolve user selections or fall back to sensible defaults.\n",
        "    \"\"\"\n",
        "    resolved_chat = chat_model.strip() or CHAT_MODEL_DEFAULT\n",
        "    resolved_embed = embed_model.strip() or EMBED_MODEL_DEFAULT\n",
        "    return resolved_chat, resolved_embed\n",
        "\n",
        "def ensure_base_dirs():\n",
        "    os.makedirs(BASE_DIR, exist_ok=True)\n",
        "    os.makedirs(INDEX_DIR, exist_ok=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsvVjv09O_9t"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ============================================================\n",
        "# CELL 1.5 / STEP 1.5 â€“ Validate OpenAI Key & Models\n",
        "# ============================================================\n",
        "\n",
        "def validate_openai_key_and_models(api_key: str, chat_model: str, embed_model: str) -> str:\n",
        "    \"\"\"\n",
        "    Lightweight validation:\n",
        "    - Instantiate client\n",
        "    - Do a tiny chat completion\n",
        "    - Do a small embedding call\n",
        "    Returns a human-readable status string.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"âŒ Please provide an OpenAI API key.\"\n",
        "\n",
        "    try:\n",
        "        client = build_openai_client(api_key)\n",
        "        resolved_chat, resolved_embed = resolve_models(chat_model, embed_model)\n",
        "\n",
        "        # Tiny chat test\n",
        "        _ = client.chat.completions.create(\n",
        "            model=resolved_chat,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Model availability test.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Respond with 'OK' only.\"},\n",
        "            ],\n",
        "            max_tokens=2,\n",
        "            temperature=0.0,\n",
        "        )\n",
        "\n",
        "        # Tiny embedding test\n",
        "        _ = client.embeddings.create(\n",
        "            model=resolved_embed,\n",
        "            input=[\"test\"],\n",
        "        )\n",
        "\n",
        "        return f\"âœ… OpenAI key valid. Chat model: `{resolved_chat}`, Embed model: `{resolved_embed}`\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error validating key/models: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q8Z3pBHPAJJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# CELL 2 / STEP 2 â€“ Document Loading & Chunking\n",
        "# ============================================================\n",
        "\n",
        "def load_pdf(file_bytes: bytes) -> str:\n",
        "    reader = PdfReader(io.BytesIO(file_bytes))\n",
        "    texts = []\n",
        "    for page in reader.pages:\n",
        "        try:\n",
        "            txt = page.extract_text() or \"\"\n",
        "        except Exception:\n",
        "            txt = \"\"\n",
        "        texts.append(txt)\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "def load_docx(file_bytes: bytes) -> str:\n",
        "    f = io.BytesIO(file_bytes)\n",
        "    doc = DocxDocument(f)\n",
        "    return \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "\n",
        "def load_txt(file_bytes: bytes, encoding: str = \"utf-8\") -> str:\n",
        "    return file_bytes.decode(encoding, errors=\"ignore\")\n",
        "\n",
        "def load_file_to_text(file_obj) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Accepts either:\n",
        "    - a string filepath (when gr.File(type=\"filepath\") is used), or\n",
        "    - a file-like object with a .name attribute (older behavior).\n",
        "\n",
        "    Returns:\n",
        "      (text_content, original_filename)\n",
        "    \"\"\"\n",
        "    # Case 1: gr.File(type=\"filepath\") -> we get a string path\n",
        "    if isinstance(file_obj, str):\n",
        "        path = file_obj\n",
        "        name = os.path.basename(path)\n",
        "    else:\n",
        "        # Case 2: some object with a .name attribute\n",
        "        path = getattr(file_obj, \"name\", None)\n",
        "        if path is None:\n",
        "            raise ValueError(\"Unsupported file object from uploader.\")\n",
        "        name = os.path.basename(path)\n",
        "\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    lower = name.lower()\n",
        "    if lower.endswith(\".pdf\"):\n",
        "        text = load_pdf(data)\n",
        "    elif lower.endswith(\".docx\"):\n",
        "        text = load_docx(data)\n",
        "    elif lower.endswith(\".txt\"):\n",
        "        text = load_txt(data)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type for {name}\")\n",
        "\n",
        "    return text, name\n",
        "\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
        "    \"\"\"\n",
        "    Simple sliding-window chunking.\n",
        "    \"\"\"\n",
        "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    tokens = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(tokens):\n",
        "        end = start + chunk_size\n",
        "        chunk_tokens = tokens[start:end]\n",
        "        chunk = \" \".join(chunk_tokens)\n",
        "        chunks.append(chunk)\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FszVBfEjPAUv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ============================================================\n",
        "# CELL 3 / STEP 3 â€“ Embedding & FAISS Index Helpers\n",
        "# ============================================================\n",
        "\n",
        "def embed_texts(\n",
        "    api_key: str,\n",
        "    embed_model: str,\n",
        "    texts: List[str],\n",
        "    batch_size: int = 32,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Embed a list of texts using OpenAI embeddings.\n",
        "    Returns an ndarray of shape (N, D).\n",
        "    \"\"\"\n",
        "    client = build_openai_client(api_key)\n",
        "    resolved_chat, resolved_embed = resolve_models(\"\", embed_model)\n",
        "\n",
        "    vectors: List[List[float]] = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        resp = client.embeddings.create(model=resolved_embed, input=batch)\n",
        "        for d in resp.data:\n",
        "            vectors.append(d.embedding)\n",
        "\n",
        "    arr = np.array(vectors, dtype=\"float32\")\n",
        "    return arr\n",
        "\n",
        "def build_faiss_index(vectors: np.ndarray) -> faiss.IndexFlatIP:\n",
        "    \"\"\"\n",
        "    Build a simple inner-product FAISS index from vectors.\n",
        "    \"\"\"\n",
        "    norm = np.linalg.norm(vectors, axis=1, keepdims=True) + 1e-10\n",
        "    normed = vectors / norm\n",
        "    dim = normed.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(normed)\n",
        "    return index\n",
        "\n",
        "def save_index(index: faiss.IndexFlatIP, index_id: str):\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.faiss\")\n",
        "    faiss.write_index(index, path)\n",
        "\n",
        "def load_index(index_id: str) -> faiss.IndexFlatIP:\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.faiss\")\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Index file not found: {path}\")\n",
        "    return faiss.read_index(path)\n",
        "\n",
        "def save_metadata(index_id: str, meta: Dict[str, Any]):\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.pkl\")\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(meta, f)\n",
        "\n",
        "def load_metadata(index_id: str) -> Dict[str, Any]:\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.pkl\")\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Metadata file not found: {path}\")\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiuRrDTnPAfr"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4 / STEP 4 â€“ SQLite Persistence for Documents & Cohorts\n",
        "# ============================================================\n",
        "\n",
        "def get_db_conn():\n",
        "    ensure_base_dirs()\n",
        "    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)\n",
        "    return sqlite3.connect(DB_PATH)\n",
        "\n",
        "def ensure_docs_table():\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS documents (\n",
        "            id              TEXT PRIMARY KEY,\n",
        "            doc_name        TEXT NOT NULL,\n",
        "            cohort_name     TEXT NOT NULL,\n",
        "            index_id        TEXT NOT NULL,\n",
        "            n_chunks        INTEGER NOT NULL,\n",
        "            embed_model     TEXT NOT NULL,\n",
        "            created_at      TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def ensure_cohort_table():\n",
        "    \"\"\"\n",
        "    Mapping of cohort_name -> doc_name (for easier listing).\n",
        "    \"\"\"\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohort_docs (\n",
        "            cohort_name TEXT NOT NULL,\n",
        "            doc_name    TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def list_cohorts() -> List[str]:\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"SELECT DISTINCT cohort_name FROM cohort_docs ORDER BY cohort_name ASC\")\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return [r[0] for r in rows]\n",
        "\n",
        "def list_docs_in_cohort(cohort_name: str) -> List[str]:\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT doc_name FROM cohort_docs WHERE cohort_name = ? ORDER BY doc_name ASC\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return [r[0] for r in rows]\n",
        "\n",
        "def add_docs_to_cohort(cohort_name: str, doc_names: List[str]):\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    for dn in doc_names:\n",
        "        cur.execute(\n",
        "            \"INSERT INTO cohort_docs (cohort_name, doc_name) VALUES (?, ?)\",\n",
        "            (cohort_name, dn),\n",
        "        )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def rename_cohort(old_name: str, new_name: str):\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"UPDATE cohort_docs SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "        (new_name, old_name),\n",
        "    )\n",
        "    cur.execute(\n",
        "        \"UPDATE documents SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "        (new_name, old_name),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def delete_cohort(cohort_name: str, reassign_to: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Delete a cohort. If reassign_to is provided, documents move there.\n",
        "    Otherwise, documents are deleted (and their indexes removed).\n",
        "    NOTE: This is intentionally explicit to avoid orphaned docs.\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\n",
        "        \"SELECT id, index_id FROM documents WHERE cohort_name = ?\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    docs = cur.fetchall()\n",
        "\n",
        "    if reassign_to:\n",
        "        # Just move docs\n",
        "        cur.execute(\n",
        "            \"UPDATE documents SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "            (reassign_to, cohort_name),\n",
        "        )\n",
        "        cur.execute(\n",
        "            \"UPDATE cohort_docs SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "            (reassign_to, cohort_name),\n",
        "        )\n",
        "        msg = f\"âœ… Cohort '{cohort_name}' renamed/reassigned to '{reassign_to}'. No indexes deleted.\"\n",
        "    else:\n",
        "        # Delete docs and indexes\n",
        "        for doc_id, index_id in docs:\n",
        "            # Remove index & metadata\n",
        "            faiss_path = os.path.join(INDEX_DIR, f\"{index_id}.faiss\")\n",
        "            pkl_path = os.path.join(INDEX_DIR, f\"{index_id}.pkl\")\n",
        "            for p in [faiss_path, pkl_path]:\n",
        "                if os.path.exists(p):\n",
        "                    os.remove(p)\n",
        "            cur.execute(\"DELETE FROM documents WHERE id = ?\", (doc_id,))\n",
        "\n",
        "        cur.execute(\"DELETE FROM cohort_docs WHERE cohort_name = ?\", (cohort_name,))\n",
        "        msg = f\"âœ… Cohort '{cohort_name}' and its documents/indexes were deleted.\"\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return msg\n",
        "\n",
        "def register_document(\n",
        "    doc_name: str,\n",
        "    cohort_name: str,\n",
        "    index_id: str,\n",
        "    n_chunks: int,\n",
        "    embed_model: str,\n",
        "):\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    doc_id = str(uuid4())\n",
        "    created_at = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO documents (id, doc_name, cohort_name, index_id, n_chunks,\n",
        "                               embed_model, created_at)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (doc_id, doc_name, cohort_name, index_id, n_chunks, embed_model, created_at),\n",
        "    )\n",
        "    cur.execute(\n",
        "        \"INSERT INTO cohort_docs (cohort_name, doc_name) VALUES (?, ?)\",\n",
        "        (cohort_name, doc_name),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return doc_id\n",
        "\n",
        "def get_doc_index_id(doc_name: str, cohort_name: str) -> Optional[str]:\n",
        "    ensure_docs_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT index_id\n",
        "        FROM documents\n",
        "        WHERE doc_name = ? AND cohort_name = ?\n",
        "        \"\"\",\n",
        "        (doc_name, cohort_name),\n",
        "    )\n",
        "    row = cur.fetchone()\n",
        "    conn.close()\n",
        "    if row:\n",
        "        return row[0]\n",
        "    return None\n",
        "\n",
        "def list_all_documents() -> List[Tuple[str, str, str]]:\n",
        "    \"\"\"\n",
        "    Return list of (doc_name, cohort_name, created_at).\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT doc_name, cohort_name, created_at FROM documents ORDER BY created_at DESC\"\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Gtm6-nPAqT"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4.5 / STEP 4.5 â€“ Users & Chat History (7-Day Retention)\n",
        "# ============================================================\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "\n",
        "# ============================================================\n",
        "# USER IDENTITY MODEL (used by audit, cohorts, admin, etc.)\n",
        "# ============================================================\n",
        "class SessionUser:\n",
        "    username: str | None = None\n",
        "    role: str = \"anonymous\"   # \"anonymous\", \"user\", \"admin\"\n",
        "\n",
        "    def __init__(self, username=None, role=\"anonymous\"):\n",
        "        self.username = username\n",
        "        self.role = role\n",
        "\n",
        "    @property\n",
        "    def is_authenticated(self) -> bool:\n",
        "        return self.username is not None\n",
        "\n",
        "    @property\n",
        "    def is_admin(self) -> bool:\n",
        "        return self.role == \"admin\"\n",
        "\n",
        "\n",
        "# Simple in-memory user store for MVP (replace with ICAM/SSO later)\n",
        "USERS = {\n",
        "    \"admin\": {\"password\": \"admin123\", \"role\": \"admin\"},\n",
        "    \"demo\":  {\"password\": \"demo123\",  \"role\": \"user\"},\n",
        "}\n",
        "\n",
        "\n",
        "def ensure_user_table():\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS users (\n",
        "            user_id     TEXT PRIMARY KEY,\n",
        "            display_name TEXT,\n",
        "            role        TEXT,\n",
        "            created_at  TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def ensure_chat_history_table():\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_id         TEXT,\n",
        "            role            TEXT,\n",
        "            cohort_name     TEXT,\n",
        "            original_query  TEXT,\n",
        "            improved_query  TEXT,\n",
        "            which_prompt    TEXT,\n",
        "            answer          TEXT,\n",
        "            chat_model      TEXT,\n",
        "            created_at      TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def upsert_user(user_id: str, role: str, display_name: Optional[str] = None):\n",
        "    \"\"\"\n",
        "    Basic user scaffolding for future ICAM:\n",
        "    - Inserts new user or updates role/display_name.\n",
        "    \"\"\"\n",
        "    if not user_id:\n",
        "        return\n",
        "    ensure_user_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    now = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO users (user_id, display_name, role, created_at)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "        ON CONFLICT(user_id) DO UPDATE SET\n",
        "            display_name = COALESCE(?, users.display_name),\n",
        "            role = COALESCE(?, users.role)\n",
        "        \"\"\",\n",
        "        (user_id, display_name, role, now, display_name, role),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def prune_chat_history(days: int = 7):\n",
        "    \"\"\"\n",
        "    Delete chat entries older than `days` days.\n",
        "    \"\"\"\n",
        "    ensure_chat_history_table()\n",
        "    cutoff = datetime.now(timezone.utc) - timedelta(days=days)\n",
        "    cutoff_iso = cutoff.isoformat()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"DELETE FROM chat_history WHERE created_at < ?\",\n",
        "        (cutoff_iso,),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def save_chat_interaction(\n",
        "    user_id: str,\n",
        "    role: str,\n",
        "    cohort_name: str,\n",
        "    original_query: str,\n",
        "    improved_query: str,\n",
        "    which_prompt: str,\n",
        "    answer: str,\n",
        "    chat_model: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    Save a single Q&A to chat_history and enforce 7-day retention.\n",
        "    \"\"\"\n",
        "    ensure_chat_history_table()\n",
        "    prune_chat_history(days=7)\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    now = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO chat_history (\n",
        "            user_id, role, cohort_name, original_query, improved_query,\n",
        "            which_prompt, answer, chat_model, created_at\n",
        "        )\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (\n",
        "            user_id or None,\n",
        "            role or None,\n",
        "            cohort_name or None,\n",
        "            original_query,\n",
        "            improved_query,\n",
        "            which_prompt,\n",
        "            answer,\n",
        "            chat_model,\n",
        "            now,\n",
        "        ),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def get_recent_history(\n",
        "    user_id: Optional[str] = None,\n",
        "    cohort_name: Optional[str] = None,\n",
        "    limit: int = 50,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Return recent chat history, optionally filtered by user_id / cohort_name.\n",
        "    \"\"\"\n",
        "    ensure_chat_history_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    query = \"SELECT user_id, role, cohort_name, original_query, improved_query, which_prompt, answer, chat_model, created_at FROM chat_history\"\n",
        "    params: List[Any] = []\n",
        "    conditions: List[str] = []\n",
        "\n",
        "    if user_id:\n",
        "        conditions.append(\"user_id = ?\")\n",
        "        params.append(user_id)\n",
        "    if cohort_name:\n",
        "        conditions.append(\"cohort_name = ?\")\n",
        "        params.append(cohort_name)\n",
        "\n",
        "    if conditions:\n",
        "        query += \" WHERE \" + \" AND \".join(conditions)\n",
        "    query += \" ORDER BY created_at DESC LIMIT ?\"\n",
        "    params.append(limit)\n",
        "\n",
        "    cur.execute(query, tuple(params))\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    history = []\n",
        "    for r in rows:\n",
        "        history.append(\n",
        "            {\n",
        "                \"user_id\": r[0],\n",
        "                \"role\": r[1],\n",
        "                \"cohort_name\": r[2],\n",
        "                \"original_query\": r[3],\n",
        "                \"improved_query\": r[4],\n",
        "                \"which_prompt\": r[5],\n",
        "                \"answer\": r[6],\n",
        "                \"chat_model\": r[7],\n",
        "                \"created_at\": r[8],\n",
        "            }\n",
        "        )\n",
        "    return history\n",
        "\n",
        "def list_users() -> List[Tuple[str, str, str]]:\n",
        "    \"\"\"\n",
        "    Simple user listing for admin view.\n",
        "    Returns list of (user_id, display_name, role).\n",
        "    \"\"\"\n",
        "    ensure_user_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT user_id, display_name, role FROM users ORDER BY created_at DESC\"\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbFVh06ns0to"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4.6 / STEP 4.6 â€“ Audit Log (v14)\n",
        "# ============================================================\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "def ensure_audit_table():\n",
        "    \"\"\"\n",
        "    Create an audit_log table if it doesn't already exist.\n",
        "    \"\"\"\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS audit_log (\n",
        "            id        INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            ts        TEXT NOT NULL,\n",
        "            username  TEXT,\n",
        "            role      TEXT,\n",
        "            action    TEXT NOT NULL,\n",
        "            details   TEXT\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def log_audit(username: str, role: str, action: str, details: str = \"\"):\n",
        "    \"\"\"\n",
        "    Insert a row into the audit_log table.\n",
        "    - ts: UTC ISO timestamp\n",
        "    - username / role: may be None/empty for anonymous\n",
        "    - action: short code, e.g. 'login', 'ask', 'admin_refresh', 'delete_cohort'\n",
        "    - details: freeform string with context\n",
        "    \"\"\"\n",
        "    ensure_audit_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Use timezone-aware UTC\n",
        "    now = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO audit_log (ts, username, role, action, details)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (now, username or \"\", role or \"\", action, details or \"\"),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URBUhBXz2PIF"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4.7 / STEP 4.7 â€“ Cohort Ownership & Sharing (v14)\n",
        "# ============================================================\n",
        "\n",
        "def ensure_cohort_meta_table():\n",
        "    \"\"\"\n",
        "    Metadata for cohorts:\n",
        "      - owner_user_id: who created/owns the cohort\n",
        "      - is_shared: 0 = private to owner, 1 = shared to all users\n",
        "      - created_ts: UTC timestamp\n",
        "    \"\"\"\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohort_meta (\n",
        "            cohort_name    TEXT PRIMARY KEY,\n",
        "            owner_user_id  TEXT,\n",
        "            is_shared      INTEGER DEFAULT 0,\n",
        "            created_ts     TEXT\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def set_cohort_owner(cohort_name: str, user: SessionUser | None):\n",
        "    \"\"\"\n",
        "    Register or update the owner of a cohort.\n",
        "    For now:\n",
        "      - owner_user_id = user.username (or 'anonymous' if not logged in)\n",
        "      - is_shared = 0 by default (private)\n",
        "    Later we can extend this to support an 'allow share' flag.\n",
        "    \"\"\"\n",
        "    if not cohort_name:\n",
        "        return\n",
        "\n",
        "    ensure_cohort_meta_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    owner = \"anonymous\"\n",
        "    if user and user.username:\n",
        "        owner = user.username\n",
        "\n",
        "    # If a row already exists, we keep the existing is_shared but update owner if needed.\n",
        "    now = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO cohort_meta (cohort_name, owner_user_id, is_shared, created_ts)\n",
        "        VALUES (?, ?, 0, ?)\n",
        "        ON CONFLICT(cohort_name) DO UPDATE SET\n",
        "            owner_user_id = excluded.owner_user_id\n",
        "        \"\"\",\n",
        "        (cohort_name, owner, now),\n",
        "    )\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def cohort_exists(cohort_name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True if a cohort with this name already exists in cohort_docs.\n",
        "    This is global (not per-user) to avoid confusing duplicate names.\n",
        "    \"\"\"\n",
        "    if not cohort_name:\n",
        "        return False\n",
        "\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT 1 FROM cohort_docs WHERE cohort_name = ? LIMIT 1\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    row = cur.fetchone()\n",
        "    conn.close()\n",
        "    return row is not None\n",
        "\n",
        "\n",
        "def list_cohorts_for_user(user: SessionUser | None) -> list[str]:\n",
        "    \"\"\"\n",
        "    Return list of cohort names visible to the given user.\n",
        "\n",
        "    Rules (v14):\n",
        "      - Admins: all cohorts (global)\n",
        "      - Non-admin:\n",
        "          * Cohorts where they are owner (cohort_meta.owner_user_id)\n",
        "          * Cohorts marked is_shared = 1 (future 'allow share' flag)\n",
        "      - Anonymous: only shared cohorts (is_shared = 1)\n",
        "\n",
        "    If anything goes wrong with the metadata logic, fall back to global list_cohorts().\n",
        "    \"\"\"\n",
        "    ensure_cohort_table()\n",
        "    ensure_cohort_meta_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        if user and getattr(user, \"is_admin\", False):\n",
        "            # Admin: all distinct cohorts\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                SELECT DISTINCT cohort_name\n",
        "                FROM cohort_docs\n",
        "                ORDER BY cohort_name\n",
        "                \"\"\"\n",
        "            )\n",
        "            rows = cur.fetchall()\n",
        "            conn.close()\n",
        "            return [r[0] for r in rows]\n",
        "\n",
        "        username = user.username if (user and user.username) else None\n",
        "\n",
        "        if username:\n",
        "            # Non-admin logged-in\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                SELECT DISTINCT cd.cohort_name\n",
        "                FROM cohort_docs cd\n",
        "                LEFT JOIN cohort_meta cm\n",
        "                  ON cd.cohort_name = cm.cohort_name\n",
        "                WHERE cm.owner_user_id = ?\n",
        "                   OR cm.is_shared = 1\n",
        "                   OR cm.cohort_name IS NULL   -- safety: cohorts without meta still appear\n",
        "                ORDER BY cd.cohort_name\n",
        "                \"\"\",\n",
        "                (username,),\n",
        "            )\n",
        "        else:\n",
        "            # Anonymous: only explicitly shared cohorts (or cohorts without meta as fallback)\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                SELECT DISTINCT cd.cohort_name\n",
        "                FROM cohort_docs cd\n",
        "                LEFT JOIN cohort_meta cm\n",
        "                  ON cd.cohort_name = cm.cohort_name\n",
        "                WHERE cm.is_shared = 1\n",
        "                   OR cm.cohort_name IS NULL\n",
        "                ORDER BY cd.cohort_name\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "        rows = cur.fetchall()\n",
        "        conn.close()\n",
        "        names = [r[0] for r in rows]\n",
        "\n",
        "        # Final safety net: if nothing, fall back to global.\n",
        "        if not names:\n",
        "            return list_cohorts()\n",
        "        return names\n",
        "\n",
        "    except Exception as e:\n",
        "        conn.close()\n",
        "        print(\"DEBUG list_cohorts_for_user error:\", e)\n",
        "        return list_cohorts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "376haZz9PA0Z"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 5 / STEP 5 â€“ RAG Retrieval Over a Cohort\n",
        "# ============================================================\n",
        "\n",
        "def build_context_from_index(\n",
        "    api_key: str,\n",
        "    chat_model: str,\n",
        "    embed_model: str,\n",
        "    cohort_name: str,\n",
        "    query: str,\n",
        "    top_k: int = 5,\n",
        ") -> Tuple[str, List[Tuple[str, int, float]]]:\n",
        "    \"\"\"\n",
        "    Given a cohort and query:\n",
        "    - Load all documents for that cohort\n",
        "    - For each doc's index, perform similarity\n",
        "    - Aggregate top_k results across docs\n",
        "    Returns:\n",
        "      - concatenated context string\n",
        "      - list of (doc_name, rank, score) for citations\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    resolved_chat, resolved_embed = resolve_models(chat_model, embed_model)\n",
        "    client = build_openai_client(api_key)\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT doc_name, index_id\n",
        "        FROM documents\n",
        "        WHERE cohort_name = ?\n",
        "        \"\"\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    if not rows:\n",
        "        return \"\", []\n",
        "\n",
        "    # Embed query once\n",
        "    q_embed_resp = client.embeddings.create(model=resolved_embed, input=[query])\n",
        "    q_vec = np.array(q_embed_resp.data[0].embedding, dtype=\"float32\")\n",
        "    q_vec = q_vec / (np.linalg.norm(q_vec) + 1e-10)\n",
        "\n",
        "    all_hits: List[Tuple[str, int, float, str]] = []  # (doc_name, idx, score, text)\n",
        "\n",
        "    for doc_name, index_id in rows:\n",
        "        try:\n",
        "            index = load_index(index_id)\n",
        "            meta = load_metadata(index_id)  # {\"chunks\": [...], \"doc_name\": ..., ...}\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        D, I = index.search(q_vec[np.newaxis, :], top_k)\n",
        "        scores = D[0]\n",
        "        idxs = I[0]\n",
        "\n",
        "        for rank, (score, idx) in enumerate(zip(scores, idxs), start=1):\n",
        "            if idx < 0:\n",
        "                continue\n",
        "            chunks = meta.get(\"chunks\", [])\n",
        "            if idx >= len(chunks):\n",
        "                continue\n",
        "            text_chunk = chunks[idx]\n",
        "            all_hits.append((doc_name, idx, float(score), text_chunk))\n",
        "\n",
        "    if not all_hits:\n",
        "        return \"\", []\n",
        "\n",
        "    # Sort across docs by score desc\n",
        "    all_hits.sort(key=lambda x: x[2], reverse=True)\n",
        "    top_hits = all_hits[:top_k]\n",
        "\n",
        "    context_parts = []\n",
        "    citations = []\n",
        "    for rank, (doc_name, idx, score, text) in enumerate(top_hits, start=1):\n",
        "        header = f\"[{rank}] From {doc_name} (chunk #{idx}, score={score:.3f})\"\n",
        "        context_parts.append(header + \"\\n\" + text)\n",
        "        citations.append((doc_name, rank, score))\n",
        "\n",
        "    context = \"\\n\\n\".join(context_parts)\n",
        "    return context, citations\n",
        "\n",
        "def answer_with_rag(\n",
        "    api_key: str,\n",
        "    chat_model: str,\n",
        "    embed_model: str,\n",
        "    cohort_name: str,\n",
        "    query: str,\n",
        "    system_prompt: str = \"\",\n",
        ") -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Perform RAG retrieval and return (answer_markdown, raw_answer_text).\n",
        "    \"\"\"\n",
        "    resolved_chat, resolved_embed = resolve_models(chat_model, embed_model)\n",
        "    client = build_openai_client(api_key)\n",
        "\n",
        "    context, citations = build_context_from_index(\n",
        "        api_key, resolved_chat, resolved_embed, cohort_name, query\n",
        "    )\n",
        "\n",
        "    if not context:\n",
        "        return (\n",
        "            \"I could not find any context for this query in the selected cohort.\",\n",
        "            \"\",\n",
        "        )\n",
        "\n",
        "    if not system_prompt:\n",
        "        system_prompt = (\n",
        "            \"You are a helpful assistant answering questions based on the provided context. \"\n",
        "            \"If the answer cannot be found in the context, say you do not know.\"\n",
        "        )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Use ONLY the context below to answer the question.\\n\\n\"\n",
        "                \"=== CONTEXT START ===\\n\"\n",
        "                f\"{context}\\n\"\n",
        "                \"=== CONTEXT END ===\\n\\n\"\n",
        "                f\"QUESTION: {query}\"\n",
        "            ),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=resolved_chat,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        max_tokens=800,\n",
        "    )\n",
        "    answer_text = resp.choices[0].message.content.strip()\n",
        "\n",
        "    # Build markdown with citations\n",
        "    md = answer_text + \"\\n\\n---\\n\\n**Cited sources:**\\n\"\n",
        "    for doc_name, rank, score in citations:\n",
        "        md += f\"- [{rank}] `{doc_name}` (score={score:.3f})\\n\"\n",
        "\n",
        "    return md, answer_text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EqPphaRPA9_"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 6 / STEP 6 â€“ Build Cohort from Uploaded Docs\n",
        "# ============================================================\n",
        "\n",
        "def build_cohort_from_files(\n",
        "    api_key: str,\n",
        "    embed_model: str,\n",
        "    cohort_name: str,\n",
        "    files: List[Any],\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Upload and index one or more files into a cohort.\n",
        "    \"\"\"\n",
        "    if not files:\n",
        "        return \"Please upload at least one file.\"\n",
        "\n",
        "    if not cohort_name:\n",
        "        return \"Please provide a cohort name.\"\n",
        "\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    ensure_user_table()\n",
        "    ensure_chat_history_table()\n",
        "\n",
        "    status_lines = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            text, original_name = load_file_to_text(f)\n",
        "        except Exception as e:\n",
        "            status_lines.append(f\"âŒ {f.name}: error loading file â€“ {e}\")\n",
        "            continue\n",
        "\n",
        "        chunks = chunk_text(text)\n",
        "        if not chunks:\n",
        "            status_lines.append(f\"âš ï¸ {original_name}: no text found.\")\n",
        "            continue\n",
        "\n",
        "        vectors = embed_texts(api_key, embed_model, chunks)\n",
        "        index = build_faiss_index(vectors)\n",
        "        index_id = str(uuid4())\n",
        "        save_index(index, index_id)\n",
        "        save_metadata(\n",
        "            index_id,\n",
        "            {\n",
        "                \"chunks\": chunks,\n",
        "                \"doc_name\": original_name,\n",
        "                \"cohort_name\": cohort_name,\n",
        "                \"embed_model\": embed_model,\n",
        "                \"created_at\": datetime.now(timezone.utc).isoformat(),\n",
        "            },\n",
        "        )\n",
        "\n",
        "        register_document(\n",
        "            doc_name=original_name,\n",
        "            cohort_name=cohort_name,\n",
        "            index_id=index_id,\n",
        "            n_chunks=len(chunks),\n",
        "            embed_model=embed_model,\n",
        "        )\n",
        "\n",
        "        status_lines.append(\n",
        "            f\"âœ… Indexed `{original_name}` into cohort `{cohort_name}` with {len(chunks)} chunks.\"\n",
        "        )\n",
        "\n",
        "    if not status_lines:\n",
        "        return \"No files were successfully processed.\"\n",
        "    return \"\\n\".join(status_lines)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzcKE8dRPBIN"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 7 / STEP 7 â€“ Admin Helpers (Stats & Maintenance)\n",
        "# ============================================================\n",
        "\n",
        "def get_db_stats() -> str:\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    ensure_user_table()\n",
        "    ensure_chat_history_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM documents\")\n",
        "    n_docs = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(DISTINCT cohort_name) FROM cohort_docs\")\n",
        "    n_cohorts = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM users\")\n",
        "    n_users = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM chat_history\")\n",
        "    n_chats = cur.fetchone()[0]\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    return (\n",
        "        f\"**DB Stats**\\n\\n\"\n",
        "        f\"- Documents: {n_docs}\\n\"\n",
        "        f\"- Cohorts: {n_cohorts}\\n\"\n",
        "        f\"- Users: {n_users}\\n\"\n",
        "        f\"- Chat records (last 7 days enforced on write): {n_chats}\\n\"\n",
        "    )\n",
        "\n",
        "def describe_users() -> str:\n",
        "    rows = list_users()\n",
        "    if not rows:\n",
        "        return \"No users have been recorded yet.\"\n",
        "    lines = [\"**Known Users**\\n\"]\n",
        "    for user_id, display_name, role in rows:\n",
        "        disp = display_name or \"(no display name)\"\n",
        "        r = role or \"(no role)\"\n",
        "        lines.append(f\"- `{user_id}` â€“ {disp} â€“ role: `{r}`\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def describe_cohorts() -> str:\n",
        "    \"\"\"\n",
        "    Returns a markdown summary of cohorts, including:\n",
        "      - name\n",
        "      - owner\n",
        "      - visibility (private/shared)\n",
        "      - document count\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    ensure_cohort_meta_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT DISTINCT\n",
        "            cd.cohort_name,\n",
        "            COALESCE(cm.owner_user_id, '(none)') AS owner,\n",
        "            COALESCE(cm.is_shared, 0)            AS is_shared,\n",
        "            COUNT(DISTINCT cd.doc_name)          AS num_docs\n",
        "        FROM cohort_docs cd\n",
        "        LEFT JOIN cohort_meta cm\n",
        "          ON cd.cohort_name = cm.cohort_name\n",
        "        GROUP BY cd.cohort_name, owner, is_shared\n",
        "        ORDER BY cd.cohort_name\n",
        "        \"\"\"\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    if not rows:\n",
        "        return \"No cohorts found.\"\n",
        "\n",
        "    lines = [\"**Cohorts**\", \"\"]\n",
        "    for name, owner, is_shared, num_docs in rows:\n",
        "        share_label = \"shared\" if is_shared else \"private\"\n",
        "        lines.append(\n",
        "            f\"- **{name}** â€” owner: `{owner}`, visibility: {share_label}, docs: {num_docs}\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KCwM-JOPBRd"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 8 / STEP 8 â€“ Prompt Coach (Optional Query Improvement)\n",
        "# ============================================================\n",
        "\n",
        "def improve_query(\n",
        "    api_key: str,\n",
        "    chat_model: str,\n",
        "    original_query: str,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Prompt coach to re-write the user's query for better RAG retrieval.\n",
        "    \"\"\"\n",
        "    if not original_query.strip():\n",
        "        return \"\"\n",
        "\n",
        "    resolved_chat, _ = resolve_models(chat_model, EMBED_MODEL_DEFAULT)\n",
        "    client = build_openai_client(api_key)\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a prompt coach helping the user improve questions for a RAG system. \"\n",
        "        \"Rewrite the query to be explicit, concise, and focused on key details. \"\n",
        "        \"Return ONLY the improved query text.\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": original_query},\n",
        "    ]\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=resolved_chat,\n",
        "        messages=messages,\n",
        "        temperature=0.1,\n",
        "        max_tokens=200,\n",
        "    )\n",
        "    improved = resp.choices[0].message.content.strip()\n",
        "    return improved\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwFVsO6MPBbG"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 9 / STEP 9 â€“ Chat History Viewer (User-Facing)\n",
        "# ============================================================\n",
        "\n",
        "def format_history_markdown(\n",
        "    user_id: Optional[str],\n",
        "    cohort_name: Optional[str],\n",
        "    limit: int = 50,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Turn recent history into markdown for display.\n",
        "    \"\"\"\n",
        "    hist = get_recent_history(user_id=user_id, cohort_name=cohort_name, limit=limit)\n",
        "    if not hist:\n",
        "        return \"No chat history found for the given filters (within retention window).\"\n",
        "\n",
        "    lines = []\n",
        "    lines.append(\n",
        "        f\"**Showing up to {limit} most recent interactions** \"\n",
        "        f\"{'(filtered)' if user_id or cohort_name else ''}\\n\"\n",
        "    )\n",
        "\n",
        "    for h in hist:\n",
        "        ts = h[\"created_at\"]\n",
        "        u = h[\"user_id\"] or \"(anonymous)\"\n",
        "        r = h[\"role\"] or \"(none)\"\n",
        "        c = h[\"cohort_name\"] or \"(none)\"\n",
        "        which = h[\"which_prompt\"] or \"(unknown)\"\n",
        "\n",
        "        lines.append(f\"---\\n**User:** `{u}`  |  **Role:** `{r}`  |  **Cohort:** `{c}`  |  **When:** {ts}\")\n",
        "        lines.append(f\"**Prompt used:** `{which}`\")\n",
        "        lines.append(f\"**Original query:**\\n{h['original_query']}\\n\")\n",
        "        if h[\"improved_query\"]:\n",
        "            lines.append(f\"**Improved query:**\\n{h['improved_query']}\\n\")\n",
        "        lines.append(\"**Answer:**\")\n",
        "        lines.append(h[\"answer\"])\n",
        "        lines.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xUlh5Loticb"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 9.5 / STEP 9.5 â€“ Identity & Admin Ops (v14)\n",
        "# ============================================================\n",
        "\n",
        "def authenticate(username: str, password: str) -> SessionUser | None:\n",
        "    \"\"\"\n",
        "    MVP auth: checks against local USERS dict.\n",
        "    Returns SessionUser or None if invalid.\n",
        "    \"\"\"\n",
        "    record = USERS.get(username)\n",
        "    if not record:\n",
        "        return None\n",
        "    if password != record[\"password\"]:\n",
        "        return None\n",
        "    return SessionUser(username=username, role=record[\"role\"])\n",
        "\n",
        "def require_admin(user: SessionUser):\n",
        "    \"\"\"\n",
        "    Helper for admin-only actions. Raises PermissionError if not admin.\n",
        "    \"\"\"\n",
        "    if not user or not user.is_admin:\n",
        "        raise PermissionError(\"Admin privileges required for this action.\")\n",
        "\n",
        "\n",
        "def admin_delete_cohort(user: SessionUser, cohort_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Admin-only wrapper around delete_cohort().\n",
        "    Uses the existing delete_cohort function from STEP 4.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        require_admin(user)\n",
        "    except PermissionError as e:\n",
        "        return f\"âŒ Not authorized: {e}\"\n",
        "\n",
        "    if not cohort_name:\n",
        "        return \"âŒ Please select a cohort to delete.\"\n",
        "\n",
        "    try:\n",
        "        # Use existing v13 delete_cohort logic (no reassignment in this MVP).\n",
        "        msg = delete_cohort(cohort_name, reassign_to=None)\n",
        "        log_audit(user.username, user.role, \"delete_cohort\", f\"cohort={cohort_name}\")\n",
        "        return msg\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error deleting cohort: {e}\"\n",
        "\n",
        "def admin_view_audit_log(user: SessionUser, limit: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Admin-only view of recent audit log entries.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        require_admin(user)\n",
        "    except PermissionError as e:\n",
        "        return f\"âŒ Not authorized: {e}\"\n",
        "\n",
        "    ensure_audit_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT ts, username, role, action, details\n",
        "        FROM audit_log\n",
        "        ORDER BY id DESC\n",
        "        LIMIT ?\n",
        "        \"\"\",\n",
        "        (limit,),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    if not rows:\n",
        "        return \"No audit log entries.\"\n",
        "\n",
        "    lines = [\"**Recent Audit Log Entries**\\n\"]\n",
        "    for ts, username, role, action, details in rows:\n",
        "        u = username or \"-\"\n",
        "        r = role or \"-\"\n",
        "        d = details or \"\"\n",
        "        lines.append(f\"- {ts} | user=`{u}` | role=`{r}` | action=`{action}` | {d}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzhkMMGGtpb-"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 10 / STEP 10 â€“ Gradio App (Cohorts, Admin, History, Q&A) â€“ v14\n",
        "# ============================================================\n",
        "\n",
        "def on_build_cohort(\n",
        "    api_key,\n",
        "    embed_model,\n",
        "    cohort_name,\n",
        "    files,\n",
        "    current_user: SessionUser,\n",
        "):\n",
        "    # Normalize name\n",
        "    cohort_name = (cohort_name or \"\").strip()\n",
        "\n",
        "    # Basic validation\n",
        "    if not api_key:\n",
        "        return \"âŒ Please provide your OpenAI API key.\", gr.update(), gr.update()\n",
        "    if not files:\n",
        "        return \"âŒ Please upload one or more files.\", gr.update(), gr.update()\n",
        "    if not cohort_name:\n",
        "        return \"âŒ Please provide a cohort name.\", gr.update(), gr.update()\n",
        "\n",
        "    # NEW: enforce global uniqueness of cohort name\n",
        "    if cohort_exists(cohort_name):\n",
        "        # Donâ€™t clear uploads; user may just want to rename\n",
        "        return (\n",
        "            f\"âŒ A cohort named '{cohort_name}' already exists. \"\n",
        "            \"Please choose a different name.\",\n",
        "            gr.update(),           # keep file_uploader contents\n",
        "            gr.update(),           # keep cohort_name_box as-is so they can tweak it\n",
        "        )\n",
        "\n",
        "    # Build / update cohort\n",
        "    msg = build_cohort_from_files(api_key, embed_model, cohort_name, files)\n",
        "\n",
        "    # Register cohort owner\n",
        "    try:\n",
        "        set_cohort_owner(cohort_name, current_user)\n",
        "    except Exception as e:\n",
        "        print(\"DEBUG set_cohort_owner error:\", e)\n",
        "\n",
        "    # Audit entry\n",
        "    log_audit(\n",
        "        username=current_user.username if current_user and current_user.username else \"\",\n",
        "        role=current_user.role if current_user else \"\",\n",
        "        action=\"build_cohort\",\n",
        "        details=f\"cohort={cohort_name}\",\n",
        "    )\n",
        "\n",
        "    # On success: clear file uploads and cohort name textbox\n",
        "    return msg, gr.update(value=None), gr.update(value=\"\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def on_refresh_cohorts_for_user(current_user=None):\n",
        "    \"\"\"\n",
        "    Refresh cohort dropdown based on the current user's visibility:\n",
        "      - admin: all cohorts\n",
        "      - user: only own (and shared) cohorts\n",
        "\n",
        "    This version is defensive:\n",
        "      - If Gradio passes no args or something unexpected, we fall back to anonymous.\n",
        "      - If filtering fails for any reason, we fall back to global list_cohorts().\n",
        "    \"\"\"\n",
        "    # Defensive handling: Gradio sometimes passes None or unexpected types\n",
        "    if isinstance(current_user, SessionUser):\n",
        "        user = current_user\n",
        "    else:\n",
        "        # Treat as anonymous if we don't have a valid SessionUser\n",
        "        user = SessionUser()\n",
        "\n",
        "    try:\n",
        "        names = list_cohorts_for_user(user)\n",
        "        if not names:\n",
        "            # Fallback: show global list (old v13 behavior)\n",
        "            names = list_cohorts()\n",
        "    except Exception as e:\n",
        "        print(\"DEBUG on_refresh_cohorts_for_user error:\", e)\n",
        "        names = list_cohorts()\n",
        "\n",
        "    if not names:\n",
        "        return gr.update(choices=[], value=None)\n",
        "    return gr.update(choices=names, value=names[0])\n",
        "\n",
        "\n",
        "def on_validate_key(api_key, chat_model, embed_model):\n",
        "    return validate_openai_key_and_models(api_key, chat_model, embed_model)\n",
        "\n",
        "def on_improve_query(api_key, chat_model, original_query):\n",
        "    if not api_key:\n",
        "        return \"Please provide an API key first.\"\n",
        "    return improve_query(api_key, chat_model, original_query)\n",
        "\n",
        "def on_ask_with_choice(\n",
        "    api_key,\n",
        "    user_id,\n",
        "    user_role,\n",
        "    chat_model,\n",
        "    embed_model,\n",
        "    cohort_name,\n",
        "    original_query,\n",
        "    improved_query,\n",
        "    which_prompt,\n",
        "):\n",
        "    \"\"\"\n",
        "    Main Q&A handler:\n",
        "    - Respects which_prompt (original vs improved)\n",
        "    - Performs RAG\n",
        "    - Saves chat history with 7-day retention\n",
        "    - Upserts user with role (future ICAM)\n",
        "    - NEW (v14): Writes an audit_log 'ask' entry\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"âŒ Please provide your OpenAI API key.\", \"\"\n",
        "\n",
        "    if not cohort_name:\n",
        "        return \"âŒ Please select a cohort.\", \"\"\n",
        "\n",
        "    if not original_query.strip():\n",
        "        return \"âŒ Please enter a question.\", \"\"\n",
        "\n",
        "    # Choose which query to send\n",
        "    query = original_query\n",
        "    if which_prompt == \"Improved\" and improved_query.strip():\n",
        "        query = improved_query\n",
        "\n",
        "    # Upsert user (scaffolding for ICAM)\n",
        "    user_id_clean = (user_id or \"\").strip() or \"anonymous\"\n",
        "    user_role_clean = (user_role or \"\").strip() or \"user\"\n",
        "    upsert_user(user_id_clean, user_role_clean)\n",
        "\n",
        "    # Call RAG\n",
        "    answer_md, answer_text = answer_with_rag(\n",
        "        api_key=api_key,\n",
        "        chat_model=chat_model,\n",
        "        embed_model=embed_model,\n",
        "        cohort_name=cohort_name,\n",
        "        query=query,\n",
        "    )\n",
        "\n",
        "    # Save chat history\n",
        "    save_chat_interaction(\n",
        "        user_id=user_id_clean,\n",
        "        role=user_role_clean,\n",
        "        cohort_name=cohort_name,\n",
        "        original_query=original_query,\n",
        "        improved_query=improved_query,\n",
        "        which_prompt=which_prompt,\n",
        "        answer=answer_md,\n",
        "        chat_model=chat_model or CHAT_MODEL_DEFAULT,\n",
        "    )\n",
        "\n",
        "    # NEW: audit log entry for the question\n",
        "    log_audit(\n",
        "        username=user_id_clean,\n",
        "        role=user_role_clean,\n",
        "        action=\"ask\",\n",
        "        details=f\"cohort={cohort_name}; which={which_prompt}; q={query[:200]}\",\n",
        "    )\n",
        "\n",
        "    return answer_md, answer_text\n",
        "\n",
        "def on_view_history(user_id, cohort_name, limit):\n",
        "    uid = user_id.strip() if user_id else None\n",
        "    coh = cohort_name.strip() if cohort_name else None\n",
        "    try:\n",
        "        limit_int = int(limit)\n",
        "    except Exception:\n",
        "        limit_int = 50\n",
        "\n",
        "    md = format_history_markdown(uid, coh, limit_int)\n",
        "\n",
        "    # Audit the view (doesn't depend on SessionUser yet, just the filter)\n",
        "    log_audit(\n",
        "        username=uid or \"\",\n",
        "        role=\"\",  # we aren't tying this to SessionUser role here\n",
        "        action=\"view_history\",\n",
        "        details=f\"user_filter={uid or ''}; cohort_filter={coh or ''}; limit={limit_int}\",\n",
        "    )\n",
        "\n",
        "    return md\n",
        "\n",
        "\n",
        "def on_admin_refresh(current_user: SessionUser):\n",
        "    \"\"\"\n",
        "    Admin overview (stats & inventory).\n",
        "    Now enforces admin role and logs an audit event.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        require_admin(current_user)\n",
        "    except PermissionError as e:\n",
        "        return f\"âŒ Not authorized: {e}\", \"\", \"\"\n",
        "\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    ensure_user_table()\n",
        "    ensure_chat_history_table()\n",
        "    ensure_audit_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM documents\")\n",
        "    n_docs = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(DISTINCT cohort_name) FROM cohort_docs\")\n",
        "    n_cohorts = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM users\")\n",
        "    n_users = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM chat_history\")\n",
        "    n_chats = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM audit_log\")\n",
        "    n_audit = cur.fetchone()[0]\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    stats = (\n",
        "        f\"**DB Stats**\\n\\n\"\n",
        "        f\"- Documents: {n_docs}\\n\"\n",
        "        f\"- Cohorts: {n_cohorts}\\n\"\n",
        "        f\"- Users: {n_users}\\n\"\n",
        "        f\"- Chat records (last 7 days enforced on write): {n_chats}\\n\"\n",
        "        f\"- Audit log entries: {n_audit}\\n\"\n",
        "    )\n",
        "\n",
        "    cohorts_md = describe_cohorts()\n",
        "    users_md = describe_users()\n",
        "\n",
        "    log_audit(current_user.username, current_user.role, \"admin_refresh\", \"Refreshed admin overview\")\n",
        "\n",
        "    return stats, cohorts_md, users_md\n",
        "\n",
        "def login_fn(username, password, current_user: SessionUser):\n",
        "    \"\"\"\n",
        "    Login handler for v14:\n",
        "      - Authenticates against USERS\n",
        "      - Logs success/failure to audit_log\n",
        "      - Updates admin panel visibility\n",
        "      - Updates Ask tab user_id / role\n",
        "      - Clears file uploads on login\n",
        "    \"\"\"\n",
        "    username = (username or \"\").strip()\n",
        "    password = (password or \"\").strip()\n",
        "\n",
        "    user = authenticate(username, password)\n",
        "\n",
        "    if not user:\n",
        "        # Audit failed login\n",
        "        log_audit(\n",
        "            username=username,\n",
        "            role=\"\",\n",
        "            action=\"login_failed\",\n",
        "            details=\"Invalid credentials\",\n",
        "        )\n",
        "        return (\n",
        "            SessionUser(),                             # user_session\n",
        "            \"âŒ Invalid credentials. Try 'admin'/'admin123' or 'demo'/'demo123'.\",\n",
        "            gr.update(visible=False),                  # admin_panel\n",
        "            gr.update(visible=True, value=\"âš ï¸ You do not have permission to access the admin dashboard. Log in as an admin user to view admin tools.\"),\n",
        "            gr.update(value=\"\"),                       # user_id_box\n",
        "            gr.update(value=\"user\"),                   # user_role_dd default\n",
        "            gr.update(value=None),                     # file_uploader clear\n",
        "            gr.update(value=\"\"),                       # cohort_name_box clear\n",
        "        )\n",
        "\n",
        "\n",
        "    # Successful login\n",
        "    log_audit(user.username, user.role, \"login\", \"User logged in\")\n",
        "    status = f\"âœ… Logged in as {user.username} (role: {user.role})\"\n",
        "\n",
        "    if user.is_admin:\n",
        "        # Admin: can see admin panel, no warning\n",
        "        return (\n",
        "            user,                                     # user_session\n",
        "            status,                                   # login_status\n",
        "            gr.update(visible=True),                  # admin_panel\n",
        "            gr.update(visible=False),                 # admin_denied_md\n",
        "            gr.update(value=user.username),           # user_id_box\n",
        "            gr.update(value=\"admin\"),                 # user_role_dd\n",
        "            gr.update(value=None),                    # file_uploader clear\n",
        "            gr.update(value=\"\"),                      # cohort_name_box clear\n",
        "        )\n",
        "\n",
        "\n",
        "    # Non-admin (demo): hide admin panel, show warning\n",
        "    return (\n",
        "        user,\n",
        "        status,\n",
        "        gr.update(visible=False),                 # admin_panel\n",
        "        gr.update(\n",
        "            visible=True,\n",
        "            value=\"âš ï¸ You do not have permission to access the admin dashboard. \"\n",
        "                  \"Log in as an admin user to view admin tools.\",\n",
        "        ),\n",
        "        gr.update(value=user.username),           # user_id_box\n",
        "        gr.update(value=\"user\"),                  # user_role_dd\n",
        "        gr.update(value=None),                    # file_uploader clear\n",
        "        gr.update(value=\"\"),                      # cohort_name_box clear\n",
        "    )\n",
        "\n",
        "\n",
        "# ---------------------- Build Gradio UI ----------------------\n",
        "\n",
        "with gr.Blocks(title=\"Phase 1 â€“ RAG MVP (v14)\") as demo:\n",
        "    user_session = gr.State(SessionUser())  # holds current SessionUser\n",
        "\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # ðŸ“˜ Phase 1 â€“ RAG MVP (v14)\n",
        "\n",
        "        **New in v14:**\n",
        "        - âœ… Audit logging to SQLite (`audit_log` table)\n",
        "        - âœ… Simple login with roles (`admin`, `demo`) using SessionUser\n",
        "        - âœ… Admin-only actions (admin tab is hidden unless logged in as admin)\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # ---- Login Tab ----\n",
        "    with gr.Tab(\"0ï¸âƒ£ Login\"):\n",
        "        gr.Markdown(\n",
        "            \"Use `admin/admin123` for admin, `demo/demo123` for user (MVP only).\"\n",
        "        )\n",
        "        login_user = gr.Textbox(label=\"Username\")\n",
        "        login_pass = gr.Textbox(label=\"Password\", type=\"password\")\n",
        "        login_btn = gr.Button(\"Login\")\n",
        "        login_status = gr.Markdown(\"Not logged in.\")\n",
        "\n",
        "    # ---- Setup & Cohorts ----\n",
        "    with gr.Tab(\"1ï¸âƒ£ Setup & Cohorts\"):\n",
        "        gr.Markdown(\"### OpenAI Setup & Build a Cohort\")\n",
        "\n",
        "        api_key_box = gr.Textbox(\n",
        "            label=\"OpenAI API Key\",\n",
        "            type=\"password\",\n",
        "            placeholder=\"sk-...\",\n",
        "        )\n",
        "        chat_model_dd = gr.Textbox(\n",
        "            label=\"Chat Model\",\n",
        "            value=CHAT_MODEL_DEFAULT,\n",
        "            info=\"e.g., gpt-4.1, gpt-4.1-mini, gpt-4o, etc.\",\n",
        "        )\n",
        "        embed_model_dd = gr.Textbox(\n",
        "            label=\"Embedding Model\",\n",
        "            value=EMBED_MODEL_DEFAULT,\n",
        "            info=\"e.g., text-embedding-3-small\",\n",
        "        )\n",
        "\n",
        "        validate_btn = gr.Button(\"Validate Key & Models\")\n",
        "        validate_out = gr.Markdown()\n",
        "\n",
        "        validate_btn.click(\n",
        "            on_validate_key,\n",
        "            inputs=[api_key_box, chat_model_dd, embed_model_dd],\n",
        "            outputs=[validate_out],\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "\n",
        "        cohort_name_box = gr.Textbox(\n",
        "            label=\"Cohort Name\",\n",
        "            placeholder=\"e.g., WIC Policy Docs\",\n",
        "        )\n",
        "        file_uploader = gr.File(\n",
        "            label=\"Upload Files (PDF, DOCX, TXT)\",\n",
        "            file_count=\"multiple\",\n",
        "            type=\"filepath\",\n",
        "        )\n",
        "\n",
        "        build_btn = gr.Button(\"Build / Update Cohort\")\n",
        "        build_status = gr.Markdown()\n",
        "\n",
        "        build_btn.click(\n",
        "            on_build_cohort,\n",
        "            inputs=[api_key_box, embed_model_dd, cohort_name_box, file_uploader, user_session],\n",
        "            outputs=[build_status, file_uploader, cohort_name_box],\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # ---- Ask Your Documents ----\n",
        "    with gr.Tab(\"2ï¸âƒ£ Ask Your Documents\"):\n",
        "        gr.Markdown(\"### Ask Questions Against a Cohort\")\n",
        "\n",
        "        with gr.Row():\n",
        "            user_id_box = gr.Textbox(\n",
        "                label=\"User ID\",\n",
        "                placeholder=\"your-username-or-email\",\n",
        "                value=\"user1\",\n",
        "            )\n",
        "            user_role_dd = gr.Dropdown(\n",
        "                label=\"Role (scaffolding for ICAM)\",\n",
        "                choices=[\"user\", \"admin\"],\n",
        "                value=\"user\",\n",
        "            )\n",
        "\n",
        "            ask_cohort_dd = gr.Dropdown(\n",
        "                label=\"Select Cohort\",\n",
        "                choices=[],\n",
        "            )\n",
        "\n",
        "\n",
        "        refresh_cohorts_btn = gr.Button(\"ðŸ”„ Refresh Cohort List\")\n",
        "        refresh_cohorts_btn.click(\n",
        "            on_refresh_cohorts_for_user,\n",
        "            inputs=[user_session],\n",
        "            outputs=[ask_cohort_dd],\n",
        "        )\n",
        "\n",
        "        query_box = gr.Textbox(\n",
        "            label=\"Original Question\",\n",
        "            lines=4,\n",
        "            placeholder=\"Ask a question about your documents...\",\n",
        "        )\n",
        "        improved_query_box = gr.Textbox(\n",
        "            label=\"Improved Question (Prompt Coach Output)\",\n",
        "            lines=4,\n",
        "            placeholder=\"Click 'Improve Question' or edit manually.\",\n",
        "        )\n",
        "        prompt_choice = gr.Radio(\n",
        "            label=\"Which query should be used for RAG?\",\n",
        "            choices=[\"Original\", \"Improved\"],\n",
        "            value=\"Original\",\n",
        "        )\n",
        "\n",
        "        improve_btn = gr.Button(\"âœ¨ Improve Question\")\n",
        "        improve_btn.click(\n",
        "            on_improve_query,\n",
        "            inputs=[api_key_box, chat_model_dd, query_box],\n",
        "            outputs=[improved_query_box],\n",
        "        )\n",
        "\n",
        "        ask_btn = gr.Button(\"ðŸ’¬ Ask\")\n",
        "        answer_md = gr.Markdown()\n",
        "        raw_answer_box = gr.Textbox(\n",
        "            label=\"Raw Answer (for copy/print/export)\",\n",
        "            lines=6,\n",
        "        )\n",
        "\n",
        "        ask_btn.click(\n",
        "            on_ask_with_choice,\n",
        "            inputs=[\n",
        "                api_key_box,\n",
        "                user_id_box,\n",
        "                user_role_dd,\n",
        "                chat_model_dd,\n",
        "                embed_model_dd,\n",
        "                ask_cohort_dd,\n",
        "                query_box,\n",
        "                improved_query_box,\n",
        "                prompt_choice,\n",
        "            ],\n",
        "            outputs=[answer_md, raw_answer_box],\n",
        "        )\n",
        "\n",
        "    # ---- Chat History ----\n",
        "    with gr.Tab(\"3ï¸âƒ£ Chat History\"):\n",
        "        gr.Markdown(\n",
        "            \"### View Chat History (7-Day Window)\\n\"\n",
        "            \"History is stored in SQLite with automatic removal of records older than 7 days.\"\n",
        "        )\n",
        "\n",
        "        hist_user_id = gr.Textbox(\n",
        "            label=\"Filter by User ID (optional)\",\n",
        "            placeholder=\"Leave blank for all users\",\n",
        "        )\n",
        "        hist_cohort = gr.Textbox(\n",
        "            label=\"Filter by Cohort Name (optional)\",\n",
        "            placeholder=\"Leave blank for all cohorts\",\n",
        "        )\n",
        "        hist_limit = gr.Textbox(\n",
        "            label=\"Max Records\",\n",
        "            value=\"50\",\n",
        "        )\n",
        "        hist_btn = gr.Button(\"ðŸ“œ Show History\")\n",
        "        hist_md = gr.Markdown()\n",
        "\n",
        "        hist_btn.click(\n",
        "            on_view_history,\n",
        "            inputs=[hist_user_id, hist_cohort, hist_limit],\n",
        "            outputs=[hist_md],\n",
        "        )\n",
        "\n",
        "    # ---- Admin ----\n",
        "    with gr.Tab(\"4ï¸âƒ£ Admin\"):\n",
        "    # Panel hidden unless logged in as admin\n",
        "      admin_panel = gr.Group(visible=False)\n",
        "      with admin_panel:\n",
        "        gr.Markdown(\n",
        "            \"### Admin Overview (Stats, Inventory, & Audit Log)\\n\"\n",
        "            \"This tab is only visible when logged in as an admin.\"\n",
        "        )\n",
        "\n",
        "        admin_refresh_btn = gr.Button(\"ðŸ”„ Refresh Admin Info\")\n",
        "        admin_stats_md = gr.Markdown()\n",
        "        admin_cohorts_md = gr.Markdown()\n",
        "        admin_users_md = gr.Markdown()\n",
        "\n",
        "        admin_refresh_btn.click(\n",
        "            on_admin_refresh,\n",
        "            inputs=[user_session],\n",
        "            outputs=[admin_stats_md, admin_cohorts_md, admin_users_md],\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "\n",
        "        # Admin-only: delete cohort\n",
        "        admin_refresh_cohorts_btn = gr.Button(\"ðŸ”„ Refresh Cohort List (Admin)\")\n",
        "        admin_del_cohort_dd = gr.Dropdown(\n",
        "            label=\"Cohort to delete (admin only)\",\n",
        "            choices=[],\n",
        "        )\n",
        "        admin_delete_cohort_btn = gr.Button(\"ðŸ—‘ï¸ Delete Selected Cohort\")\n",
        "        admin_delete_status = gr.Markdown()\n",
        "\n",
        "        admin_refresh_cohorts_btn.click(\n",
        "            on_refresh_cohorts_for_user,\n",
        "            inputs=[user_session],\n",
        "            outputs=[admin_del_cohort_dd],\n",
        "        )\n",
        "\n",
        "        admin_delete_cohort_btn.click(\n",
        "            fn=lambda cohort, user: admin_delete_cohort(user, cohort),\n",
        "            inputs=[admin_del_cohort_dd, user_session],\n",
        "            outputs=[admin_delete_status],\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "\n",
        "        # Admin-only: view audit log\n",
        "        audit_btn = gr.Button(\"ðŸ“‹ View Audit Log (last 50)\")\n",
        "        audit_md = gr.Markdown()\n",
        "\n",
        "        audit_btn.click(\n",
        "            fn=lambda user: admin_view_audit_log(user, limit=50),\n",
        "            inputs=[user_session],\n",
        "            outputs=[audit_md],\n",
        "        )\n",
        "\n",
        "    # NEW: message shown when user is not admin\n",
        "    admin_denied_md = gr.Markdown(\n",
        "        \"âš ï¸ You do not have permission to access the admin dashboard. \"\n",
        "        \"Log in as an admin user to view admin tools.\",\n",
        "        visible=True,\n",
        "    )\n",
        "\n",
        "\n",
        "    gr.Markdown(\"Built for fast iteration and future ICAM integration. âš¡\")\n",
        "\n",
        "    # Wire login button\n",
        "    login_btn.click(\n",
        "          fn=login_fn,\n",
        "          inputs=[login_user, login_pass, user_session],\n",
        "          outputs=[\n",
        "              user_session,\n",
        "              login_status,\n",
        "              admin_panel,\n",
        "              admin_denied_md,\n",
        "              user_id_box,\n",
        "              user_role_dd,\n",
        "              file_uploader,\n",
        "              cohort_name_box,\n",
        "          ],\n",
        "    )\n",
        "\n",
        "\n",
        "demo.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbXqa9KUrH435cE5xgunrG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}