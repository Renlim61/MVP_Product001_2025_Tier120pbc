{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Renlim61/MVP_Product001_2025_Tier120pbc/blob/version-history/Phase1_RAG_MVP_v16_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "703cdf3d",
      "metadata": {
        "id": "703cdf3d"
      },
      "outputs": [],
      "source": [
        "# ==============================================================\n",
        "# Colab setup\n",
        "# ==============================================================\n",
        "%pip install -q faiss-cpu openai gradio PyPDF2 python-docx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b6991f89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "b6991f89",
        "outputId": "2144aca7-0ed3-454c-9594-7ec7e6bda844"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RAG_MVP_v16_login_logout_stable.ipynb\\n\\nAutomatically generated by Colab.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/13hSYOl6kd3G1xwcYnIGtXN0TMlS-jt0e\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Phase1_RAG_MVP_v16_1.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1p5oRzSNrrsgLwxdyvPBohruPzRimlXYO\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"RAG_MVP_v16_Prod_Ready.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1HeWDkcsep3wz8eF92iUeDD1P9ecBpDlw\n",
        "\"\"\"\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"RAG_MVP_v16_login_logout_stable.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/13hSYOl6kd3G1xwcYnIGtXN0TMlS-jt0e\n",
        "\"\"\"\n",
        "#\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "# CELL 0 / STEP 0 – Install & Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3b9bad4b",
      "metadata": {
        "id": "3b9bad4b"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# Run this once at the top of the notebook (Colab style).\n",
        "#=============================================================\n",
        "# %pip install -q faiss-cpu openai gradio PyPDF2 python-docx\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import shutil\n",
        "import pickle\n",
        "import sqlite3\n",
        "from uuid import uuid4\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "import gradio as gr\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document as DocxDocument\n",
        "\n",
        "# Global datetime import for the whole notebook\n",
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "# Colab detection\n",
        "try:\n",
        "    import google.colab  # type: ignore\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive as colab_drive\n",
        "\n",
        "# OpenAI client (v1 library)\n",
        "from openai import OpenAI\n",
        "\n",
        "# CELL 1 — Execution flags & persistence-safe paths (Colab/Drive)\n",
        "#============================================================\n",
        "# If True, we only run the DB pre-flight checks and stop BEFORE launching Gradio.\n",
        "RUN_PREFLIGHT_ONLY = False\n",
        "\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "51747823",
      "metadata": {
        "id": "51747823"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# PERSISTENCE CONFIG (Colab-safe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "704802e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "704802e5",
        "outputId": "fe6ad7ce-2044-428d-e626-58f738911452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "PERSISTENCE CONFIG\n",
            "IN_COLAB: True\n",
            "BASE_DIR: /content/drive/MyDrive/rag_mvp\n",
            "DB_PATH : /content/drive/MyDrive/rag_mvp/rag_documents.db\n",
            "INDEX_DIR: /content/drive/MyDrive/rag_mvp/indexes\n",
            "TRACE_LOG_PATH: /content/drive/MyDrive/rag_mvp/debug_trace_v16.log\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "\n",
        "# Colab runtime storage under /content is ephemeral. Persist DB + indexes to Drive.\n",
        "USE_DRIVE_PERSISTENCE = True          # Set False only if running locally\n",
        "DRIVE_SUBFOLDER = \"rag_mvp\"           # Folder under MyDrive\n",
        "\n",
        "# If IN_COLAB is not defined for any reason, define it safely.\n",
        "try:\n",
        "    IN_COLAB\n",
        "except NameError:\n",
        "    try:\n",
        "        import google.colab  # type: ignore\n",
        "        IN_COLAB = True\n",
        "    except Exception:\n",
        "        IN_COLAB = False\n",
        "\n",
        "if IN_COLAB and USE_DRIVE_PERSISTENCE:\n",
        "    try:\n",
        "        from google.colab import drive as colab_drive  # type: ignore\n",
        "        colab_drive.mount(\"/content/drive\", force_remount=False)\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Drive mount issue (continuing):\", e)\n",
        "\n",
        "    BASE_DIR = f\"/content/drive/MyDrive/{DRIVE_SUBFOLDER}\"\n",
        "else:\n",
        "    BASE_DIR = os.path.join(os.getcwd(), DRIVE_SUBFOLDER)\n",
        "\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "\n",
        "# Persistent DB path\n",
        "DB_PATH = os.path.join(BASE_DIR, \"rag_documents.db\")\n",
        "\n",
        "# Persistent index/log directories\n",
        "INDEX_DIR = os.path.join(BASE_DIR, \"indexes\")\n",
        "os.makedirs(INDEX_DIR, exist_ok=True)\n",
        "\n",
        "TRACE_LOG_PATH = os.path.join(BASE_DIR, \"debug_trace_v16.log\")\n",
        "\n",
        "print(\"PERSISTENCE CONFIG\")\n",
        "print(\"IN_COLAB:\", IN_COLAB)\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"DB_PATH :\", DB_PATH)\n",
        "print(\"INDEX_DIR:\", INDEX_DIR)\n",
        "print(\"TRACE_LOG_PATH:\", TRACE_LOG_PATH)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1584691a",
      "metadata": {
        "id": "1584691a"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 1.75 — Global Configuration Constants\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "567f6de5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "567f6de5",
        "outputId": "ec445b33-15a2-4166-8deb-0d5c3eb41b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONFIG CONSTANTS LOADED\n",
            "CHUNK_SIZE = 800\n",
            "CHUNK_OVERLAP = 100\n",
            "DEFAULT_EMBED_MODEL = text-embedding-3-small\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# -------- Chunking --------\n",
        "CHUNK_SIZE = 800          # tokens/characters per chunk (adjust as needed)\n",
        "CHUNK_OVERLAP = 100       # overlap between chunks\n",
        "\n",
        "# -------- Embeddings / Index --------\n",
        "EMBEDDING_DIM = 1536      # OpenAI text-embedding-3-small\n",
        "DEFAULT_EMBED_MODEL = \"text-embedding-3-small\"\n",
        "\n",
        "# -------- Retrieval --------\n",
        "TOP_K = 5\n",
        "\n",
        "# -------- Limits --------\n",
        "MAX_FILES_PER_UPLOAD = 20\n",
        "MAX_FILE_SIZE_MB = 25\n",
        "\n",
        "print(\"CONFIG CONSTANTS LOADED\")\n",
        "print(\"CHUNK_SIZE =\", CHUNK_SIZE)\n",
        "print(\"CHUNK_OVERLAP =\", CHUNK_OVERLAP)\n",
        "print(\"DEFAULT_EMBED_MODEL =\", DEFAULT_EMBED_MODEL)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2eb0de2c",
      "metadata": {
        "id": "2eb0de2c"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 1.9 — OpenAI Client Factory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "94193dba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94193dba",
        "outputId": "c698260d-5746-48cb-fa42-d7d91eff97d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ build_openai_client() is defined.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "def build_openai_client(api_key: str):\n",
        "    \"\"\"\n",
        "    Returns an OpenAI client using the new SDK interface.\n",
        "    Centralized so ingestion and chat use the same construction.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        raise ValueError(\"OpenAI API key is required.\")\n",
        "\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "    except ImportError as e:\n",
        "        raise RuntimeError(\"openai package not installed.\") from e\n",
        "\n",
        "    return OpenAI(api_key=api_key)\n",
        "\n",
        "print(\"✅ build_openai_client() is defined.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "415bb516",
      "metadata": {
        "id": "415bb516"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 1.95 — Model Defaults + Resolver\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4a3a38f6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a3a38f6",
        "outputId": "1b344636-94fe-48ea-a14b-2ae55f72b061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ resolve_models() is defined.\n",
            "   CHAT_MODEL_DEFAULT = gpt-4.1-mini\n",
            "   EMBED_MODEL_DEFAULT = text-embedding-3-small\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# Defaults (used across embed + chat if user does not override)\n",
        "EMBED_MODEL_DEFAULT = \"text-embedding-3-small\"\n",
        "CHAT_MODEL_DEFAULT  = \"gpt-4.1-mini\"\n",
        "\n",
        "def resolve_models(chat_model: str | None, embed_model: str | None) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Normalize selected models and apply defaults.\n",
        "    Returns (resolved_chat_model, resolved_embed_model).\n",
        "    \"\"\"\n",
        "    resolved_chat = (chat_model or \"\").strip() or CHAT_MODEL_DEFAULT\n",
        "    resolved_embed = (embed_model or \"\").strip() or EMBED_MODEL_DEFAULT\n",
        "    return resolved_chat, resolved_embed\n",
        "\n",
        "print(\"✅ resolve_models() is defined.\")\n",
        "print(\"   CHAT_MODEL_DEFAULT =\", CHAT_MODEL_DEFAULT)\n",
        "print(\"   EMBED_MODEL_DEFAULT =\", EMBED_MODEL_DEFAULT)\n",
        "\n",
        "# CELL 1.5 / STEP 1.5 – Validate OpenAI Key & Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a9546141",
      "metadata": {
        "id": "a9546141"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def validate_openai_key_and_models(api_key: str, chat_model: str, embed_model: str) -> str:\n",
        "    \"\"\"\n",
        "    Lightweight validation:\n",
        "    - Instantiate client\n",
        "    - Do a tiny chat completion\n",
        "    - Do a small embedding call\n",
        "    Returns a human-readable status string.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        return \"❌ Please provide an OpenAI API key.\"\n",
        "\n",
        "    try:\n",
        "        client = build_openai_client(api_key)\n",
        "        resolved_chat, resolved_embed = resolve_models(chat_model, embed_model)\n",
        "\n",
        "        # Tiny chat test\n",
        "        _ = client.chat.completions.create(\n",
        "            model=resolved_chat,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Model availability test.\"},\n",
        "                {\"role\": \"user\", \"content\": \"Respond with 'OK' only.\"},\n",
        "            ],\n",
        "            max_tokens=2,\n",
        "            temperature=0.0,\n",
        "        )\n",
        "\n",
        "        # Tiny embedding test\n",
        "        _ = client.embeddings.create(\n",
        "            model=resolved_embed,\n",
        "            input=[\"test\"],\n",
        "        )\n",
        "\n",
        "        return f\"✅ OpenAI key valid. Chat model: `{resolved_chat}`, Embed model: `{resolved_embed}`\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error validating key/models: {e}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a3f6aecd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3f6aecd",
        "outputId": "8e2a88bb-2350-49ce-e437-76ac2b2c3237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DB SANITY GATE — PRE-FLIGHT CHECK\n",
            "================================================================================\n",
            "BASE_DIR: /content/drive/MyDrive/rag_mvp\n",
            "DB_PATH : /content/drive/MyDrive/rag_mvp/rag_documents.db\n",
            "Exists  : True\n",
            "Size    : 94208\n",
            "Modified: Thu Dec 18 19:27:47 2025\n",
            "Tables  : ['audit_log', 'chat_history', 'cohort_docs', 'cohort_meta', 'cohorts', 'demo_prompts', 'documents', 'model_registry', 'sqlite_sequence', 'users']\n",
            "✅ DB SANITY GATE PASSED\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "#============================================================\n",
        "\n",
        "# CELL 1.25 — Soft DB sanity gate (bootstrap + report)\n",
        "#============================================================\n",
        "import sqlite3\n",
        "import time\n",
        "\n",
        "REQUIRED_TABLES = [\n",
        "    \"documents\",\n",
        "    \"cohort_docs\",\n",
        "    \"cohorts\",\n",
        "    \"cohort_meta\",\n",
        "    \"users\",\n",
        "    \"chat_history\",\n",
        "    \"audit_log\",\n",
        "    \"model_registry\",\n",
        "]\n",
        "\n",
        "def soft_db_sanity_gate(db_path: str, base_dir: str, required_tables: list[str]) -> None:\n",
        "    print(\"=\"*80)\n",
        "    print(\"DB SANITY GATE — PRE-FLIGHT CHECK\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"BASE_DIR:\", base_dir)\n",
        "    print(\"DB_PATH :\", db_path)\n",
        "\n",
        "    os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
        "\n",
        "    # Create DB file if missing (do NOT fail on first run)\n",
        "    first_create = not os.path.exists(db_path)\n",
        "    if first_create:\n",
        "        # Touch/create by connecting\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    # Bootstrap minimal schema so the app can start from a clean environment\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Minimal table definitions (aligned with MVP expectations)\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS documents (\n",
        "            id              TEXT PRIMARY KEY,\n",
        "            doc_name        TEXT NOT NULL,\n",
        "            cohort_name     TEXT NOT NULL,\n",
        "            index_id        TEXT NOT NULL,\n",
        "            n_chunks        INTEGER NOT NULL,\n",
        "            embed_model     TEXT NOT NULL,\n",
        "            created_at      TEXT NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohort_docs (\n",
        "            cohort_name TEXT NOT NULL,\n",
        "            doc_name    TEXT NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohorts (\n",
        "            id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            name            TEXT NOT NULL UNIQUE,\n",
        "            description     TEXT,\n",
        "            owner_user_id   TEXT,\n",
        "            created_at      TEXT NOT NULL,\n",
        "            updated_at      TEXT NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohort_meta (\n",
        "            cohort_name    TEXT PRIMARY KEY,\n",
        "            owner_user_id  TEXT,\n",
        "            is_shared      INTEGER DEFAULT 0,\n",
        "            allow_clone    INTEGER DEFAULT 0,\n",
        "            created_ts     TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS users (\n",
        "            user_id      TEXT PRIMARY KEY,\n",
        "            display_name TEXT,\n",
        "            role         TEXT,\n",
        "            created_at   TEXT NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id             INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_id        TEXT,\n",
        "            role           TEXT,\n",
        "            cohort_name    TEXT,\n",
        "            original_query TEXT,\n",
        "            improved_query TEXT,\n",
        "            which_prompt   TEXT,\n",
        "            answer         TEXT,\n",
        "            chat_model     TEXT,\n",
        "            created_at     TEXT NOT NULL\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS audit_log (\n",
        "            id        INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            ts        TEXT NOT NULL,\n",
        "            username  TEXT,\n",
        "            role      TEXT,\n",
        "            action    TEXT NOT NULL,\n",
        "            details   TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "    cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS model_registry (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            provider TEXT,\n",
        "            model_id TEXT,\n",
        "            display_name TEXT,\n",
        "            model_type TEXT,\n",
        "            enabled INTEGER DEFAULT 1,\n",
        "            is_default INTEGER DEFAULT 0,\n",
        "            cost_score INTEGER DEFAULT 2,\n",
        "            latency_score INTEGER DEFAULT 2,\n",
        "            max_context_tokens INTEGER,\n",
        "            api_base TEXT,\n",
        "            notes TEXT\n",
        "        )\n",
        "    \"\"\")\n",
        "\n",
        "    conn.commit()\n",
        "\n",
        "    # Inspect tables\n",
        "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' ORDER BY name\")\n",
        "    tables = [r[0] for r in cur.fetchall()]\n",
        "    missing = [t for t in required_tables if t not in set(tables)]\n",
        "\n",
        "    # File stats\n",
        "    exists = os.path.exists(db_path)\n",
        "    size = os.path.getsize(db_path) if exists else None\n",
        "    mtime = time.ctime(os.path.getmtime(db_path)) if exists else None\n",
        "\n",
        "    print(\"Exists  :\", exists)\n",
        "    print(\"Size    :\", size)\n",
        "    print(\"Modified:\", mtime)\n",
        "    print(\"Tables  :\", tables)\n",
        "\n",
        "    if missing:\n",
        "        print(\"❌ DB SANITY GATE FAILED — still missing required tables:\", missing)\n",
        "        raise RuntimeError(f\"DB schema incomplete after bootstrap. Missing tables: {missing}\")\n",
        "\n",
        "    print(\"✅ DB SANITY GATE PASSED\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# Run the gate\n",
        "soft_db_sanity_gate(DB_PATH, BASE_DIR, REQUIRED_TABLES)\n",
        "\n",
        "# Optional stop (without raising a traceback)\n",
        "STOP_AFTER_PREFLIGHT = bool(RUN_PREFLIGHT_ONLY)\n",
        "if STOP_AFTER_PREFLIGHT:\n",
        "    print(\"Stopping after pre-flight by configuration (RUN_PREFLIGHT_ONLY=True).\")\n",
        "\n",
        "# CELL 2 / STEP 2 – Document Loading & Chunking\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "83a15f3a",
      "metadata": {
        "id": "83a15f3a"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def load_pdf(file_bytes: bytes) -> str:\n",
        "    reader = PdfReader(io.BytesIO(file_bytes))\n",
        "    texts = []\n",
        "    for page in reader.pages:\n",
        "        try:\n",
        "            txt = page.extract_text() or \"\"\n",
        "        except Exception:\n",
        "            txt = \"\"\n",
        "        texts.append(txt)\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "def load_docx(file_bytes: bytes) -> str:\n",
        "    f = io.BytesIO(file_bytes)\n",
        "    doc = DocxDocument(f)\n",
        "    return \"\\n\".join(p.text for p in doc.paragraphs)\n",
        "\n",
        "def load_txt(file_bytes: bytes, encoding: str = \"utf-8\") -> str:\n",
        "    return file_bytes.decode(encoding, errors=\"ignore\")\n",
        "\n",
        "def load_file_to_text(file_obj) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Accepts either:\n",
        "    - a string filepath (when gr.File(type=\"filepath\") is used), or\n",
        "    - a file-like object with a .name attribute (older behavior).\n",
        "\n",
        "    Returns:\n",
        "      (text_content, original_filename)\n",
        "    \"\"\"\n",
        "    # Case 1: gr.File(type=\"filepath\") -> we get a string path\n",
        "    if isinstance(file_obj, str):\n",
        "        path = file_obj\n",
        "        name = os.path.basename(path)\n",
        "    else:\n",
        "        # Case 2: some object with a .name attribute\n",
        "        path = getattr(file_obj, \"name\", None)\n",
        "        if path is None:\n",
        "            raise ValueError(\"Unsupported file object from uploader.\")\n",
        "        name = os.path.basename(path)\n",
        "\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    lower = name.lower()\n",
        "    if lower.endswith(\".pdf\"):\n",
        "        text = load_pdf(data)\n",
        "    elif lower.endswith(\".docx\"):\n",
        "        text = load_docx(data)\n",
        "    elif lower.endswith(\".txt\"):\n",
        "        text = load_txt(data)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type for {name}\")\n",
        "\n",
        "    return text, name\n",
        "\n",
        "\n",
        "def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:\n",
        "    \"\"\"\n",
        "    Simple sliding-window chunking.\n",
        "    \"\"\"\n",
        "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "    tokens = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(tokens):\n",
        "        end = start + chunk_size\n",
        "        chunk_tokens = tokens[start:end]\n",
        "        chunk = \" \".join(chunk_tokens)\n",
        "        chunks.append(chunk)\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "33831113",
      "metadata": {
        "id": "33831113"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 3 / STEP 3 – Embedding & FAISS Index Helpers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2d0f5c69",
      "metadata": {
        "id": "2d0f5c69"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def embed_texts(\n",
        "    api_key: str,\n",
        "    embed_model: str,\n",
        "    texts: List[str],\n",
        "    batch_size: int = 32,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Embed a list of texts using OpenAI embeddings.\n",
        "    Returns an ndarray of shape (N, D).\n",
        "    \"\"\"\n",
        "    client = build_openai_client(api_key)\n",
        "    resolved_chat, resolved_embed = resolve_models(\"\", embed_model)\n",
        "\n",
        "    vectors: List[List[float]] = []\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i : i + batch_size]\n",
        "        resp = client.embeddings.create(model=resolved_embed, input=batch)\n",
        "        for d in resp.data:\n",
        "            vectors.append(d.embedding)\n",
        "\n",
        "    arr = np.array(vectors, dtype=\"float32\")\n",
        "    return arr\n",
        "\n",
        "def build_faiss_index(vectors: np.ndarray) -> faiss.IndexFlatIP:\n",
        "    \"\"\"\n",
        "    Build a simple inner-product FAISS index from vectors.\n",
        "    \"\"\"\n",
        "    norm = np.linalg.norm(vectors, axis=1, keepdims=True) + 1e-10\n",
        "    normed = vectors / norm\n",
        "    dim = normed.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(normed)\n",
        "    return index\n",
        "\n",
        "def save_index(index: faiss.IndexFlatIP, index_id: str):\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.faiss\")\n",
        "    faiss.write_index(index, path)\n",
        "\n",
        "def load_index(index_id: str) -> faiss.IndexFlatIP:\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.faiss\")\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Index file not found: {path}\")\n",
        "    return faiss.read_index(path)\n",
        "\n",
        "def save_metadata(index_id: str, meta: Dict[str, Any]):\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.pkl\")\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(meta, f)\n",
        "\n",
        "def load_metadata(index_id: str) -> Dict[str, Any]:\n",
        "    path = os.path.join(INDEX_DIR, f\"{index_id}.pkl\")\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Metadata file not found: {path}\")\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "294c8860",
      "metadata": {
        "id": "294c8860"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 4 / STEP 4 – SQLite Persistence for Documents & Cohorts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "9cd6af1c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cd6af1c",
        "outputId": "421b61c7-de37-4916-edef-6df8574eff0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 4 starting with DB_PATH: /content/drive/MyDrive/rag_mvp/rag_documents.db\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import sqlite3\n",
        "from uuid import uuid4\n",
        "\n",
        "assert \"BASE_DIR\" in globals(), \"BASE_DIR is not defined. Run CELL 1 first.\"\n",
        "assert \"DB_PATH\"  in globals(), \"DB_PATH is not defined. Run CELL 1 first.\"\n",
        "print(\"STEP 4 starting with DB_PATH:\", DB_PATH)\n",
        "\n",
        "def get_db_conn():\n",
        "    # Ensure BASE_DIR exists (defined in CELL 1)\n",
        "    os.makedirs(BASE_DIR, exist_ok=True)\n",
        "    # Ensure DB folder exists\n",
        "    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)\n",
        "    return sqlite3.connect(DB_PATH)\n",
        "\n",
        "\n",
        "\n",
        "def ensure_docs_table():\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS documents (\n",
        "            id              TEXT PRIMARY KEY,\n",
        "            doc_name        TEXT NOT NULL,\n",
        "            cohort_name     TEXT NOT NULL,\n",
        "            index_id        TEXT NOT NULL,\n",
        "            n_chunks        INTEGER NOT NULL,\n",
        "            embed_model     TEXT NOT NULL,\n",
        "            created_at      TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def ensure_cohort_table():\n",
        "    \"\"\"\n",
        "    Ensure both:\n",
        "      - cohorts: cohort metadata (required by v16 tests)\n",
        "      - cohort_docs: mapping of cohort_name -> doc_name (used by the app)\n",
        "    \"\"\"\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # ---- New table required by tests ----\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohorts (\n",
        "            id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            name            TEXT NOT NULL UNIQUE,\n",
        "            description     TEXT,\n",
        "            owner_user_id   TEXT,\n",
        "            created_at      TEXT NOT NULL,\n",
        "            updated_at      TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # ---- Existing mapping table (unchanged behavior) ----\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohort_docs (\n",
        "            cohort_name TEXT NOT NULL,\n",
        "            doc_name    TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def list_cohorts() -> List[str]:\n",
        "    # We keep existing behavior: list distinct names from cohort_docs\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"SELECT DISTINCT cohort_name FROM cohort_docs ORDER BY cohort_name ASC\")\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return [r[0] for r in rows]\n",
        "\n",
        "\n",
        "def list_docs_in_cohort(cohort_name: str) -> List[str]:\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT doc_name FROM cohort_docs WHERE cohort_name = ? ORDER BY doc_name ASC\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return [r[0] for r in rows]\n",
        "\n",
        "\n",
        "def add_docs_to_cohort(cohort_name: str, doc_names: List[str]):\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    for dn in doc_names:\n",
        "        cur.execute(\n",
        "            \"INSERT INTO cohort_docs (cohort_name, doc_name) VALUES (?, ?)\",\n",
        "            (cohort_name, dn),\n",
        "        )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def rename_cohort(old_name: str, new_name: str):\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"UPDATE cohort_docs SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "        (new_name, old_name),\n",
        "    )\n",
        "    cur.execute(\n",
        "        \"UPDATE documents SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "        (new_name, old_name),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def delete_cohort(cohort_name: str, reassign_to: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Delete a cohort. If reassign_to is provided, documents move there.\n",
        "    Otherwise, documents are deleted (and their indexes removed).\n",
        "    NOTE: This is intentionally explicit to avoid orphaned docs.\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\n",
        "        \"SELECT id, index_id FROM documents WHERE cohort_name = ?\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    docs = cur.fetchall()\n",
        "\n",
        "    if reassign_to:\n",
        "        # Just move docs\n",
        "        cur.execute(\n",
        "            \"UPDATE documents SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "            (reassign_to, cohort_name),\n",
        "        )\n",
        "        cur.execute(\n",
        "            \"UPDATE cohort_docs SET cohort_name = ? WHERE cohort_name = ?\",\n",
        "            (reassign_to, cohort_name),\n",
        "        )\n",
        "        msg = f\"✅ Cohort '{cohort_name}' renamed/reassigned to '{reassign_to}'. No indexes deleted.\"\n",
        "    else:\n",
        "        # Delete docs and indexes\n",
        "        for doc_id, index_id in docs:\n",
        "            # Remove index & metadata\n",
        "            faiss_path = os.path.join(INDEX_DIR, f\"{index_id}.faiss\")\n",
        "            pkl_path = os.path.join(INDEX_DIR, f\"{index_id}.pkl\")\n",
        "            for p in [faiss_path, pkl_path]:\n",
        "                if os.path.exists(p):\n",
        "                    os.remove(p)\n",
        "            cur.execute(\"DELETE FROM documents WHERE id = ?\", (doc_id,))\n",
        "\n",
        "        cur.execute(\"DELETE FROM cohort_docs WHERE cohort_name = ?\", (cohort_name,))\n",
        "        msg = f\"✅ Cohort '{cohort_name}' and its documents/indexes were deleted.\"\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return msg\n",
        "\n",
        "\n",
        "def register_document(\n",
        "    doc_name: str,\n",
        "    cohort_name: str,\n",
        "    index_id: str,\n",
        "    n_chunks: int,\n",
        "    embed_model: str,\n",
        "):\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    doc_id = str(uuid4())\n",
        "\n",
        "    # ✅ Use dt.datetime (module alias) so the bottom `import datetime`\n",
        "    #    in the self-test cell cannot break this.\n",
        "    created_at = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO documents (id, doc_name, cohort_name, index_id, n_chunks,\n",
        "                               embed_model, created_at)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (doc_id, doc_name, cohort_name, index_id, n_chunks, embed_model, created_at),\n",
        "    )\n",
        "    cur.execute(\n",
        "        \"INSERT INTO cohort_docs (cohort_name, doc_name) VALUES (?, ?)\",\n",
        "        (cohort_name, doc_name),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return doc_id\n",
        "\n",
        "\n",
        "def get_doc_index_id(doc_name: str, cohort_name: str) -> Optional[str]:\n",
        "    ensure_docs_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT index_id\n",
        "        FROM documents\n",
        "        WHERE doc_name = ? AND cohort_name = ?\n",
        "        \"\"\",\n",
        "        (doc_name, cohort_name),\n",
        "    )\n",
        "    row = cur.fetchone()\n",
        "    conn.close()\n",
        "    if row:\n",
        "        return row[0]\n",
        "    return None\n",
        "\n",
        "\n",
        "def list_all_documents() -> List[Tuple[str, str, str]]:\n",
        "    \"\"\"\n",
        "    Return list of (doc_name, cohort_name, created_at).\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT doc_name, cohort_name, created_at FROM documents ORDER BY created_at DESC\"\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "# ------------------------------------------------------------\n",
        "# SCHEMA BOOTSTRAP (ensures required tables exist for tests)\n",
        "# ------------------------------------------------------------\n",
        "ensure_docs_table()\n",
        "ensure_cohort_table()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5d6ae736",
      "metadata": {
        "id": "5d6ae736"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 4.5 / STEP 4.5 – Users & Chat History (7-Day Retention)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "4f19cb13",
      "metadata": {
        "id": "4f19cb13"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import datetime as dt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6ff6ed7f",
      "metadata": {
        "id": "6ff6ed7f"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# USER IDENTITY MODEL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "23dded43",
      "metadata": {
        "id": "23dded43"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SessionUser:\n",
        "    username: str | None = None\n",
        "    role: str = \"anonymous\"   # \"anonymous\", \"user\", \"admin\"\n",
        "\n",
        "    @property\n",
        "    def is_authenticated(self) -> bool:\n",
        "        return bool(self.username and str(self.username).strip()) and self.role in (\"user\", \"admin\")\n",
        "\n",
        "    @property\n",
        "    def is_admin(self) -> bool:\n",
        "        return self.role == \"admin\"\n",
        "\n",
        "\n",
        "def require_login(session_user, action: str = \"access this feature\") -> SessionUser:\n",
        "    \"\"\"Enforce authenticated access (no access for anonymous users).\n",
        "\n",
        "    Accepts SessionUser, dict, or None and returns a normalized SessionUser.\n",
        "    Raises PermissionError if not authenticated.\n",
        "    \"\"\"\n",
        "    if isinstance(session_user, SessionUser):\n",
        "        su = session_user\n",
        "    elif isinstance(session_user, dict):\n",
        "        su = SessionUser(\n",
        "            username=((session_user.get(\"username\") or \"\").strip() or None),\n",
        "            role=(session_user.get(\"role\") or \"anonymous\"),\n",
        "        )\n",
        "    else:\n",
        "        su = SessionUser(username=None, role=\"anonymous\")\n",
        "\n",
        "    if not su.is_authenticated:\n",
        "        raise PermissionError(f\"Login required to {action}.\")\n",
        "    return su\n",
        "\n",
        "# MVP in-memory auth store (will be replaced later by ICAM/SSO)\n",
        "USERS = {\n",
        "    \"admin\": {\"password\": \"admin123\", \"role\": \"admin\"},\n",
        "    \"demo1\":  {\"password\": \"demo1123\",  \"role\": \"user\"},\n",
        "    \"demo2\": {\"password\": \"demo2123\", \"role\": \"user\"},\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a78d2c52",
      "metadata": {
        "id": "a78d2c52"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# USERS TABLE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "aafc96c5",
      "metadata": {
        "id": "aafc96c5"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def ensure_user_table():\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS users (\n",
        "            user_id      TEXT PRIMARY KEY,\n",
        "            display_name TEXT,\n",
        "            role         TEXT,\n",
        "            created_at   TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def upsert_user(user_id: str, role: str, display_name: Optional[str] = None):\n",
        "    \"\"\"\n",
        "    Basic ICAM-ready user record.\n",
        "    Inserts new or updates existing users.\n",
        "    \"\"\"\n",
        "    if not user_id:\n",
        "        return\n",
        "\n",
        "    ensure_user_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    now = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO users (user_id, display_name, role, created_at)\n",
        "        VALUES (?, ?, ?, ?)\n",
        "        ON CONFLICT(user_id) DO UPDATE SET\n",
        "            display_name = COALESCE(?, users.display_name),\n",
        "            role = COALESCE(?, users.role)\n",
        "        \"\"\",\n",
        "        (user_id, display_name, role, now, display_name, role),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4c3b0ebc",
      "metadata": {
        "id": "4c3b0ebc"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# CHAT HISTORY TABLE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e5b8902b",
      "metadata": {
        "id": "e5b8902b"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def ensure_chat_history_table():\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS chat_history (\n",
        "            id             INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            user_id        TEXT,\n",
        "            role           TEXT,\n",
        "            cohort_name    TEXT,\n",
        "            original_query TEXT,\n",
        "            improved_query TEXT,\n",
        "            which_prompt   TEXT,\n",
        "            answer         TEXT,\n",
        "            chat_model     TEXT,\n",
        "            created_at     TEXT NOT NULL\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7fcd485d",
      "metadata": {
        "id": "7fcd485d"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# 7-DAY RETENTION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "96b1f821",
      "metadata": {
        "id": "96b1f821"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def prune_chat_history(days: int = 7):\n",
        "    ensure_chat_history_table()\n",
        "    cutoff = dt.datetime.now(dt.timezone.utc) - dt.timedelta(days=days)\n",
        "    cutoff_iso = cutoff.isoformat()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"DELETE FROM chat_history WHERE created_at < ?\", (cutoff_iso,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7e702f19",
      "metadata": {
        "id": "7e702f19"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# v14 BEHAVIOR: Save Chat Interaction (DETAILED LOGGING)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "9b7bc50e",
      "metadata": {
        "id": "9b7bc50e"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def save_chat_interaction(\n",
        "    user_id: str,\n",
        "    role: str,\n",
        "    cohort_name: str,\n",
        "    original_query: str,\n",
        "    improved_query: str,\n",
        "    which_prompt: str,\n",
        "    answer: str,\n",
        "    chat_model: str,\n",
        "):\n",
        "    \"\"\"\n",
        "    This is your existing v16 logging mechanism.\n",
        "    Now fully preserved and compatible with v16.\n",
        "    \"\"\"\n",
        "    ensure_chat_history_table()\n",
        "    prune_chat_history(days=7)\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    now = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO chat_history (\n",
        "            user_id, role, cohort_name, original_query, improved_query,\n",
        "            which_prompt, answer, chat_model, created_at\n",
        "        )\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (\n",
        "            user_id or None,\n",
        "            role or None,\n",
        "            cohort_name or None,\n",
        "            original_query,\n",
        "            improved_query,\n",
        "            which_prompt,\n",
        "            answer,\n",
        "            chat_model,\n",
        "            now,\n",
        "        ),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5c3ec5bc",
      "metadata": {
        "id": "5c3ec5bc"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# v16 REQUIRED FUNCTIONS – FLEXIBLE SIGNATURES\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "6d9085b8",
      "metadata": {
        "id": "6d9085b8"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def _extract_user_id(user: Any) -> str:\n",
        "    \"\"\"\n",
        "    Helper to derive a stable user_id from various representations.\n",
        "    \"\"\"\n",
        "    if user is None:\n",
        "        return \"anonymous\"\n",
        "\n",
        "    # dict-like\n",
        "    if isinstance(user, dict):\n",
        "        for key in (\"username\", \"user_id\", \"name\"):\n",
        "            v = user.get(key)\n",
        "            if v:\n",
        "                return str(v)\n",
        "\n",
        "    # attribute-based (SessionUser or other objects)\n",
        "    for attr in (\"username\", \"user_id\", \"name\"):\n",
        "        try:\n",
        "            v = getattr(user, attr, None)\n",
        "            if v:\n",
        "                return str(v)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # mapping-like (sqlite3.Row, etc.)\n",
        "    try:\n",
        "        for key in (\"username\", \"user_id\", \"name\"):\n",
        "            if key in user:\n",
        "                v = user[key]\n",
        "                if v:\n",
        "                    return str(v)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return \"anonymous\"\n",
        "\n",
        "\n",
        "def save_chat_history(\n",
        "    messages=None,\n",
        "    *args,\n",
        "    user: Any = None,\n",
        "    user_id: Optional[str] = None,\n",
        "    cohort_name: str = \"default\",\n",
        "    cohort: Optional[str] = None,\n",
        "    **kwargs,\n",
        "):\n",
        "    \"\"\"\n",
        "    v16 Test Suite Requirement:\n",
        "    Supports BOTH:\n",
        "      1) save_chat_history(messages=[{role, content}, ...], user=..., cohort=...)\n",
        "      2) save_chat_history(user=..., cohort=..., question=\"Q\", answer=\"A\", model_used=\"...\")\n",
        "\n",
        "    In (2) we write a single row using the Q/A fields.\n",
        "    \"\"\"\n",
        "    ensure_chat_history_table()\n",
        "    prune_chat_history(days=7)\n",
        "\n",
        "    # Normalize cohort alias\n",
        "    if cohort is not None:\n",
        "        cohort_name = cohort\n",
        "\n",
        "    # Derive user_id if needed\n",
        "    if user_id is None:\n",
        "        user_id = _extract_user_id(user)\n",
        "\n",
        "    # ---- Path 1: test-style call with question/answer/model_used ----\n",
        "    question = kwargs.get(\"question\")\n",
        "    answer = kwargs.get(\"answer\")\n",
        "    model_used = kwargs.get(\"model_used\")\n",
        "\n",
        "    if messages is None and (question is not None or answer is not None):\n",
        "        now = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "        conn = get_db_conn()\n",
        "        cur = conn.cursor()\n",
        "\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            INSERT INTO chat_history (\n",
        "                user_id, role, cohort_name, original_query,\n",
        "                improved_query, which_prompt, answer,\n",
        "                chat_model, created_at\n",
        "            )\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            \"\"\",\n",
        "            (\n",
        "                user_id,          # user_id\n",
        "                \"user\",           # role\n",
        "                cohort_name,      # cohort_name\n",
        "                question or \"\",   # original_query\n",
        "                None,             # improved_query\n",
        "                None,             # which_prompt\n",
        "                answer or \"\",     # answer\n",
        "                model_used,       # chat_model\n",
        "                now,              # created_at\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        return  # We're done for this style of call\n",
        "\n",
        "    # ---- Path 2: normal messages-based usage ----\n",
        "    if messages is None:\n",
        "        messages = kwargs.get(\"messages\", None)\n",
        "\n",
        "    # If still no messages, treat as no-op\n",
        "    if messages is None:\n",
        "        return\n",
        "\n",
        "    now = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    for m in messages:\n",
        "        role = m.get(\"role\", \"user\")\n",
        "        content = m.get(\"content\", \"\")\n",
        "\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            INSERT INTO chat_history (\n",
        "                user_id, role, cohort_name, original_query,\n",
        "                improved_query, which_prompt, answer,\n",
        "                chat_model, created_at\n",
        "            )\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            \"\"\",\n",
        "            (\n",
        "                user_id,\n",
        "                role,\n",
        "                cohort_name,\n",
        "                content,   # original_query\n",
        "                None,\n",
        "                None,\n",
        "                None,\n",
        "                None,\n",
        "                now,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "\n",
        "def load_chat_history(\n",
        "    *args,\n",
        "    **kwargs,\n",
        "):\n",
        "    \"\"\"\n",
        "    v16 Test Suite Requirement:\n",
        "    Returns list[dict] with keys: role, content, created_at.\n",
        "\n",
        "    For simplicity and maximum compatibility with the tests,\n",
        "    we ignore user/cohort filters here and just return the\n",
        "    oldest messages up to `limit`.\n",
        "    \"\"\"\n",
        "    ensure_chat_history_table()\n",
        "\n",
        "    limit = int(kwargs.get(\"limit\", 50))\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT role, original_query, created_at\n",
        "        FROM chat_history\n",
        "        ORDER BY created_at ASC\n",
        "        LIMIT ?\n",
        "        \"\"\",\n",
        "        (limit,),\n",
        "    )\n",
        "\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return [\n",
        "        {\"role\": r[0], \"content\": r[1], \"created_at\": r[2]}\n",
        "        for r in rows\n",
        "    ]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f4222705",
      "metadata": {
        "id": "f4222705"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# RECENT HISTORY (Admin screens / Debug UI)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "6d4a9420",
      "metadata": {
        "id": "6d4a9420"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def get_recent_history(\n",
        "    user_id: Optional[str] = None,\n",
        "    cohort_name: Optional[str] = None,\n",
        "    limit: int = 50,\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Returns full detailed history rows for admin/debug views.\n",
        "    \"\"\"\n",
        "    ensure_chat_history_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    query = \"\"\"\n",
        "        SELECT user_id, role, cohort_name, original_query, improved_query,\n",
        "               which_prompt, answer, chat_model, created_at\n",
        "        FROM chat_history\n",
        "    \"\"\"\n",
        "    params = []\n",
        "    conditions = []\n",
        "\n",
        "    if user_id:\n",
        "        conditions.append(\"user_id = ?\")\n",
        "        params.append(user_id)\n",
        "    if cohort_name:\n",
        "        conditions.append(\"cohort_name = ?\")\n",
        "        params.append(cohort_name)\n",
        "\n",
        "    if conditions:\n",
        "        query += \" WHERE \" + \" AND \".join(conditions)\n",
        "\n",
        "    query += \" ORDER BY created_at DESC LIMIT ?\"\n",
        "    params.append(limit)\n",
        "\n",
        "    cur.execute(query, params)\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return [\n",
        "        {\n",
        "            \"user_id\": r[0],\n",
        "            \"role\": r[1],\n",
        "            \"cohort_name\": r[2],\n",
        "            \"original_query\": r[3],\n",
        "            \"improved_query\": r[4],\n",
        "            \"which_prompt\": r[5],\n",
        "            \"answer\": r[6],\n",
        "            \"chat_model\": r[7],\n",
        "            \"created_at\": r[8],\n",
        "        }\n",
        "        for r in rows\n",
        "    ]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "18a0ab3c",
      "metadata": {
        "id": "18a0ab3c"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# ADMIN: LIST USERS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "05c60b12",
      "metadata": {
        "id": "05c60b12"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def list_users() -> List[Tuple[str, str, str]]:\n",
        "    ensure_user_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"SELECT user_id, display_name, role FROM users ORDER BY created_at DESC\")\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n",
        "# CELL 4.6 / STEP 4.6 – Audit Log (v16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "bd81da32",
      "metadata": {
        "id": "bd81da32"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def ensure_audit_table():\n",
        "    \"\"\"\n",
        "    Create an audit_log table if it doesn't already exist.\n",
        "    \"\"\"\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS audit_log (\n",
        "            id        INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            ts        TEXT NOT NULL,\n",
        "            username  TEXT,\n",
        "            role      TEXT,\n",
        "            action    TEXT NOT NULL,\n",
        "            details   TEXT\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def log_audit(username: str, role: str, action: str, details: str = \"\"):\n",
        "    \"\"\"\n",
        "    Insert a row into the audit_log table.\n",
        "    - ts: UTC ISO timestamp\n",
        "    - username / role: may be None/empty for anonymous\n",
        "    - action: short code, e.g. 'login', 'ask', 'admin_refresh', 'delete_cohort'\n",
        "    - details: freeform string with context\n",
        "    \"\"\"\n",
        "    ensure_audit_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Use the global datetime alias `dt` so we don't conflict with any\n",
        "    # later \"import datetime\" inside the self-test cell.\n",
        "    now = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO audit_log (ts, username, role, action, details)\n",
        "        VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (now, username or \"\", role or \"\", action, details or \"\"),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def trace_log(message: str):\n",
        "    \"\"\"\n",
        "    Append a timestamped debug line to debug_trace_v16.log in BASE_DIR.\n",
        "\n",
        "    Used to capture errors/warnings that happen inside Gradio callbacks\n",
        "    where the UI might just show a generic 'Error'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        ts = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "    except Exception:\n",
        "        ts = \"UNKNOWN_TIME\"\n",
        "\n",
        "    line = f\"{ts} {message}\\n\"\n",
        "    try:\n",
        "        with open(TRACE_LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(line)\n",
        "    except Exception as e:\n",
        "        # Last resort: don't let logging itself crash anything\n",
        "        print(\"TRACE_LOG_ERROR\", e, line)\n",
        "\n",
        "\n",
        "\n",
        "import traceback as _tb\n",
        "\n",
        "def safe_ui_call(fn, fallback=None):\n",
        "    \"\"\"Wrap a Gradio callback so exceptions don't surface as generic 'Error' UI outputs.\n",
        "    Writes full traceback to trace_log() and returns a safe fallback value.\n",
        "    \"\"\"\n",
        "    if fallback is None:\n",
        "        fallback = \"❌ An internal error occurred. See debug trace log.\"\n",
        "    def _wrapped(*args, **kwargs):\n",
        "        try:\n",
        "            return fn(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            try:\n",
        "                trace_log(f\"[UI ERROR] {getattr(fn, '__name__', 'callback')}: {e}\\n{_tb.format_exc()}\")\n",
        "            except Exception:\n",
        "                pass\n",
        "            return fallback\n",
        "    return _wrapped\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ef855062",
      "metadata": {
        "id": "ef855062"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# STEP 4.7 – Cohort Ownership & Sharing (v16-safe)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "159ef2a1",
      "metadata": {
        "id": "159ef2a1"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "def ensure_cohort_meta_table():\n",
        "    \"\"\"\n",
        "    Metadata for cohorts (v16_1 Phase 1):\n",
        "      - owner_user_id: who created/owns the cohort (REQUIRED)\n",
        "      - is_shared: 0 = private to owner/admin, 1 = visible to all authenticated users\n",
        "      - allow_clone: 0 = non-owners cannot clone, 1 = cloning enabled for authenticated users (when shared)\n",
        "      - created_ts: UTC timestamp\n",
        "\n",
        "    Notes:\n",
        "      - Performs a lightweight schema migration if cohort_meta already exists.\n",
        "    \"\"\"\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Create base table if missing\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS cohort_meta (\n",
        "            cohort_name    TEXT PRIMARY KEY,\n",
        "            owner_user_id  TEXT,\n",
        "            is_shared      INTEGER DEFAULT 0,\n",
        "            created_ts     TEXT\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # ---- Schema migration (add allow_clone if missing) ----\n",
        "    try:\n",
        "        cur.execute(\"PRAGMA table_info(cohort_meta)\")\n",
        "        cols = {r[1] for r in cur.fetchall()}  # r[1] = column name\n",
        "        if \"allow_clone\" not in cols:\n",
        "            cur.execute(\"ALTER TABLE cohort_meta ADD COLUMN allow_clone INTEGER DEFAULT 0\")\n",
        "    except Exception as e:\n",
        "        # Do not hard-fail cohort operations due to migration issues\n",
        "        trace_log(f\"ensure_cohort_meta_table migration warning: {e}\")\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def _extract_username_from_user(user: SessionUser | dict | None) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Helper: accept SessionUser, dict, or None and pull out a username string.\n",
        "    \"\"\"\n",
        "    if user is None:\n",
        "        return None\n",
        "\n",
        "    # If SessionUser dataclass\n",
        "    if isinstance(user, SessionUser):\n",
        "        return user.username\n",
        "\n",
        "    # If dict-like\n",
        "    if isinstance(user, dict):\n",
        "        # Try common keys in order\n",
        "        for k in (\"username\", \"user_id\", \"name\"):\n",
        "            try:\n",
        "                v = user.get(k)\n",
        "                if v:\n",
        "                    return str(v)\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def set_cohort_owner(cohort_name: str, user: SessionUser | dict | None):\n",
        "    \"\"\"\n",
        "    Register the owner of a cohort, but do NOT change it once set.\n",
        "\n",
        "    HARD REQUIREMENT (v16_1 Phase 1 security):\n",
        "      - Cohorts must have an authenticated owner.\n",
        "      - We do NOT silently fall back to \"anonymous\".\n",
        "\n",
        "    Behavior:\n",
        "      - On first creation: insert owner_user_id and is_shared=0 (private).\n",
        "      - On subsequent calls for the same cohort_name: owner remains unchanged.\n",
        "    \"\"\"\n",
        "    if not cohort_name:\n",
        "        return\n",
        "\n",
        "    from datetime import datetime, timezone\n",
        "\n",
        "    owner = _extract_username_from_user(user)\n",
        "    if not owner or not str(owner).strip() or str(owner).strip().lower() == \"anonymous\":\n",
        "        raise ValueError(\"Cohort owner is required. Please log in before creating/updating a cohort.\")\n",
        "\n",
        "\n",
        "    ensure_cohort_meta_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    now = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    # Insert cohort_meta row if missing; if it already exists with an invalid owner, repair the owner once.\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO cohort_meta (cohort_name, owner_user_id, is_shared, created_ts)\n",
        "        VALUES (?, ?, 0, ?)\n",
        "        ON CONFLICT(cohort_name) DO UPDATE SET\n",
        "            owner_user_id = excluded.owner_user_id\n",
        "        WHERE cohort_meta.owner_user_id IS NULL\n",
        "           OR TRIM(cohort_meta.owner_user_id) = ''\n",
        "           OR LOWER(TRIM(cohort_meta.owner_user_id)) = 'anonymous'\n",
        "        \"\"\",\n",
        "        (cohort_name, owner, now),\n",
        "    )\n",
        "\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def set_cohort_sharing(cohort_name: str, is_shared: bool | int):\n",
        "    \"\"\"\n",
        "    Update ONLY the is_shared flag for a cohort in cohort_meta.\n",
        "\n",
        "    is_shared:\n",
        "        False/0 -> private (owner + admins)\n",
        "        True/1  -> shared (all users can see; non-owners are read-only)\n",
        "    \"\"\"\n",
        "    if not cohort_name:\n",
        "        return\n",
        "\n",
        "    ensure_cohort_meta_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    shared_flag = 1 if is_shared else 0\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        UPDATE cohort_meta\n",
        "        SET is_shared = ?\n",
        "        WHERE cohort_name = ?\n",
        "        \"\"\",\n",
        "        (shared_flag, cohort_name),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def set_cohort_clone_allowed(cohort_name: str, allow_clone: bool | int):\n",
        "    \"\"\"\n",
        "    Update ONLY the allow_clone flag for a cohort in cohort_meta.\n",
        "\n",
        "    allow_clone:\n",
        "        False/0 -> non-owners cannot clone (even if shared)\n",
        "        True/1  -> if shared, any authenticated user may clone\n",
        "    \"\"\"\n",
        "    if not cohort_name:\n",
        "        return\n",
        "\n",
        "    ensure_cohort_meta_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    flag = 1 if allow_clone else 0\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        UPDATE cohort_meta\n",
        "        SET allow_clone = ?\n",
        "        WHERE cohort_name = ?\n",
        "        \"\"\",\n",
        "        (flag, cohort_name),\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def set_cohort_allow_clone(cohort_name: str, allow_clone: bool) -> None:\n",
        "    \"\"\"\n",
        "    Backward-compatible alias for older call sites.\n",
        "    \"\"\"\n",
        "    return set_cohort_clone_allowed(cohort_name, allow_clone)\n",
        "\n",
        "\n",
        "#def set_cohort_clone_allowed(cohort_name: str, allow_clone: bool | int):\n",
        "#    \"\"\"Backward-compatible alias for earlier UI code.\"\"\"\n",
        "#    return set_cohort_clone_allowed(cohort_name, allow_clone)\n",
        "\n",
        "def _get_cohort_meta(cohort_name: str) -> tuple[str | None, int, int]:\n",
        "    \"\"\"\n",
        "    Returns (owner_user_id, is_shared, allow_clone).\n",
        "    If cohort not found in meta, returns (None, 0, 0).\n",
        "    \"\"\"\n",
        "    ensure_cohort_meta_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT owner_user_id, COALESCE(is_shared,0), COALESCE(allow_clone,0) FROM cohort_meta WHERE cohort_name = ?\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    row = cur.fetchone()\n",
        "    conn.close()\n",
        "    if not row:\n",
        "        return None, 0, 0\n",
        "    return (row[0], int(row[1] or 0), int(row[2] or 0))\n",
        "\n",
        "\n",
        "def can_clone_cohort(session_user: Any, source_cohort: str) -> tuple[bool, str | None]:\n",
        "    \"\"\"\n",
        "    Returns (allowed, message_if_denied).\n",
        "\n",
        "    Rules (Option A):\n",
        "      - Admin: may always clone.\n",
        "      - Owner: may always clone.\n",
        "      - Other authenticated users:\n",
        "          * allowed ONLY if source cohort is_shared=1 AND allow_clone=1\n",
        "      - Anonymous: not allowed.\n",
        "    \"\"\"\n",
        "    if not source_cohort:\n",
        "        return False, \"❌ Please select a cohort to clone.\"\n",
        "\n",
        "    username = _extract_user_id(session_user)\n",
        "    if not username or username == \"anonymous\":\n",
        "        return False, \"❌ You must be logged in to clone a cohort.\"\n",
        "\n",
        "    # Determine admin role\n",
        "    role = None\n",
        "    if isinstance(session_user, dict):\n",
        "        role = session_user.get(\"role\")\n",
        "    elif isinstance(session_user, SessionUser):\n",
        "        role = \"admin\" if session_user.is_admin else \"user\"\n",
        "    else:\n",
        "        role = USERS.get(username, {}).get(\"role\", \"user\")\n",
        "\n",
        "    if role == \"admin\":\n",
        "        return True, None\n",
        "\n",
        "    owner, is_shared, allow_clone = _get_cohort_meta(source_cohort)\n",
        "\n",
        "    # Owner may always clone\n",
        "    if owner and owner == username:\n",
        "        return True, None\n",
        "\n",
        "    # Non-owner: only if shared + cloning allowed\n",
        "    if is_shared == 1 and allow_clone == 1:\n",
        "        return True, None\n",
        "\n",
        "    return False, \"❌ Cloning is not permitted for this cohort (owner has disabled cloning).\"\n",
        "\n",
        "\n",
        "def clone_cohort(source_cohort: str, target_cohort: str, new_owner: str) -> str:\n",
        "    \"\"\"\n",
        "    Clone a cohort by duplicating its document rows and index artifacts.\n",
        "\n",
        "    Implementation notes:\n",
        "      - We copy each source FAISS index (.faiss) and metadata (.pkl) to a new index_id.\n",
        "      - We create new rows in documents and cohort_docs for the target cohort.\n",
        "      - The cloned cohort is created as PRIVATE by default (is_shared=0, allow_clone=0).\n",
        "    \"\"\"\n",
        "    if not source_cohort or not target_cohort:\n",
        "        return \"❌ Source and target cohort names are required.\"\n",
        "\n",
        "    if not new_owner or not str(new_owner).strip() or str(new_owner).strip().lower() == \"anonymous\":\n",
        "        return \"❌ You must be logged in to clone a cohort (owner is required).\"\n",
        "\n",
        "\n",
        "    target_cohort = target_cohort.strip()\n",
        "    if cohort_exists(target_cohort):\n",
        "        return f\"❌ Target cohort '{target_cohort}' already exists. Choose a different name.\"\n",
        "\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    ensure_cohort_meta_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\n",
        "        \"SELECT doc_name, index_id, n_chunks, embed_model FROM documents WHERE cohort_name = ?\",\n",
        "        (source_cohort,),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "\n",
        "    if not rows:\n",
        "        conn.close()\n",
        "        return f\"❌ Source cohort '{source_cohort}' has no documents to clone.\"\n",
        "\n",
        "    created_at = dt.datetime.now(dt.timezone.utc).isoformat()\n",
        "\n",
        "    # Create a meta row for the new cohort (private by default)\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO cohort_meta (cohort_name, owner_user_id, is_shared, allow_clone, created_ts)\n",
        "        VALUES (?, ?, 0, 0, ?)\n",
        "        ON CONFLICT(cohort_name) DO NOTHING\n",
        "        \"\"\",\n",
        "        (target_cohort, (new_owner or \"\").strip(), created_at),\n",
        "    )\n",
        "\n",
        "    cloned_count = 0\n",
        "    for (doc_name, src_index_id, n_chunks, embed_model) in rows:\n",
        "        new_index_id = str(uuid4())\n",
        "\n",
        "        # Copy FAISS + PKL artifacts to new ids\n",
        "        src_faiss = os.path.join(INDEX_DIR, f\"{src_index_id}.faiss\")\n",
        "        src_pkl = os.path.join(INDEX_DIR, f\"{src_index_id}.pkl\")\n",
        "        dst_faiss = os.path.join(INDEX_DIR, f\"{new_index_id}.faiss\")\n",
        "        dst_pkl = os.path.join(INDEX_DIR, f\"{new_index_id}.pkl\")\n",
        "\n",
        "        if not os.path.exists(src_faiss) or not os.path.exists(src_pkl):\n",
        "            trace_log(f\"clone_cohort warning: missing artifacts for index_id={src_index_id}\")\n",
        "            continue\n",
        "\n",
        "        shutil.copyfile(src_faiss, dst_faiss)\n",
        "        shutil.copyfile(src_pkl, dst_pkl)\n",
        "\n",
        "        # Insert new document row\n",
        "        new_doc_id = str(uuid4())\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            INSERT INTO documents (id, doc_name, cohort_name, index_id, n_chunks, embed_model, created_at)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "            \"\"\",\n",
        "            (new_doc_id, doc_name, target_cohort, new_index_id, int(n_chunks), embed_model, created_at),\n",
        "        )\n",
        "\n",
        "        # Map doc to cohort_docs\n",
        "        cur.execute(\n",
        "            \"INSERT INTO cohort_docs (cohort_name, doc_name) VALUES (?, ?)\",\n",
        "            (target_cohort, doc_name),\n",
        "        )\n",
        "\n",
        "        cloned_count += 1\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    return f\"✅ Cloned cohort '{source_cohort}' into '{target_cohort}' with {cloned_count} documents.\"\n",
        "\n",
        "\n",
        "def cohort_exists(cohort_name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Returns True if a cohort with this name already exists in cohort_docs.\n",
        "    This is global (not per-user) to avoid confusing duplicate names.\n",
        "    \"\"\"\n",
        "    if not cohort_name:\n",
        "        return False\n",
        "\n",
        "    ensure_cohort_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"SELECT 1 FROM cohort_docs WHERE cohort_name = ? LIMIT 1\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    row = cur.fetchone()\n",
        "    conn.close()\n",
        "    return row is not None\n",
        "\n",
        "\n",
        "def list_cohorts_for_user(user: SessionUser | dict | None) -> list[str]:\n",
        "    \"\"\"\n",
        "    Return list of cohort names visible to the given user.\n",
        "\n",
        "    Rules:\n",
        "      - Admins: all cohorts (global)\n",
        "      - Non-admin:\n",
        "          * Cohorts where they are owner (cohort_meta.owner_user_id)\n",
        "          * Cohorts marked is_shared = 1\n",
        "      - Anonymous: only shared cohorts (is_shared = 1)\n",
        "\n",
        "    If anything goes wrong with the metadata logic, falls back to global list_cohorts().\n",
        "    Also writes debug info to the v16 trace log.\n",
        "    \"\"\"\n",
        "    trace_log(f\"list_cohorts_for_user called with user={user!r}\")\n",
        "\n",
        "    ensure_cohort_table()\n",
        "    ensure_cohort_meta_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    try:\n",
        "        # Determine if user is admin, safely\n",
        "        is_admin = False\n",
        "        username = None\n",
        "\n",
        "        if isinstance(user, SessionUser):\n",
        "            is_admin = user.is_admin\n",
        "            username = user.username\n",
        "        elif isinstance(user, dict):\n",
        "            username = _extract_username_from_user(user)\n",
        "            role = user.get(\"role\")\n",
        "            is_admin = (role == \"admin\")\n",
        "\n",
        "        if is_admin:\n",
        "            # Admin sees all distinct cohorts\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                SELECT DISTINCT cohort_name\n",
        "                FROM cohort_docs\n",
        "                ORDER BY cohort_name\n",
        "                \"\"\"\n",
        "            )\n",
        "        else:\n",
        "            # Non-admin or anonymous\n",
        "            if username:\n",
        "                # Logged-in non-admin -> owner or shared\n",
        "                cur.execute(\n",
        "                    \"\"\"\n",
        "                    SELECT DISTINCT cd.cohort_name\n",
        "                    FROM cohort_docs cd\n",
        "                    LEFT JOIN cohort_meta cm\n",
        "                      ON cd.cohort_name = cm.cohort_name\n",
        "                    WHERE cm.owner_user_id = ?\n",
        "                       OR cm.is_shared = 1\n",
        "                       OR cm.cohort_name IS NULL   -- safety: cohorts without meta still appear\n",
        "                    ORDER BY cd.cohort_name\n",
        "                    \"\"\",\n",
        "                    (username,),\n",
        "                )\n",
        "            else:\n",
        "                # Anonymous -> only shared (or cohorts w/o meta as a fallback)\n",
        "                cur.execute(\n",
        "                    \"\"\"\n",
        "                    SELECT DISTINCT cd.cohort_name\n",
        "                    FROM cohort_docs cd\n",
        "                    LEFT JOIN cohort_meta cm\n",
        "                      ON cd.cohort_name = cm.cohort_name\n",
        "                    WHERE cm.is_shared = 1\n",
        "                       OR cm.cohort_name IS NULL\n",
        "                    ORDER BY cd.cohort_name\n",
        "                    \"\"\"\n",
        "                )\n",
        "\n",
        "        rows = cur.fetchall()\n",
        "        conn.close()\n",
        "        names = [r[0] for r in rows]\n",
        "\n",
        "        # Final safety net: do not leak global cohorts; return empty.\n",
        "        if not names:\n",
        "            trace_log(\"list_cohorts_for_user -> no rows; returning empty\")\n",
        "            names = []\n",
        "\n",
        "        trace_log(f\"list_cohorts_for_user returning {names}\")\n",
        "        return names\n",
        "\n",
        "    except Exception as e:\n",
        "        conn.close()\n",
        "        trace_log(f\"list_cohorts_for_user ERROR: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# UI HELPERS FOR COHORT LISTS (used in STEP 10)\n",
        "# ------------------------------------------------------------\n",
        "\n",
        "def get_cohorts_for_user(username: Optional[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Convenience wrapper for the Gradio UI:\n",
        "    take a simple username string and delegate to list_cohorts_for_user().\n",
        "\n",
        "    Also logs to the v16 trace file for easier debugging of Refresh Cohorts.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        trace_log(f\"get_cohorts_for_user called with username={username!r}\")\n",
        "\n",
        "        if not username or not str(username).strip():\n",
        "            # No anonymous access: callers must be logged in.\n",
        "            return []\n",
        "        role = USERS.get(username, {}).get(\"role\", \"user\")\n",
        "        user = SessionUser(username=str(username).strip(), role=role)\n",
        "\n",
        "        names = list_cohorts_for_user(user)\n",
        "        trace_log(f\"get_cohorts_for_user returning {names}\")\n",
        "        return names\n",
        "\n",
        "    except Exception as e:\n",
        "        trace_log(f\"get_cohorts_for_user ERROR for username={username!r}: {e}\")\n",
        "        # No anonymous fallback; return empty to avoid leaking data.\n",
        "        return []\n",
        "\n",
        "\n",
        "\n",
        "def get_all_cohorts() -> List[List[str]]:\n",
        "    \"\"\"\n",
        "    For the Admin tab: return [[cohort_name, owner], ...].\n",
        "    \"\"\"\n",
        "    ensure_cohort_table()\n",
        "    ensure_cohort_meta_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT cd.cohort_name,\n",
        "               COALESCE(cm.owner_user_id, 'unknown') AS owner\n",
        "        FROM cohort_docs cd\n",
        "        LEFT JOIN cohort_meta cm\n",
        "          ON cd.cohort_name = cm.cohort_name\n",
        "        GROUP BY cd.cohort_name\n",
        "        ORDER BY cd.cohort_name\n",
        "        \"\"\"\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    return [[name, owner] for (name, owner) in rows]\n",
        "\n",
        "def get_allowed_setup_actions(current_user_dict: dict | None) -> tuple[list[str], str, str, bool]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      - action_choices\n",
        "      - action_value (safe default)\n",
        "      - info_message\n",
        "      - info_visible\n",
        "    \"\"\"\n",
        "    # Build a SessionUser safely\n",
        "    if not current_user_dict or not current_user_dict.get(\"username\"):\n",
        "        user_obj = SessionUser(username=None, role=\"anonymous\")\n",
        "    else:\n",
        "        user_obj = SessionUser(\n",
        "            username=current_user_dict[\"username\"],\n",
        "            role=current_user_dict.get(\"role\", \"user\"),\n",
        "        )\n",
        "\n",
        "    # Determine if clone is possible for this user\n",
        "    cloneable = list_cloneable_shared_cohorts_for_user(user_obj)  # you already have / can add this helper\n",
        "\n",
        "    choices = [ACTION_CREATE, ACTION_APPEND]\n",
        "    msg = \"\"\n",
        "    visible = False\n",
        "\n",
        "    if cloneable:\n",
        "        choices.append(ACTION_CLONE)\n",
        "    else:\n",
        "        # “Greyed out” effect: omit the choice entirely\n",
        "        msg = (\n",
        "            \"Clone is unavailable because no shared cohorts have been marked as clone-eligible for your account.\\n\\n\"\n",
        "            \"Ask the cohort owner (or an admin) to enable **Allow cloning** on a shared cohort.\"\n",
        "        )\n",
        "        visible = True\n",
        "\n",
        "    # Always return a valid selection (prevents the ValueError you hit on logout)\n",
        "    return choices, DEFAULT_ACTION, msg, visible\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "fbd137db",
      "metadata": {
        "id": "fbd137db"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# CELL 4.7 / STEP 4.7 – Demo Prompts (v16.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "9a95e42f",
      "metadata": {
        "id": "9a95e42f"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# Supports \"demo mode\" cohorts by storing curated prompt questions in SQLite.\n",
        "# Prompts can be preloaded via admin file upload (CSV/TXT/JSON).\n",
        "\n",
        "def ensure_demo_prompts_table():\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS demo_prompts (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            cohort_name TEXT NOT NULL,\n",
        "            prompt_text TEXT NOT NULL,\n",
        "            sort_order INTEGER DEFAULT 0,\n",
        "            created_at TEXT DEFAULT (datetime('now'))\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    cur.execute(\"CREATE INDEX IF NOT EXISTS idx_demo_prompts_cohort ON demo_prompts(cohort_name)\")\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def clear_demo_prompts_for_cohort(cohort_name: str):\n",
        "    ensure_demo_prompts_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\"DELETE FROM demo_prompts WHERE cohort_name = ?\", (cohort_name,))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "def list_demo_prompts_for_cohort(cohort_name: str) -> list[str]:\n",
        "    ensure_demo_prompts_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT prompt_text\n",
        "        FROM demo_prompts\n",
        "        WHERE cohort_name = ?\n",
        "        ORDER BY COALESCE(sort_order,0), id\n",
        "        \"\"\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "    return [r[0] for r in rows if r and r[0]]\n",
        "\n",
        "def upsert_demo_prompts_for_cohort(cohort_name: str, prompts: list[str], replace: bool = True) -> int:\n",
        "    \"\"\"\n",
        "    Insert demo prompts for a cohort. If replace=True, clears existing prompts first.\n",
        "    Returns number of prompts inserted.\n",
        "    \"\"\"\n",
        "    ensure_demo_prompts_table()\n",
        "    cohort = (cohort_name or \"\").strip()\n",
        "    if not cohort:\n",
        "        return 0\n",
        "\n",
        "    cleaned: list[str] = []\n",
        "    seen: set[str] = set()\n",
        "    for p in (prompts or []):\n",
        "        t = (p or \"\").strip()\n",
        "        if not t:\n",
        "            continue\n",
        "        if t in seen:\n",
        "            continue\n",
        "        seen.add(t)\n",
        "        cleaned.append(t)\n",
        "\n",
        "    if replace:\n",
        "        clear_demo_prompts_for_cohort(cohort)\n",
        "\n",
        "    if not cleaned:\n",
        "        return 0\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    for i, t in enumerate(cleaned, start=1):\n",
        "        cur.execute(\n",
        "            \"INSERT INTO demo_prompts (cohort_name, prompt_text, sort_order) VALUES (?,?,?)\",\n",
        "            (cohort, t, i),\n",
        "        )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return len(cleaned)\n",
        "\n",
        "def parse_demo_prompts_file(file_path: str) -> list[str]:\n",
        "    \"\"\"\n",
        "    Parse demo prompts from a local file path.\n",
        "    Supported:\n",
        "      - .txt: one question per line (blank lines ignored)\n",
        "      - .csv: one prompt per line OR header with columns 'prompt'/'question'/'text'\n",
        "      - .json: either list[str] or {\"prompts\":[...]}\n",
        "    \"\"\"\n",
        "    if not file_path:\n",
        "        return []\n",
        "    fp = str(file_path)\n",
        "    ext = os.path.splitext(fp)[1].lower()\n",
        "    try:\n",
        "        with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            raw = f.read()\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "    if ext == \".json\":\n",
        "        try:\n",
        "            obj = json.loads(raw)\n",
        "            if isinstance(obj, list):\n",
        "                return [str(x) for x in obj]\n",
        "            if isinstance(obj, dict) and isinstance(obj.get(\"prompts\"), list):\n",
        "                return [str(x) for x in obj.get(\"prompts\")]\n",
        "        except Exception:\n",
        "            return []\n",
        "        return []\n",
        "\n",
        "    lines = [ln.strip() for ln in raw.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\").split(\"\\n\")]\n",
        "    lines = [ln for ln in lines if ln]\n",
        "\n",
        "    if ext == \".txt\":\n",
        "        return lines\n",
        "\n",
        "    if ext == \".csv\":\n",
        "        if not lines:\n",
        "            return []\n",
        "        header = [h.strip().strip('\"').strip(\"'\").lower() for h in lines[0].split(\",\")]\n",
        "        if any(h in (\"prompt\", \"question\", \"text\") for h in header):\n",
        "            col_idx = None\n",
        "            for k in (\"prompt\", \"question\", \"text\"):\n",
        "                if k in header:\n",
        "                    col_idx = header.index(k)\n",
        "                    break\n",
        "            out = []\n",
        "            for row in lines[1:]:\n",
        "                parts = [p.strip().strip('\"').strip(\"'\") for p in row.split(\",\")]\n",
        "                if col_idx is not None and col_idx < len(parts):\n",
        "                    out.append(parts[col_idx])\n",
        "            return out\n",
        "        # no header: each row is a prompt (first column)\n",
        "        out = []\n",
        "        for row in lines:\n",
        "            parts = [p.strip().strip('\"').strip(\"'\") for p in row.split(\",\")]\n",
        "            if parts and parts[0]:\n",
        "                out.append(parts[0])\n",
        "        return out\n",
        "\n",
        "    return lines\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "25c17c4f",
      "metadata": {
        "id": "25c17c4f"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 5.0 / STEP 5.0 – Model Registry Core (v16_1, with schema migration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "47fa3934",
      "metadata": {
        "id": "47fa3934"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "import sqlite3\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "def ensure_model_registry_table():\n",
        "    \"\"\"\n",
        "    Ensure the model_registry table exists with the v6_15 schema.\n",
        "    If an older schema is detected (missing model_id or other key fields),\n",
        "    we DROP and recreate the table.\n",
        "\n",
        "    This is safe for the MVP since we don't rely on persistent custom models yet.\n",
        "    \"\"\"\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Does the table exist?\n",
        "    cur.execute(\n",
        "        \"SELECT name FROM sqlite_master WHERE type='table' AND name='model_registry'\"\n",
        "    )\n",
        "    row = cur.fetchone()\n",
        "\n",
        "    if row:\n",
        "        # Table exists – inspect its columns\n",
        "        cur.execute(\"PRAGMA table_info(model_registry)\")\n",
        "        cols_info = cur.fetchall()\n",
        "        existing_cols = {c[1] for c in cols_info}  # c[1] is the column name\n",
        "\n",
        "        required_cols = {\n",
        "            \"provider\",\n",
        "            \"model_id\",\n",
        "            \"display_name\",\n",
        "            \"model_type\",\n",
        "            \"enabled\",\n",
        "            \"is_default\",\n",
        "            \"cost_score\",\n",
        "            \"latency_score\",\n",
        "            \"max_context_tokens\",\n",
        "            \"api_base\",\n",
        "            \"notes\",\n",
        "        }\n",
        "\n",
        "        # If the key v16 columns are missing, drop and recreate\n",
        "        if not required_cols.issubset(existing_cols):\n",
        "            print(\"DEBUG: model_registry schema mismatch detected. Dropping old table.\")\n",
        "            cur.execute(\"DROP TABLE IF EXISTS model_registry\")\n",
        "            conn.commit()\n",
        "\n",
        "    # (Re)create the table with the correct v16 schema\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS model_registry (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            provider TEXT,\n",
        "            model_id TEXT,\n",
        "            display_name TEXT,\n",
        "            model_type TEXT,\n",
        "            enabled INTEGER DEFAULT 1,\n",
        "            is_default INTEGER DEFAULT 0,\n",
        "            cost_score INTEGER DEFAULT 2,\n",
        "            latency_score INTEGER DEFAULT 2,\n",
        "            max_context_tokens INTEGER,\n",
        "            api_base TEXT,\n",
        "            notes TEXT\n",
        "        )\n",
        "        \"\"\"\n",
        "    )\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def seed_default_models():\n",
        "    \"\"\"\n",
        "    Seed the registry with standard defaults if empty.\n",
        "    \"\"\"\n",
        "    ensure_model_registry_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM model_registry\")\n",
        "    count = cur.fetchone()[0]\n",
        "\n",
        "    if count == 0:\n",
        "        defaults = [\n",
        "            # Default Chat Model\n",
        "            {\n",
        "                \"provider\": \"openai\",\n",
        "                \"model_id\": \"gpt-4.1-mini\",\n",
        "                \"display_name\": \"GPT-4.1 Mini\",\n",
        "                \"model_type\": \"chat\",\n",
        "                \"enabled\": 1,\n",
        "                \"is_default\": 1,\n",
        "                \"cost_score\": 1,\n",
        "                \"latency_score\": 1,\n",
        "                \"max_context_tokens\": 128_000,\n",
        "                \"api_base\": None,\n",
        "                \"notes\": \"Primary chat model\",\n",
        "            },\n",
        "            # Default Embedding Model\n",
        "            {\n",
        "                \"provider\": \"openai\",\n",
        "                \"model_id\": \"text-embedding-3-small\",\n",
        "                \"display_name\": \"text-embedding-3-small\",\n",
        "                \"model_type\": \"embed\",\n",
        "                \"enabled\": 1,\n",
        "                \"is_default\": 1,\n",
        "                \"cost_score\": 1,\n",
        "                \"latency_score\": 1,\n",
        "                \"max_context_tokens\": None,\n",
        "                \"api_base\": None,\n",
        "                \"notes\": \"Primary embedding model\",\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        for row in defaults:\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                INSERT INTO model_registry (\n",
        "                    provider, model_id, display_name, model_type,\n",
        "                    enabled, is_default, cost_score, latency_score,\n",
        "                    max_context_tokens, api_base, notes\n",
        "                )\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "                \"\"\",\n",
        "                (\n",
        "                    row[\"provider\"],\n",
        "                    row[\"model_id\"],\n",
        "                    row[\"display_name\"],\n",
        "                    row[\"model_type\"],\n",
        "                    row[\"enabled\"],\n",
        "                    row[\"is_default\"],\n",
        "                    row[\"cost_score\"],\n",
        "                    row[\"latency_score\"],\n",
        "                    row[\"max_context_tokens\"],\n",
        "                    row[\"api_base\"],\n",
        "                    row[\"notes\"],\n",
        "                ),\n",
        "            )\n",
        "\n",
        "        conn.commit()\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def list_models(model_type: str | None = None, only_enabled: bool = True) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Return raw dict rows from the model_registry table.\n",
        "\n",
        "    Args:\n",
        "        model_type: 'chat', 'embed', etc. (optional)\n",
        "        only_enabled: filter to enabled == 1\n",
        "    \"\"\"\n",
        "    ensure_model_registry_table()\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    sql = \"\"\"\n",
        "        SELECT provider, model_id, display_name, model_type,\n",
        "               enabled, is_default, cost_score, latency_score,\n",
        "               max_context_tokens, api_base, notes\n",
        "        FROM model_registry\n",
        "        WHERE 1=1\n",
        "    \"\"\"\n",
        "    params: list[Any] = []\n",
        "\n",
        "    if model_type:\n",
        "        sql += \" AND model_type = ?\"\n",
        "        params.append(model_type)\n",
        "\n",
        "    if only_enabled:\n",
        "        sql += \" AND enabled = 1\"\n",
        "\n",
        "    sql += \" ORDER BY model_type, is_default DESC, model_id\"\n",
        "\n",
        "    cur.execute(sql, params)\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    keys = [\n",
        "        \"provider\", \"model_id\", \"display_name\", \"model_type\", \"enabled\",\n",
        "        \"is_default\", \"cost_score\", \"latency_score\", \"max_context_tokens\",\n",
        "        \"api_base\", \"notes\",\n",
        "    ]\n",
        "\n",
        "    return [dict(zip(keys, r)) for r in rows]\n",
        "def load_model_registry() -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Loads all models from the registry and ensures defaults exist.\n",
        "    \"\"\"\n",
        "    ensure_model_registry_table()\n",
        "    seed_default_models()  # <-- CRITICAL LINE (missing previously)\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT\n",
        "            id,\n",
        "            provider,\n",
        "            model_id,\n",
        "            model_id AS model,          -- backward compatibility\n",
        "            display_name,\n",
        "            model_type AS type,         -- backward compatibility\n",
        "            enabled,\n",
        "            is_default,\n",
        "            cost_score,\n",
        "            latency_score,\n",
        "            max_context_tokens,\n",
        "            api_base,\n",
        "            notes\n",
        "        FROM model_registry\n",
        "        ORDER BY model_type, is_default DESC, model_id\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    rows = [dict(r) for r in cur.fetchall()]\n",
        "    conn.close()\n",
        "    return rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "57c1cdee",
      "metadata": {
        "id": "57c1cdee"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 5.1 / STEP 5.1 – ModelConfig & Lookup Helpers (v16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8649be61",
      "metadata": {
        "id": "8649be61"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, List, Dict, Any\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    model_id: str\n",
        "    provider: str = \"openai\"\n",
        "    display_name: str | None = None\n",
        "    model_type: str = \"chat\"   # 'chat', 'embed', 'rerank', etc.\n",
        "    is_default: bool = False\n",
        "    enabled: bool = True\n",
        "    cost_score: int = 2\n",
        "    latency_score: int = 2\n",
        "    max_context_tokens: int | None = None\n",
        "    api_base: str | None = None\n",
        "    notes: str | None = None\n",
        "\n",
        "    def as_kwargs(self) -> dict:\n",
        "        \"\"\"\n",
        "        Common kwargs we might pass into a client, e.g. OpenAI.\n",
        "        For now this is mostly for future extensibility.\n",
        "        \"\"\"\n",
        "        kw = {\"model\": self.model_id}\n",
        "        if self.api_base:\n",
        "            kw[\"api_base\"] = self.api_base\n",
        "        return kw\n",
        "\n",
        "\n",
        "def load_model_configs(model_type: str, only_enabled: bool = True) -> list[ModelConfig]:\n",
        "    \"\"\"\n",
        "    Load models from the registry as ModelConfig objects.\n",
        "    Relies on list_models(...) from STEP 5.0.\n",
        "    \"\"\"\n",
        "    rows = list_models(model_type=model_type, only_enabled=only_enabled)\n",
        "    configs: list[ModelConfig] = []\n",
        "    for row in rows:\n",
        "        configs.append(\n",
        "            ModelConfig(\n",
        "                model_id=row[\"model_id\"],\n",
        "                provider=row[\"provider\"],\n",
        "                display_name=row[\"display_name\"],\n",
        "                model_type=row[\"model_type\"],\n",
        "                is_default=row[\"is_default\"],\n",
        "                enabled=row[\"enabled\"],\n",
        "                cost_score=row[\"cost_score\"],\n",
        "                latency_score=row[\"latency_score\"],\n",
        "                max_context_tokens=row[\"max_context_tokens\"],\n",
        "                api_base=row[\"api_base\"],\n",
        "                notes=row[\"notes\"],\n",
        "            )\n",
        "        )\n",
        "    return configs\n",
        "\n",
        "\n",
        "def get_default_model(model_type: str) -> Optional[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Low-level helper used by the *Config() helpers below.\n",
        "\n",
        "    Looks in the model_registry for the default model of a given type.\n",
        "    Strategy:\n",
        "      1) Use list_models(model_type, only_enabled=True)\n",
        "      2) Return the one where is_default = True, if present\n",
        "      3) Otherwise return the first enabled model\n",
        "      4) If none exist, return None\n",
        "    \"\"\"\n",
        "    rows = list_models(model_type=model_type, only_enabled=True)\n",
        "    if not rows:\n",
        "        return None\n",
        "\n",
        "    for row in rows:\n",
        "        if row.get(\"is_default\"):\n",
        "            return row\n",
        "\n",
        "    # Fallback: first enabled of that type\n",
        "    return rows[0]\n",
        "\n",
        "\n",
        "def get_default_chat_model_config() -> ModelConfig:\n",
        "    \"\"\"\n",
        "    Returns a ModelConfig for the default chat model.\n",
        "    If none is explicitly set, falls back to the first enabled chat model.\n",
        "    \"\"\"\n",
        "    default_row = get_default_model(\"chat\")\n",
        "    if default_row:\n",
        "        return ModelConfig(\n",
        "            model_id=default_row[\"model_id\"],\n",
        "            provider=default_row[\"provider\"],\n",
        "            display_name=default_row[\"display_name\"],\n",
        "            model_type=default_row[\"model_type\"],\n",
        "            is_default=default_row[\"is_default\"],\n",
        "            enabled=default_row[\"enabled\"],\n",
        "            cost_score=default_row[\"cost_score\"],\n",
        "            latency_score=default_row[\"latency_score\"],\n",
        "            max_context_tokens=default_row[\"max_context_tokens\"],\n",
        "            api_base=default_row[\"api_base\"],\n",
        "            notes=default_row[\"notes\"],\n",
        "        )\n",
        "\n",
        "    # Fallback: first enabled chat model\n",
        "    configs = load_model_configs(\"chat\", only_enabled=True)\n",
        "    if configs:\n",
        "        return configs[0]\n",
        "\n",
        "    # Last resort hard-coded default (should not happen due to seeding)\n",
        "    return ModelConfig(\n",
        "        model_id=\"gpt-4.1-mini\",\n",
        "        provider=\"openai\",\n",
        "        display_name=\"GPT-4.1 Mini (fallback)\",\n",
        "        model_type=\"chat\",\n",
        "        is_default=True,\n",
        "        enabled=True,\n",
        "        cost_score=1,\n",
        "        latency_score=1,\n",
        "        max_context_tokens=128_000,\n",
        "    )\n",
        "\n",
        "\n",
        "def get_default_embed_model_config() -> ModelConfig:\n",
        "    \"\"\"\n",
        "    Returns a ModelConfig for the default embedding model.\n",
        "    \"\"\"\n",
        "    default_row = get_default_model(\"embed\")\n",
        "    if default_row:\n",
        "        return ModelConfig(\n",
        "            model_id=default_row[\"model_id\"],\n",
        "            provider=default_row[\"provider\"],\n",
        "            display_name=default_row[\"display_name\"],\n",
        "            model_type=default_row[\"model_type\"],\n",
        "            is_default=default_row[\"is_default\"],\n",
        "            enabled=default_row[\"enabled\"],\n",
        "            cost_score=default_row[\"cost_score\"],\n",
        "            latency_score=default_row[\"latency_score\"],\n",
        "            max_context_tokens=default_row[\"max_context_tokens\"],\n",
        "            api_base=default_row[\"api_base\"],\n",
        "            notes=default_row[\"notes\"],\n",
        "        )\n",
        "\n",
        "    # Fallback: first enabled embed model\n",
        "    configs = load_model_configs(\"embed\", only_enabled=True)\n",
        "    if configs:\n",
        "        return configs[0]\n",
        "\n",
        "    # Last resort hard-coded default\n",
        "    return ModelConfig(\n",
        "        model_id=\"text-embedding-3-small\",\n",
        "        provider=\"openai\",\n",
        "        display_name=\"text-embedding-3-small (fallback)\",\n",
        "        model_type=\"embed\",\n",
        "        is_default=True,\n",
        "        enabled=True,\n",
        "        cost_score=1,\n",
        "        latency_score=1,\n",
        "    )\n",
        "def list_chat_models() -> List[str]:\n",
        "    models = load_model_registry()\n",
        "    return [m[\"model_id\"] for m in models if m[\"type\"] == \"chat\" and m[\"enabled\"]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "49184be9",
      "metadata": {
        "id": "49184be9"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 5.2 / STEP 5.2 – RAG Retrieval Over a Cohort (v16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "a4d978ae",
      "metadata": {
        "id": "a4d978ae"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def build_context_from_index(\n",
        "    api_key: str,\n",
        "    chat_model: str,\n",
        "    embed_model: str,\n",
        "    cohort_name: str,\n",
        "    query: str,\n",
        "    top_k: int = 5,\n",
        "):\n",
        "    \"\"\"\n",
        "    Given a cohort and query:\n",
        "    - Load all documents for that cohort\n",
        "    - For each doc's index, perform similarity search\n",
        "    - Aggregate top_k results across docs\n",
        "    Returns:\n",
        "      - concatenated context string\n",
        "      - list of (doc_name, rank, score) for citations\n",
        "    \"\"\"\n",
        "\n",
        "    ensure_docs_table()\n",
        "    resolved_chat, resolved_embed = resolve_models(chat_model, embed_model)\n",
        "    client = build_openai_client(api_key)\n",
        "\n",
        "    # 1. Load all docs & their index references\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT doc_name, index_id\n",
        "        FROM documents\n",
        "        WHERE cohort_name = ?\n",
        "        \"\"\",\n",
        "        (cohort_name,),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    if not rows:\n",
        "        return \"\", []\n",
        "\n",
        "    # 2. Embed query once\n",
        "    q_embed_resp = client.embeddings.create(model=resolved_embed, input=[query])\n",
        "    q_vec = np.array(q_embed_resp.data[0].embedding, dtype=\"float32\")\n",
        "    q_vec = q_vec / (np.linalg.norm(q_vec) + 1e-10)\n",
        "\n",
        "    all_hits = []  # (doc_name, idx, score, text)\n",
        "\n",
        "    # 3. Perform similarity search in each doc index\n",
        "    for doc_name, index_id in rows:\n",
        "        try:\n",
        "            index = load_index(index_id)\n",
        "            meta = load_metadata(index_id)  # {\"chunks\": [...]}\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        D, I = index.search(q_vec[np.newaxis, :], top_k)\n",
        "        scores = D[0]\n",
        "        idxs = I[0]\n",
        "\n",
        "        for score, idx in zip(scores, idxs):\n",
        "            if idx < 0:\n",
        "                continue\n",
        "            chunks = meta.get(\"chunks\", [])\n",
        "            if idx >= len(chunks):\n",
        "                continue\n",
        "            text_chunk = chunks[idx]\n",
        "            all_hits.append((doc_name, idx, float(score), text_chunk))\n",
        "\n",
        "    if not all_hits:\n",
        "        return \"\", []\n",
        "\n",
        "    # 4. Sort & select top results\n",
        "    all_hits.sort(key=lambda x: x[2], reverse=True)\n",
        "    top_hits = all_hits[:top_k]\n",
        "\n",
        "    context_parts = []\n",
        "    citations = []\n",
        "\n",
        "    for rank, (doc_name, idx, score, text) in enumerate(top_hits, start=1):\n",
        "        header = f\"[{rank}] From {doc_name} (chunk #{idx}, score={score:.3f})\"\n",
        "        context_parts.append(header + \"\\n\" + text)\n",
        "        citations.append((doc_name, rank, score))\n",
        "\n",
        "    context = \"\\n\\n\".join(context_parts)\n",
        "    return context, citations\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "33cf61b7",
      "metadata": {
        "id": "33cf61b7"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "# UPDATED answer_with_rag() — Now uses Routing Brain (v16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "8be1d6ae",
      "metadata": {
        "id": "8be1d6ae"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def answer_with_rag(\n",
        "    api_key: str,\n",
        "    chat_model: str,          # kept for backward compatibility\n",
        "    embed_model: str,         # still used for embedding queries\n",
        "    cohort_name: str,\n",
        "    query: str,\n",
        "    system_prompt: str = \"\",\n",
        "    user_pref: str | None = None,  # NEW: allows override from UI\n",
        "):\n",
        "    \"\"\"\n",
        "    Perform RAG retrieval and return:\n",
        "        - answer_markdown\n",
        "        - raw_answer_text\n",
        "        - model_used (for history & UI display)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Build RAG context\n",
        "    context, citations = build_context_from_index(\n",
        "        api_key, chat_model, embed_model, cohort_name, query\n",
        "    )\n",
        "\n",
        "    if not context:\n",
        "        return (\n",
        "            \"I could not find any context for this query in the selected cohort.\",\n",
        "            \"\",\n",
        "            \"N/A\",\n",
        "        )\n",
        "\n",
        "    # 2. Default system prompt\n",
        "    if not system_prompt:\n",
        "        system_prompt = (\n",
        "            \"You are a helpful assistant answering questions based on the provided context.\\n\"\n",
        "            \"If the answer cannot be found in the context, say you do not know.\"\n",
        "        )\n",
        "\n",
        "    # 3. Construct chat messages\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                \"Use ONLY the context below to answer the question.\\n\\n\"\n",
        "                \"=== CONTEXT START ===\\n\"\n",
        "                f\"{context}\\n\"\n",
        "                \"=== CONTEXT END ===\\n\\n\"\n",
        "                f\"QUESTION: {query}\"\n",
        "            ),\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # 4. Call the routing brain — NEW for v16\n",
        "    answer_text, raw_answer_text, model_used = call_chat_model(\n",
        "        api_key=api_key,\n",
        "        messages=messages,\n",
        "        task_type=\"rag_answer\",\n",
        "        user_pref=user_pref,          # user-selected override (optional)\n",
        "        context_size=len(context),    # helps routing choose large/small models\n",
        "    )\n",
        "\n",
        "    # 5. Build answer markdown with citations + model info\n",
        "    md = answer_text + \"\\n\\n---\\n\\n**Cited sources:**\\n\"\n",
        "    for doc_name, rank, score in citations:\n",
        "        md += f\"- [{rank}] `{doc_name}` (score={score:.3f})\\n\"\n",
        "\n",
        "    md += f\"\\n\\n**Model Used:** `{model_used}`\\n\"\n",
        "\n",
        "    return md, raw_answer_text, model_used\n",
        "def answer_question_over_cohort(api_key, username, cohort_name, question, model_id):\n",
        "    \"\"\"\n",
        "    Wrapper for the RAG retrieval + LLM step.\n",
        "    Must exist BEFORE STEP 10.\n",
        "    \"\"\"\n",
        "    trace_log(\n",
        "        f\"answer_question_over_cohort called user={username}, cohort={cohort_name}\"\n",
        "    )\n",
        "\n",
        "    embed_cfg = get_default_embed_model_config()\n",
        "    embed_model = embed_cfg.model_id\n",
        "\n",
        "    answer_md, raw_answer, used_model = answer_with_rag(\n",
        "        api_key=api_key,\n",
        "        chat_model=model_id,\n",
        "        embed_model=embed_model,\n",
        "        cohort_name=cohort_name,\n",
        "        query=question,\n",
        "        system_prompt=\"\",\n",
        "        user_pref=model_id,  # routed through routing brain\n",
        "    )\n",
        "\n",
        "    return answer_md, raw_answer, used_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "1561e7e5",
      "metadata": {
        "id": "1561e7e5"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 6 / STEP 6 – Build Cohort from Uploaded Docs (v16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "717e62aa",
      "metadata": {
        "id": "717e62aa"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "def build_cohort_from_files(\n",
        "    api_key: str,\n",
        "    embed_model: str,\n",
        "    cohort_name: str,\n",
        "    files: List[Any],\n",
        ") -> str:\n",
        "    \"\"\"Ingest a list of uploaded files into a *single* cohort.\n",
        "\n",
        "    For each file we:\n",
        "      - load the text\n",
        "      - chunk it\n",
        "      - embed with the given embedding model\n",
        "      - build & save a FAISS index\n",
        "      - save metadata (including the chunks)\n",
        "      - register the document in the SQLite `documents` table\n",
        "\n",
        "    Returns a human-readable summary string for the UI.\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    os.makedirs(INDEX_DIR, exist_ok=True)\n",
        "\n",
        "    success_count = 0\n",
        "    total_chunks = 0\n",
        "    messages: List[str] = []\n",
        "\n",
        "    for file_obj in files:\n",
        "        try:\n",
        "            # 1) Load text & derive a stable doc_name\n",
        "            text, doc_name = load_file_to_text(file_obj)\n",
        "            if not text or not text.strip():\n",
        "                messages.append(f\"⚠️ {doc_name}: no extractable text, skipped.\")\n",
        "                continue\n",
        "\n",
        "            # 2) Chunk\n",
        "            chunks = chunk_text(text)\n",
        "            if not chunks:\n",
        "                messages.append(f\"⚠️ {doc_name}: produced 0 chunks, skipped.\")\n",
        "                continue\n",
        "\n",
        "            # 3) Embed\n",
        "            vectors = embed_texts(\n",
        "                api_key=api_key,\n",
        "                embed_model=embed_model,\n",
        "                texts=chunks,\n",
        "            )\n",
        "\n",
        "            # 4) Build FAISS index\n",
        "            index = build_faiss_index(vectors)\n",
        "\n",
        "            # 5) Save index & metadata\n",
        "            index_id = str(uuid4())\n",
        "            save_index(index, index_id)\n",
        "\n",
        "            meta = {\n",
        "                \"cohort_name\": cohort_name,\n",
        "                \"doc_name\": doc_name,\n",
        "                \"chunks\": chunks,\n",
        "                \"embed_model\": embed_model,\n",
        "            }\n",
        "            save_metadata(index_id, meta)\n",
        "\n",
        "            # 6) Register in SQLite\n",
        "            register_document(\n",
        "                doc_name=doc_name,\n",
        "                cohort_name=cohort_name,\n",
        "                index_id=index_id,\n",
        "                n_chunks=len(chunks),\n",
        "                embed_model=embed_model,\n",
        "            )\n",
        "\n",
        "            success_count += 1\n",
        "            total_chunks += len(chunks)\n",
        "            messages.append(f\"✅ {doc_name}: {len(chunks)} chunks embedded.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Best-effort error capture per-file\n",
        "            name = getattr(file_obj, \"name\", str(file_obj))\n",
        "            messages.append(f\"❌ {name}: {e}\")\n",
        "\n",
        "    if success_count == 0:\n",
        "        detail = \"\\n\".join(messages) if messages else \"\"\n",
        "        return \"❌ No documents were successfully processed.\" + (f\"\\n{detail}\" if detail else \"\")\n",
        "\n",
        "    summary = (\n",
        "        f\"✅ Built cohort '{cohort_name}' with {success_count} document(s) \"\n",
        "        f\"and {total_chunks} total chunks.\"\n",
        "    )\n",
        "    if messages:\n",
        "        summary += \"\\n\" + \"\\n\".join(messages)\n",
        "    return summary\n",
        "\n",
        "\n",
        "def build_cohort_index(\n",
        "    api_key: str,\n",
        "    cohort_name: str,\n",
        "    files: List[Any],\n",
        "    owner: Optional[str] = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    High-level helper used by the Gradio UI (v16):\n",
        "\n",
        "      - Selects default embedding model (from model registry)\n",
        "      - Builds the cohort\n",
        "      - Stores cohort ownership\n",
        "    \"\"\"\n",
        "    if not api_key or not api_key.strip():\n",
        "        return \"❌ OpenAI API key is required.\"\n",
        "\n",
        "    if not cohort_name or not cohort_name.strip():\n",
        "        return \"❌ Cohort name is required.\"\n",
        "\n",
        "    if (not owner) or (not str(owner).strip()) or (str(owner).strip().lower() in (\"anonymous\",\"none\",\"null\")):\n",
        "        return \"❌ You must be logged in to create a cohort (owner is required).\"\n",
        "\n",
        "    if not files:\n",
        "        return \"❌ Please upload at least one file.\"\n",
        "\n",
        "    # ✔️ NEW — correct default embedding model call\n",
        "    embed_cfg = get_default_embed_model_config()\n",
        "    embed_model = embed_cfg.model_id\n",
        "\n",
        "    # Build FAISS index + metadata\n",
        "    result_msg = build_cohort_from_files(\n",
        "        api_key=api_key,\n",
        "        embed_model=embed_model,\n",
        "        cohort_name=cohort_name.strip(),\n",
        "        files=files,\n",
        "    )\n",
        "\n",
        "    # Save cohort owner metadata (required)\n",
        "\n",
        "\n",
        "    # Save cohort owner metadata (required)\n",
        "    try:\n",
        "        role = USERS.get(owner, {}).get(\"role\", \"user\")\n",
        "        user_obj = SessionUser(username=str(owner).strip(), role=role)\n",
        "        set_cohort_owner(cohort_name.strip(), user_obj)\n",
        "    except Exception as e:\n",
        "        trace_log(f\"build_cohort_index set_cohort_owner ERROR: {e}\")\n",
        "        return f\"❌ Failed to set cohort owner (cohort will not be treated as valid): {e}\"\n",
        "\n",
        "    return result_msg\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "799a7087",
      "metadata": {
        "id": "799a7087"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 6.1 / STEP 6.1 – Routing Brain (v16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "374e5789",
      "metadata": {
        "id": "374e5789"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "#\n",
        "# Centralized model selection + wrapper for ALL chat LLM calls.\n",
        "# Uses the model_registry table (STEP 5.0) and supports:\n",
        "#   - task_type hints (\"question_improve\", \"rag_answer\", \"summary\", \"admin\")\n",
        "#   - optional user_pref override (a specific model_id)\n",
        "#   - dry_run flag for automated self-tests (no API call made)\n",
        "#\n",
        "# Functions:\n",
        "#   - select_chat_model(task_type, context_size, user_pref)\n",
        "#   - call_chat_model(api_key, messages, task_type, user_pref, context_size, dry_run)\n",
        "\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "\n",
        "def select_chat_model(\n",
        "    task_type: str,\n",
        "    context_size: int = 0,\n",
        "    user_pref: str | None = None,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Decide which chat model_id to use based on:\n",
        "      - user_pref: explicit override from UI\n",
        "      - registry defaults (is_default)\n",
        "      - task_type and context_size (reserved for future heuristics)\n",
        "\n",
        "    Returns:\n",
        "        model_id (e.g., \"gpt-4.1-mini\")\n",
        "    \"\"\"\n",
        "    # Load enabled chat models as ModelConfig objects\n",
        "    configs = load_model_configs(\"chat\", only_enabled=True)\n",
        "\n",
        "    # Fallback if registry is empty or misconfigured\n",
        "    if not configs:\n",
        "        return \"gpt-4.1-mini\"\n",
        "\n",
        "    # 1. If user_pref matches a known enabled model_id, honor it\n",
        "    if user_pref:\n",
        "        for cfg in configs:\n",
        "            if cfg.model_id == user_pref:\n",
        "                return cfg.model_id\n",
        "\n",
        "    # 2. Prefer the model marked as default\n",
        "    for cfg in configs:\n",
        "        if cfg.is_default:\n",
        "            return cfg.model_id\n",
        "\n",
        "    # 3. Simple heuristic placeholder:\n",
        "    #    For now we ignore task_type/context_size and just use the first enabled.\n",
        "    return configs[0].model_id\n",
        "\n",
        "\n",
        "\n",
        "def call_chat_model(\n",
        "    api_key: str,\n",
        "    messages: List[Dict[str, Any]],\n",
        "    task_type: str,\n",
        "    user_pref: str | None = None,\n",
        "    context_size: int = 0,\n",
        "    dry_run: bool = False,\n",
        ") -> Tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    Wrapper for ALL chat LLM calls in the app.\n",
        "\n",
        "    Args:\n",
        "        api_key:      OpenAI API key\n",
        "        messages:     Chat completion messages\n",
        "        task_type:    Semantic label for routing (e.g. 'rag_answer', 'question_improve')\n",
        "        user_pref:    Optional explicit model_id override\n",
        "        context_size: Approx size of context (chars) to inform routing\n",
        "        dry_run:      If True, DO NOT call the API (used by self-tests).\n",
        "\n",
        "    Returns:\n",
        "        (answer_text, raw_answer_text, model_used)\n",
        "    \"\"\"\n",
        "    model_id = select_chat_model(\n",
        "        task_type=task_type,\n",
        "        context_size=context_size,\n",
        "        user_pref=user_pref,\n",
        "    )\n",
        "\n",
        "    # For automated self-tests: don't hit the API\n",
        "    if dry_run:\n",
        "        dummy = f\"[DRY RUN] task_type={task_type}, model_id={model_id}\"\n",
        "        return dummy, dummy, model_id\n",
        "\n",
        "    client = build_openai_client(api_key)\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model_id,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        max_tokens=900,\n",
        "    )\n",
        "\n",
        "    answer_text = resp.choices[0].message.content.strip()\n",
        "    # In this MVP, raw_answer_text == answer_text, but we keep both for future transforms\n",
        "    raw_answer_text = answer_text\n",
        "\n",
        "    return answer_text, raw_answer_text, model_id\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "3e8175c9",
      "metadata": {
        "id": "3e8175c9"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 7 / STEP 7 – Admin Helpers (Stats & Maintenance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "c3cf30ec",
      "metadata": {
        "id": "c3cf30ec"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def get_db_stats() -> str:\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    ensure_user_table()\n",
        "    ensure_chat_history_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM documents\")\n",
        "    n_docs = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(DISTINCT cohort_name) FROM cohort_docs\")\n",
        "    n_cohorts = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM users\")\n",
        "    n_users = cur.fetchone()[0]\n",
        "\n",
        "    cur.execute(\"SELECT COUNT(*) FROM chat_history\")\n",
        "    n_chats = cur.fetchone()[0]\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    return (\n",
        "        f\"**DB Stats**\\n\\n\"\n",
        "        f\"- Documents: {n_docs}\\n\"\n",
        "        f\"- Cohorts: {n_cohorts}\\n\"\n",
        "        f\"- Users: {n_users}\\n\"\n",
        "        f\"- Chat records (last 7 days enforced on write): {n_chats}\\n\"\n",
        "    )\n",
        "\n",
        "def describe_users() -> str:\n",
        "    rows = list_users()\n",
        "    if not rows:\n",
        "        return \"No users have been recorded yet.\"\n",
        "    lines = [\"**Known Users**\\n\"]\n",
        "    for user_id, display_name, role in rows:\n",
        "        disp = display_name or \"(no display name)\"\n",
        "        r = role or \"(no role)\"\n",
        "        lines.append(f\"- `{user_id}` – {disp} – role: `{r}`\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def describe_cohorts() -> str:\n",
        "    \"\"\"\n",
        "    Returns a markdown summary of cohorts, including:\n",
        "      - name\n",
        "      - owner\n",
        "      - visibility (private/shared)\n",
        "      - document count\n",
        "    \"\"\"\n",
        "    ensure_docs_table()\n",
        "    ensure_cohort_table()\n",
        "    ensure_cohort_meta_table()\n",
        "\n",
        "    conn = get_db_conn()\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT DISTINCT\n",
        "            cd.cohort_name,\n",
        "            COALESCE(cm.owner_user_id, '(none)') AS owner,\n",
        "            COALESCE(cm.is_shared, 0)            AS is_shared,\n",
        "            COUNT(DISTINCT cd.doc_name)          AS num_docs\n",
        "        FROM cohort_docs cd\n",
        "        LEFT JOIN cohort_meta cm\n",
        "          ON cd.cohort_name = cm.cohort_name\n",
        "        GROUP BY cd.cohort_name, owner, is_shared\n",
        "        ORDER BY cd.cohort_name\n",
        "        \"\"\"\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    if not rows:\n",
        "        return \"No cohorts found.\"\n",
        "\n",
        "    lines = [\"**Cohorts**\", \"\"]\n",
        "    for name, owner, is_shared, num_docs in rows:\n",
        "        share_label = \"shared\" if is_shared else \"private\"\n",
        "        lines.append(\n",
        "            f\"- **{name}** — owner: `{owner}`, visibility: {share_label}, docs: {num_docs}\"\n",
        "        )\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "13c8a26c",
      "metadata": {
        "id": "13c8a26c"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 8 / STEP 8 – Prompt Coach (Optional Query Improvement) – v16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "85ca15c2",
      "metadata": {
        "id": "85ca15c2"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "#\n",
        "# Uses the v16 Routing Brain (call_chat_model) instead of calling OpenAI directly.\n",
        "# Signature is kept the same so STEP 10's on_improve_query(...) still works:\n",
        "#     improve_query(api_key, chat_model, original_query)\n",
        "#\n",
        "# In a future step, we can optionally add a user-selected model override and\n",
        "# pass it into call_chat_model(user_pref=...).\n",
        "\n",
        "def improve_query(\n",
        "    api_key: str,\n",
        "    chat_model: str,       # kept for backward compatibility; routing ignores it\n",
        "    original_query: str,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Prompt coach to re-write the user's query for better RAG retrieval.\n",
        "\n",
        "    Behavior:\n",
        "    - If the original query is empty/whitespace, returns \"\".\n",
        "    - Otherwise, uses the Routing Brain (task_type='question_improve') to pick\n",
        "      an appropriate chat model and rewrite the question to be clearer, more\n",
        "      explicit, and RAG-friendly.\n",
        "    \"\"\"\n",
        "    if not original_query.strip():\n",
        "        return \"\"\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are a prompt coach helping the user improve questions for a RAG system. \"\n",
        "        \"Rewrite the query to be explicit, concise, and focused on key details. \"\n",
        "        \"Preserve the user's intent but remove ambiguity, vague pronouns, and \"\n",
        "        \"unnecessary filler. Return ONLY the improved query text.\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": original_query},\n",
        "    ]\n",
        "\n",
        "    # Use the v16 Routing Brain instead of calling OpenAI directly\n",
        "    improved, _, model_used = call_chat_model(\n",
        "        api_key=api_key,\n",
        "        messages=messages,\n",
        "        task_type=\"question_improve\",\n",
        "        user_pref=None,                     # (optional override will come from UI later)\n",
        "        context_size=len(original_query),   # small, but available for routing heuristics\n",
        "    )\n",
        "\n",
        "    # For now we just return the improved text. If desired later, we can:\n",
        "    # - log model_used to audit_log\n",
        "    # - display which model did the improvement in the UI.\n",
        "    return improved.strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "5ac16efd",
      "metadata": {
        "id": "5ac16efd"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "# CELL 9 / STEP 9 – Chat History Viewer (User-Facing)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "3410d761",
      "metadata": {
        "id": "3410d761"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "def format_history_markdown(\n",
        "    user_id: Optional[str],\n",
        "    cohort_name: Optional[str],\n",
        "    limit: int = 50,\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Turn recent history into markdown for display.\n",
        "    \"\"\"\n",
        "    hist = get_recent_history(user_id=user_id, cohort_name=cohort_name, limit=limit)\n",
        "    if not hist:\n",
        "        return \"No chat history found for the given filters (within retention window).\"\n",
        "\n",
        "    lines = []\n",
        "    lines.append(\n",
        "        f\"**Showing up to {limit} most recent interactions** \"\n",
        "        f\"{'(filtered)' if user_id or cohort_name else ''}\\n\"\n",
        "    )\n",
        "\n",
        "    for h in hist:\n",
        "        ts = h[\"created_at\"]\n",
        "        u = h[\"user_id\"] or \"(anonymous)\"\n",
        "        r = h[\"role\"] or \"(none)\"\n",
        "        c = h[\"cohort_name\"] or \"(none)\"\n",
        "        which = h[\"which_prompt\"] or \"(unknown)\"\n",
        "\n",
        "        lines.append(f\"---\\n**User:** `{u}`  |  **Role:** `{r}`  |  **Cohort:** `{c}`  |  **When:** {ts}\")\n",
        "        lines.append(f\"**Prompt used:** `{which}`\")\n",
        "        lines.append(f\"**Original query:**\\n{h['original_query']}\\n\")\n",
        "        if h[\"improved_query\"]:\n",
        "            lines.append(f\"**Improved query:**\\n{h['improved_query']}\\n\")\n",
        "        lines.append(\"**Answer:**\")\n",
        "        lines.append(h[\"answer\"])\n",
        "        lines.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1809131d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "1809131d",
        "outputId": "12c9148f-f47d-4459-e135-3d8b51babc74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "\n",
        "\n",
        "#============================================================\n",
        "# NOTE: If RUN_PREFLIGHT_ONLY=True, do not launch Gradio\n",
        "#============================================================\n",
        "if globals().get(\"STOP_AFTER_PREFLIGHT\", False):\n",
        "    print(\"✅ Pre-flight only: skipping Gradio launch.\")\n",
        "else:\n",
        "    # CELL 9.5 / STEP 9.5 – Identity & Admin Ops (v14)\n",
        "    # ============================================================\n",
        "    def authenticate(username: str, password: str) -> SessionUser | None:\n",
        "        \"\"\"\n",
        "        MVP auth: checks against local USERS dict.\n",
        "        Returns SessionUser or None if invalid.\n",
        "        \"\"\"\n",
        "        record = USERS.get(username)\n",
        "        if not record:\n",
        "            return None\n",
        "        if password != record[\"password\"]:\n",
        "            return None\n",
        "        return SessionUser(username=username, role=record[\"role\"])\n",
        "\n",
        "\n",
        "    def authenticate_credentials(username: str, password: str):\n",
        "        \"\"\"\n",
        "        Wrapper used by the Gradio login logic in STEP 10.\n",
        "\n",
        "        It calls authenticate(...) which returns a SessionUser, then:\n",
        "          - Upserts the user into the `users` table (for admin/history views)\n",
        "          - Returns a simple dict {username, role} that the UI expects.\n",
        "        \"\"\"\n",
        "\n",
        "        # Use the existing MVP auth\n",
        "        user = authenticate(username, password)\n",
        "        if not user:\n",
        "            return None\n",
        "\n",
        "        # Make sure the user exists in the DB's `users` table\n",
        "        try:\n",
        "            upsert_user(\n",
        "                user_id=user.username,\n",
        "                role=user.role,\n",
        "                display_name=user.username,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            # Don't break login if DB write fails; just log it\n",
        "            trace_log(f\"authenticate_credentials upsert_user ERROR: {e}\")\n",
        "\n",
        "        # UI login code in STEP 10 expects a dict-like object\n",
        "        return {\"username\": user.username, \"role\": user.role}\n",
        "        # Use the existing MVP auth\n",
        "        user = authenticate(username, password)\n",
        "        if not user:\n",
        "            return None\n",
        "\n",
        "        # Make sure the user exists in the DB's `users` table\n",
        "        try:\n",
        "            upsert_user(\n",
        "                user_id=user.username,\n",
        "                role=user.role,\n",
        "                display_name=user.username,\n",
        "            )\n",
        "        except Exception as e:\n",
        "            # Don't break login if DB write fails; just log it\n",
        "            trace_log(f\"authenticate_credentials upsert_user ERROR: {e}\")\n",
        "\n",
        "        # UI login code in STEP 10 expects a dict-like object\n",
        "        return {\"username\": user.username, \"role\": user.role}\n",
        "\n",
        "    def require_admin(user: SessionUser):\n",
        "        \"\"\"\n",
        "        Helper for admin-only actions. Raises PermissionError if not admin.\n",
        "        \"\"\"\n",
        "        if not user or not user.is_admin:\n",
        "            raise PermissionError(\"Admin privileges required for this action.\")\n",
        "\n",
        "\n",
        "    def admin_delete_cohort(user: SessionUser, cohort_name: str) -> str:\n",
        "        \"\"\"\n",
        "        Admin-only wrapper around delete_cohort().\n",
        "        Uses the existing delete_cohort function from STEP 4.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            require_admin(user)\n",
        "        except PermissionError as e:\n",
        "            return f\"❌ Not authorized: {e}\"\n",
        "\n",
        "        if not cohort_name:\n",
        "            return \"❌ Please select a cohort to delete.\"\n",
        "\n",
        "        try:\n",
        "            # Use existing v13 delete_cohort logic (no reassignment in this MVP).\n",
        "            msg = delete_cohort(cohort_name, reassign_to=None)\n",
        "            log_audit(user.username, user.role, \"delete_cohort\", f\"cohort={cohort_name}\")\n",
        "            return msg\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error deleting cohort: {e}\"\n",
        "\n",
        "    def admin_view_audit_log(user: SessionUser, limit: int = 50) -> str:\n",
        "        \"\"\"\n",
        "        Admin-only view of recent audit log entries.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            require_admin(user)\n",
        "        except PermissionError as e:\n",
        "            return f\"❌ Not authorized: {e}\"\n",
        "\n",
        "        ensure_audit_table()\n",
        "        conn = get_db_conn()\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\n",
        "            \"\"\"\n",
        "            SELECT ts, username, role, action, details\n",
        "            FROM audit_log\n",
        "            ORDER BY id DESC\n",
        "            LIMIT ?\n",
        "            \"\"\",\n",
        "            (limit,),\n",
        "        )\n",
        "        rows = cur.fetchall()\n",
        "        conn.close()\n",
        "\n",
        "        if not rows:\n",
        "            return \"No audit log entries.\"\n",
        "\n",
        "        lines = [\"**Recent Audit Log Entries**\\n\"]\n",
        "        for ts, username, role, action, details in rows:\n",
        "            u = username or \"-\"\n",
        "            r = role or \"-\"\n",
        "            d = details or \"\"\n",
        "            lines.append(f\"- {ts} | user=`{u}` | role=`{r}` | action=`{action}` | {d}\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    # ============================================================\n",
        "    # STEP 10 — Gradio App, Tabs & Startup (v16_1 with cohort sharing)\n",
        "    # ============================================================\n",
        "\n",
        "    # -----------------------------\n",
        "    # Setup & Cohorts Tab\n",
        "    # -----------------------------\n",
        "\n",
        "    def build_setup_tab(session_state, api_key_state):\n",
        "        \"\"\"\n",
        "        Setup tab (v16_1 Phase 1):\n",
        "          - Create a new cohort from uploaded files (authenticated users only)\n",
        "          - Append files to an existing cohort (owner/admin only)\n",
        "          - Clone a shared cohort when (is_shared=1 AND allow_clone=1)\n",
        "\n",
        "        IMPORTANT POLICY:\n",
        "          - No access is allowed unless the user is logged in.\n",
        "          - Cohorts must always have a valid owner; 'anonymous' is never permitted.\n",
        "        \"\"\"\n",
        "        gr.Markdown(\"### Build or Manage a Cohort\")\n",
        "\n",
        "        def _require_session_user(session_user, action: str) -> SessionUser:\n",
        "            # require_login() is defined earlier in the codebase; this wrapper keeps UI callbacks tidy.\n",
        "            return require_login(session_user, action)\n",
        "\n",
        "        def _is_admin(su: SessionUser) -> bool:\n",
        "            return bool(su and su.is_admin)\n",
        "\n",
        "        def _get_owner(cohort_name: str) -> str | None:\n",
        "            ensure_cohort_meta_table()\n",
        "            conn = get_db_conn()\n",
        "            cur = conn.cursor()\n",
        "            cur.execute(\"SELECT owner_user_id FROM cohort_meta WHERE cohort_name = ? LIMIT 1\", (cohort_name,))\n",
        "            row = cur.fetchone()\n",
        "            conn.close()\n",
        "            return row[0] if row else None\n",
        "\n",
        "        def _can_write(session_user, cohort_name: str) -> bool:\n",
        "            try:\n",
        "                su = _require_session_user(session_user, \"modify cohorts\")\n",
        "            except PermissionError:\n",
        "                return False\n",
        "            if _is_admin(su):\n",
        "                return True\n",
        "            owner = _get_owner(cohort_name)\n",
        "            return bool(owner and su.username and owner == su.username)\n",
        "\n",
        "        def _list_cloneable_shared_cohorts() -> list[str]:\n",
        "            \"\"\"\n",
        "            Cloneable cohorts = is_shared=1 AND allow_clone=1.\n",
        "            We join through `documents` to ensure the cohort has content.\n",
        "            \"\"\"\n",
        "            ensure_cohort_meta_table()\n",
        "            ensure_docs_table()\n",
        "            conn = get_db_conn()\n",
        "            cur = conn.cursor()\n",
        "            cur.execute(\n",
        "                \"\"\"\n",
        "                SELECT DISTINCT cm.cohort_name\n",
        "                FROM cohort_meta cm\n",
        "                JOIN documents d\n",
        "                  ON d.cohort_name = cm.cohort_name\n",
        "                WHERE cm.is_shared = 1\n",
        "                  AND COALESCE(cm.allow_clone,0) = 1\n",
        "                  AND d.cohort_name IS NOT NULL\n",
        "                  AND TRIM(d.cohort_name) <> ''\n",
        "                ORDER BY cm.cohort_name\n",
        "                \"\"\"\n",
        "            )\n",
        "            rows = cur.fetchall()\n",
        "            conn.close()\n",
        "            return [r[0] for r in rows]\n",
        "\n",
        "        # ---------- UI ----------\n",
        "        with gr.Row():\n",
        "            action_radio = gr.Radio(\n",
        "                choices=[ACTION_CREATE, ACTION_APPEND, ACTION_CLONE],\n",
        "                value=DEFAULT_ACTION,\n",
        "                label=\"Action\",\n",
        "            )\n",
        "\n",
        "        clone_info_md = gr.Markdown(\"\", visible=False)\n",
        "\n",
        "        with gr.Row():\n",
        "            new_cohort_name = gr.Textbox(label=\"New Cohort Name\", placeholder=\"e.g., WIC_Security_2025\")\n",
        "            existing_cohort_dropdown = gr.Dropdown(\n",
        "                label=\"Existing Cohort\",\n",
        "                choices=[],\n",
        "                interactive=True,\n",
        "                visible=False,\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            share_checkbox = gr.Checkbox(label=\"Shared (visible to all logged-in users)\", value=False)\n",
        "            allow_clone_checkbox = gr.Checkbox(label=\"Allow other users to clone this cohort\", value=False)\n",
        "\n",
        "        file_uploader = gr.File(\n",
        "            label=\"Upload Documents (PDF, DOCX, TXT)\",\n",
        "            file_count=\"multiple\",\n",
        "            type=\"filepath\",\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            build_btn = gr.Button(\"Run\", variant=\"primary\")\n",
        "\n",
        "        gr.Markdown(\"#### Clone a Shared Cohort\")\n",
        "        with gr.Row():\n",
        "            clone_source_dropdown = gr.Dropdown(\n",
        "                label=\"Source Cohort (shared + cloning enabled)\",\n",
        "                choices=[],\n",
        "                interactive=True,\n",
        "                visible=False,\n",
        "            )\n",
        "            clone_target_name = gr.Textbox(\n",
        "                label=\"New Cohort Name (clone target)\",\n",
        "                placeholder=\"e.g., My_Copy_of_WIC_Security_2025\",\n",
        "                visible=False,\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            clone_btn = gr.Button(\"Clone Cohort\", visible=False)\n",
        "\n",
        "        build_status = gr.Markdown(\"\")\n",
        "\n",
        "        # ---------- dynamic visibility ----------\n",
        "        def _toggle_fields(action: str, session_user):\n",
        "            # ✅ FIX 1: Handle None/empty action by defaulting to CREATE\n",
        "            if not action or action not in [ACTION_CREATE, ACTION_APPEND,       ACTION_CLONE]:\n",
        "                action = ACTION_CREATE\n",
        "\n",
        "            try:\n",
        "                _require_session_user(session_user, \"use cohort management\")\n",
        "            except PermissionError:\n",
        "                # If not logged in, hide everything. (Login gating policy)\n",
        "                return (\n",
        "                    gr.update(visible=False),  # new_cohort_name\n",
        "                    gr.update(visible=False, choices=[], value=None),  # existing_cohort_dropdown\n",
        "                    gr.update(visible=False),  # share_checkbox\n",
        "                    gr.update(visible=False),  # allow_clone_checkbox\n",
        "                    gr.update(visible=False),  # file_uploader\n",
        "                    gr.update(visible=False),  # build_btn\n",
        "                    gr.update(visible=False, choices=[], value=None),  # clone_source_dropdown\n",
        "                    gr.update(visible=False),  # clone_target_name\n",
        "                    gr.update(visible=False),  # clone_btn\n",
        "                    gr.update(value=\"❌ Please log in to manage cohorts.\", visible=True),  # clone_info_md\n",
        "                )\n",
        "\n",
        "            is_create = action == ACTION_CREATE\n",
        "            is_append = action == ACTION_APPEND\n",
        "            is_clone = action == ACTION_CLONE\n",
        "\n",
        "            clone_sources = _list_cloneable_shared_cohorts() if is_clone else []\n",
        "            has_sources = len(clone_sources) > 0\n",
        "\n",
        "            msg = \"\"\n",
        "            if is_clone and not has_sources:\n",
        "                msg = \"ℹ️ No shared cohorts are available for you to clone yet.\"\n",
        "\n",
        "            return (\n",
        "                gr.update(visible=is_create),\n",
        "                gr.update(visible=is_append),\n",
        "                gr.update(visible=is_create or is_append),\n",
        "                gr.update(visible=is_create or is_append),\n",
        "                gr.update(visible=is_create or is_append),\n",
        "                gr.update(visible=is_create or is_append),\n",
        "                gr.update(visible=is_clone and has_sources, choices=clone_sources, value=None),\n",
        "                gr.update(visible=is_clone and has_sources),\n",
        "                gr.update(visible=is_clone and has_sources),\n",
        "                gr.update(value=msg, visible=bool(msg)),\n",
        "            )\n",
        "\n",
        "        action_radio.change(\n",
        "            fn=safe_ui_call(_toggle_fields, fallback=(\n",
        "                gr.update(visible=True),   # new_cohort_name\n",
        "                gr.update(visible=False),  # existing_cohort_dropdown\n",
        "                gr.update(visible=True),   # share_checkbox\n",
        "                gr.update(visible=True),   # allow_clone_checkbox\n",
        "                gr.update(visible=True),   # file_uploader\n",
        "                gr.update(visible=True),   # build_btn\n",
        "                gr.update(visible=False, choices=[], value=None),  # clone_source_dropdown\n",
        "                gr.update(visible=False, value=\"\"),              # clone_target_name\n",
        "                gr.update(visible=False),                         # clone_btn\n",
        "                gr.update(value=\"❌ UI error. See trace log.\", visible=True),  # clone_info_md\n",
        "            )),\n",
        "            inputs=[action_radio, session_state],\n",
        "            outputs=[\n",
        "                new_cohort_name,\n",
        "                existing_cohort_dropdown,\n",
        "                share_checkbox,\n",
        "                allow_clone_checkbox,\n",
        "                file_uploader,\n",
        "                build_btn,\n",
        "                clone_source_dropdown,\n",
        "                clone_target_name,\n",
        "                clone_btn,\n",
        "                clone_info_md,\n",
        "            ],\n",
        "        )\n",
        "        # ✅ FIX 2: REMOVE THIS ENTIRE BLOCK (it causes the bug by re-triggering with action=None)\n",
        "        # Refresh the cohort-management UI when login/logout changes session_state.\n",
        "        # This prevents stale \"Please log in\" messages from persisting after a successful login.\n",
        "        session_state.change(\n",
        "            fn=safe_ui_call(_toggle_fields, fallback=(\n",
        "                gr.update(visible=True),   # new_cohort_name\n",
        "                gr.update(visible=False),  # existing_cohort_dropdown\n",
        "                gr.update(visible=True),   # share_checkbox\n",
        "                gr.update(visible=True),   # allow_clone_checkbox\n",
        "                gr.update(visible=True),   # file_uploader\n",
        "                gr.update(visible=True),   # build_btn\n",
        "                gr.update(visible=False, choices=[], value=None),  # clone_source_dropdown\n",
        "                gr.update(visible=False, value=\"\"),                # clone_target_name\n",
        "                gr.update(visible=False),                          # clone_btn\n",
        "                gr.update(value=\"\", visible=False),                # clone_info_md  (CLEAR)\n",
        "            )),\n",
        "            inputs=[action_radio, session_state],\n",
        "            outputs=[\n",
        "                new_cohort_name,\n",
        "                existing_cohort_dropdown,\n",
        "                share_checkbox,\n",
        "                allow_clone_checkbox,\n",
        "                file_uploader,\n",
        "                build_btn,\n",
        "                clone_source_dropdown,\n",
        "                clone_target_name,\n",
        "                clone_btn,\n",
        "                clone_info_md,\n",
        "            ],\n",
        "            queue=False,\n",
        "        )\n",
        "\n",
        "\n",
        "        # ---------- refresh helpers ----------\n",
        "\n",
        "\n",
        "        def _refresh_existing_dropdown(session_user):\n",
        "            try:\n",
        "                su = _require_session_user(session_user, \"view cohorts\")\n",
        "            except PermissionError:\n",
        "                return gr.update(choices=[], value=None)\n",
        "            return gr.update(choices=get_cohorts_for_user(su.username), value=None)\n",
        "\n",
        "        def _refresh_clone_sources(session_user):\n",
        "            try:\n",
        "                _require_session_user(session_user, \"view cloneable cohorts\")\n",
        "            except PermissionError:\n",
        "                return gr.update(choices=[], value=None)\n",
        "            choices = _list_cloneable_shared_cohorts()\n",
        "            return gr.update(choices=choices, value=None)\n",
        "        def _normalize_cohort_name(selected: str | None) -> str:\n",
        "            s = (selected or \"\").strip()\n",
        "            if not s:\n",
        "                return \"\"\n",
        "            # If dropdown shows \"name/owner\", keep only the cohort name\n",
        "            return s.split(\"/\", 1)[0].strip()\n",
        "\n",
        "        # ---------- action handlers ----------\n",
        "       # ---------- action handlers ----------\n",
        "        def _run_action(action, api_key, session_user, new_name, existing_name, files, is_shared, allow_clone):\n",
        "            \"\"\"\n",
        "            MUST return exactly 3 outputs (matches build_btn.click outputs):\n",
        "              1) build_status (markdown)\n",
        "              2) file_uploader (File component)\n",
        "              3) existing_cohort_dropdown (Dropdown component)\n",
        "            \"\"\"\n",
        "\n",
        "            # Helper: refresh existing cohort dropdown choices for this user\n",
        "            def _refresh_existing_dd(owner_username: str):\n",
        "                try:\n",
        "                    choices = get_cohorts_for_user(owner_username)\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"SETUP refresh existing dropdown ERROR: {e}\")\n",
        "                    choices = []\n",
        "                return gr.update(choices=choices, value=None)\n",
        "\n",
        "            # 1) Require session user\n",
        "            try:\n",
        "                su = _require_session_user(session_user, \"create or modify cohorts\")\n",
        "            except PermissionError as e:\n",
        "                return f\"❌ {e}\", gr.update(), gr.update()\n",
        "\n",
        "            owner = (su.username or \"\").strip()\n",
        "            if not owner or owner.lower() == \"anonymous\":\n",
        "                return \"❌ You must be logged in to create or modify cohorts (owner is required).\", gr.update(), gr.update()\n",
        "\n",
        "            if not api_key or not str(api_key).strip():\n",
        "                return \"❌ Please provide an OpenAI API key.\", gr.update(), gr.update()\n",
        "\n",
        "            # -------------------------\n",
        "            # CREATE\n",
        "            # -------------------------\n",
        "            if action == ACTION_CREATE:\n",
        "                cohort_name = (new_name or \"\").strip()\n",
        "\n",
        "                if not cohort_name:\n",
        "                    return \"❌ Please provide a new cohort name.\", gr.update(), gr.update()\n",
        "                if cohort_exists(cohort_name):\n",
        "                    return f\"❌ Cohort '{cohort_name}' already exists.\", gr.update(), gr.update()\n",
        "                if not files:\n",
        "                    return \"❌ Please upload at least one file.\", gr.update(), gr.update()\n",
        "\n",
        "                # Build index first\n",
        "                try:\n",
        "                    msg = build_cohort_index(api_key=api_key, cohort_name=cohort_name, files=files, owner=owner)\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"Create build_cohort_index ERROR: {e}\")\n",
        "                    return f\"❌ Error building cohort: {e}\", gr.update(), gr.update()\n",
        "\n",
        "                # Persist metadata (REQUIRED)\n",
        "                try:\n",
        "                    ensure_cohort_meta_table()\n",
        "                    set_cohort_owner(cohort_name, su)  # required\n",
        "                    set_cohort_sharing(cohort_name, bool(is_shared))\n",
        "                    set_cohort_allow_clone(cohort_name, bool(allow_clone))\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"Create cohort meta update ERROR: {e}\")\n",
        "                    return f\"❌ Failed to persist cohort ownership/sharing metadata: {e}\", gr.update(), gr.update()\n",
        "\n",
        "                try:\n",
        "                    log_audit(owner, su.role, \"create_cohort\", f\"cohort={cohort_name}, shared={is_shared}, allow_clone={allow_clone}\")\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"log_audit create_cohort ERROR: {e}\")\n",
        "\n",
        "                # SUCCESS: clear uploader + refresh dropdown\n",
        "                refreshed_dd = _refresh_existing_dd(owner)\n",
        "                return msg, gr.update(value=None), refreshed_dd\n",
        "\n",
        "            # -------------------------\n",
        "            # APPEND\n",
        "            # -------------------------\n",
        "            if action == ACTION_APPEND:\n",
        "                cohort_name = _normalize_cohort_name(existing_name)\n",
        "\n",
        "                if not cohort_name:\n",
        "                    return \"❌ Please select an existing cohort.\", gr.update(), gr.update()\n",
        "                if not cohort_exists(cohort_name):\n",
        "                    return f\"❌ Cohort '{cohort_name}' does not exist.\", gr.update(), gr.update()\n",
        "                if not files:\n",
        "                    return \"❌ Please upload at least one file.\", gr.update(), gr.update()\n",
        "                if not _can_write(session_user, cohort_name):\n",
        "                    return \"❌ Not authorized: only the cohort owner or an admin may append files.\", gr.update(), gr.update()\n",
        "\n",
        "                embed_cfg = get_default_embed_model_config()\n",
        "\n",
        "                try:\n",
        "                    msg = build_cohort_from_files(\n",
        "                        api_key=api_key,\n",
        "                        embed_model=embed_cfg.model_id,\n",
        "                        cohort_name=cohort_name,\n",
        "                        files=files\n",
        "                    )\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"Append build_cohort_from_files ERROR: {e}\")\n",
        "                    return f\"❌ Error appending files to cohort: {e}\", gr.update(), gr.update()\n",
        "\n",
        "                # Owner/admin may update sharing flags during append\n",
        "                try:\n",
        "                    ensure_cohort_meta_table()\n",
        "                    set_cohort_owner(cohort_name, su)  # repairs invalid owners if needed\n",
        "                    set_cohort_sharing(cohort_name, bool(is_shared))\n",
        "                    set_cohort_allow_clone(cohort_name, bool(allow_clone))\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"Append cohort meta update ERROR: {e}\")\n",
        "                    return f\"❌ Failed to update cohort metadata: {e}\", gr.update(), gr.update()\n",
        "\n",
        "                try:\n",
        "                    log_audit(owner, su.role, \"append_files\", f\"cohort={cohort_name}, shared={is_shared}, allow_clone={allow_clone}\")\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"log_audit append_files ERROR: {e}\")\n",
        "\n",
        "                # SUCCESS: clear uploader + refresh dropdown\n",
        "                refreshed_dd = _refresh_existing_dd(owner)\n",
        "                return msg, gr.update(value=None), refreshed_dd\n",
        "\n",
        "            # -------------------------\n",
        "            # Unsupported\n",
        "            # -------------------------\n",
        "            return \"❌ Unsupported action selected.\", gr.update(), gr.update()\n",
        "\n",
        "        build_btn.click(\n",
        "            fn=safe_ui_call(_run_action, fallback=(\"❌ UI error. See trace log.\", gr.update(), gr.update())),\n",
        "            inputs=[\n",
        "                action_radio,\n",
        "                api_key_state,\n",
        "                session_state,\n",
        "                new_cohort_name,\n",
        "                existing_cohort_dropdown,\n",
        "                file_uploader,\n",
        "                share_checkbox,\n",
        "                allow_clone_checkbox,\n",
        "            ],\n",
        "            outputs=[build_status, file_uploader, existing_cohort_dropdown],\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        def _run_clone(api_key, session_user, source_cohort, target_cohort):\n",
        "            try:\n",
        "                su = _require_session_user(session_user, \"clone cohorts\")\n",
        "            except PermissionError as e:\n",
        "                return f\"❌ {e}\"\n",
        "\n",
        "            if not api_key or not str(api_key).strip():\n",
        "                return \"❌ Please provide an OpenAI API key.\"\n",
        "            if not source_cohort:\n",
        "                return \"❌ Please select a source cohort.\"\n",
        "            if not target_cohort or not target_cohort.strip():\n",
        "                return \"❌ Please provide a new cohort name for the clone.\"\n",
        "\n",
        "            allowed = set(_list_cloneable_shared_cohorts())\n",
        "            if (source_cohort not in allowed) and not _is_admin(su):\n",
        "                return \"❌ Not authorized: cloning is not enabled for this cohort.\"\n",
        "\n",
        "            msg = clone_cohort(source_cohort=source_cohort, target_cohort=target_cohort.strip(), new_owner=su.username)\n",
        "            try:\n",
        "                log_audit(su.username, su.role, \"clone_cohort\", f\"{source_cohort} → {target_cohort.strip()}\")\n",
        "            except Exception as e:\n",
        "                trace_log(f\"log_audit clone_cohort ERROR: {e}\")\n",
        "\n",
        "            return msg\n",
        "\n",
        "        clone_btn.click(\n",
        "            fn=safe_ui_call(_run_clone),\n",
        "            inputs=[api_key_state, session_state, clone_source_dropdown, clone_target_name],\n",
        "            outputs=[build_status],\n",
        "        )\n",
        "\n",
        "        # Return handles expected by build_interface()\n",
        "        return {\n",
        "            \"action_radio\": action_radio,\n",
        "            \"new_cohort_name\": new_cohort_name,\n",
        "            \"existing_cohort_dropdown\": existing_cohort_dropdown,\n",
        "            \"share_checkbox\": share_checkbox,\n",
        "            \"allow_clone_checkbox\": allow_clone_checkbox,\n",
        "            \"file_uploader\": file_uploader,\n",
        "            \"build_btn\": build_btn,\n",
        "            \"clone_source_dropdown\": clone_source_dropdown,\n",
        "            \"clone_target_name\": clone_target_name,\n",
        "            \"clone_btn\": clone_btn,\n",
        "            \"build_status\": build_status,\n",
        "            \"clone_info_md\": clone_info_md,\n",
        "            \"refresh_existing_dropdown\": _refresh_existing_dropdown,\n",
        "            \"refresh_clone_sources\": _refresh_clone_sources,\n",
        "        }\n",
        "\n",
        "    def build_ask_tab(session_state, api_key_state):\n",
        "        \"\"\"\n",
        "        Ask tab:\n",
        "          - Choose cohort + chat model\n",
        "          - Optional prompt improvement\n",
        "          - Ask question over cohort with RAG\n",
        "          - View documents in selected cohort\n",
        "        \"\"\"\n",
        "        gr.Markdown(\"### Ask Questions Over a Cohort\")\n",
        "\n",
        "        with gr.Row():\n",
        "            cohort_dropdown = gr.Dropdown(\n",
        "                label=\"Cohort\",\n",
        "                choices=[],\n",
        "                elem_id=\"ask_cohort_dropdown\",\n",
        "            )\n",
        "            model_dropdown = gr.Dropdown(\n",
        "                label=\"Choose Chat Model\",\n",
        "                choices=list_chat_models(),\n",
        "                elem_id=\"ask_model_dropdown\",\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            demo_prompt_dropdown = gr.Dropdown(\n",
        "                label=\"Demo Prompt (optional)\",\n",
        "                choices=[],\n",
        "                value=None,\n",
        "                interactive=True,\n",
        "                visible=False,\n",
        "                elem_id=\"ask_demo_prompt_dropdown\",\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            question_box = gr.Textbox(\n",
        "                label=\"Your Question\",\n",
        "                lines=3,\n",
        "                elem_id=\"ask_question_box\",\n",
        "            )\n",
        "            improved_box = gr.Textbox(\n",
        "                label=\"Improved Prompt (optional, from Prompt Coach)\",\n",
        "                lines=3,\n",
        "                elem_id=\"ask_improved_box\",\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "        with gr.Row():\n",
        "            improve_btn = gr.Button(\"Improve Prompt\", elem_id=\"ask_improve_btn\")\n",
        "            ask_btn = gr.Button(\"Ask Question\", elem_id=\"ask_ask_btn\")\n",
        "            refresh_cohorts_btn = gr.Button(\"Refresh Cohorts\", elem_id=\"ask_refresh_btn\")\n",
        "\n",
        "\n",
        "        with gr.Accordion(\"Documents in Selected Cohort\", open=False):\n",
        "            docs_md = gr.Markdown(\"_No cohort selected._\")\n",
        "\n",
        "\n",
        "        gr.Markdown(\"#### Answer\")\n",
        "        answer_md = gr.Markdown()\n",
        "\n",
        "        # ---- Callbacks ----\n",
        "\n",
        "        def _refresh_cohorts(session_user):\n",
        "            \"\"\"Refresh cohort list for the logged-in user only (no anonymous access).\"\"\"\n",
        "            try:\n",
        "                su = require_login(session_user, \"view cohorts\")\n",
        "                names = get_cohorts_for_user(su.username)\n",
        "                return gr.update(choices=names, value=None)\n",
        "            except PermissionError:\n",
        "                return gr.update(choices=[], value=None)\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ASK _refresh_cohorts ERROR: {e}\")\n",
        "                return gr.update(choices=[], value=None)\n",
        "\n",
        "\n",
        "\n",
        "        def _refresh_demo_prompts_ui(cohort_name: str, session_user):\n",
        "            \"\"\"\n",
        "            If selected cohort has demo prompts, show the Demo Prompt dropdown and populate choices.\n",
        "            Always clears the question box on cohort change to avoid stale text between demos.\n",
        "            \"\"\"\n",
        "            try:\n",
        "                su = require_login(session_user, \"view demo prompts\")\n",
        "            except PermissionError:\n",
        "                return gr.update(visible=False, choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "            c = (cohort_name or \"\").strip()\n",
        "            if not c:\n",
        "                return gr.update(visible=False, choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "            prompts = list_demo_prompts_for_cohort(c)\n",
        "            if not prompts:\n",
        "                return gr.update(visible=False, choices=[], value=None), gr.update(value=\"\")\n",
        "\n",
        "            return gr.update(visible=True, choices=prompts, value=None), gr.update(value=\"\")\n",
        "\n",
        "        def _demo_prompt_pick_cb(selected_prompt: str):\n",
        "            # Populate \"Your Question\" from the selected demo prompt.\n",
        "            return gr.update(value=(selected_prompt or \"\").strip())\n",
        "        def _improve_query_cb(original_query: str, api_key: str):\n",
        "            if not api_key or not api_key.strip():\n",
        "                return \"❌ OpenAI API key is required.\"\n",
        "            try:\n",
        "                improved = improve_query(\n",
        "                    api_key=api_key,\n",
        "                    chat_model=CHAT_MODEL_DEFAULT,\n",
        "                    original_query=original_query or \"\",\n",
        "                )\n",
        "                if not improved:\n",
        "                    return original_query\n",
        "                return improved\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ASK _improve_query_cb ERROR: {e}\")\n",
        "                return f\"❌ Error improving query: {e}\"\n",
        "\n",
        "        def _ask_cb(\n",
        "            cohort_name: str,\n",
        "            question: str,\n",
        "            improved_prompt: str,\n",
        "            model_id: str,\n",
        "            session_user,\n",
        "            api_key: str,\n",
        "        ):\n",
        "            try:\n",
        "                su = require_login(session_user, \"ask questions\")\n",
        "            except PermissionError as e:\n",
        "                return f\"❌ {e}\"\n",
        "\n",
        "            username = su.username.strip()\n",
        "\n",
        "            # Authorization: user must have visibility to cohort\n",
        "            if cohort_name and cohort_name not in set(get_cohorts_for_user(username)):\n",
        "                return \"❌ Not authorized to access this cohort.\"\n",
        "\n",
        "            if not api_key or not api_key.strip():\n",
        "                return \"❌ OpenAI API key is required.\"\n",
        "\n",
        "            if not cohort_name:\n",
        "                return \"❌ Please choose a cohort.\"\n",
        "\n",
        "            # Decide which prompt is used\n",
        "            improved_clean = (improved_prompt or \"\").strip()\n",
        "            question_clean = (question or \"\").strip()\n",
        "            used_improved = bool(improved_clean)\n",
        "\n",
        "            final_question = improved_clean if used_improved else question_clean\n",
        "            if not final_question:\n",
        "                return \"❌ Please enter a question.\"\n",
        "\n",
        "            try:\n",
        "                answer_markdown, raw_answer, used_model = answer_question_over_cohort(\n",
        "                    api_key=api_key,\n",
        "                    username=username,\n",
        "                    cohort_name=cohort_name,\n",
        "                    question=final_question,\n",
        "                    model_id=model_id or CHAT_MODEL_DEFAULT,\n",
        "                )\n",
        "\n",
        "                # Log to chat_history\n",
        "                try:\n",
        "                    save_chat_history(\n",
        "                        user=session_user,\n",
        "                        cohort=cohort_name,\n",
        "                        question=final_question,\n",
        "                        answer=raw_answer,\n",
        "                        model_used=used_model,\n",
        "                    )\n",
        "                except Exception as log_e:\n",
        "                    trace_log(f\"ASK save_chat_history ERROR: {log_e}\")\n",
        "\n",
        "                # Add a visible note about which prompt was used\n",
        "                if used_improved:\n",
        "                    note = \"**Note:** Used the *Improved Prompt* for this answer.\\n\\n\"\n",
        "                else:\n",
        "                    note = \"**Note:** Used your *Original Question* for this answer.\\n\\n\"\n",
        "\n",
        "                return note + (answer_markdown or \"\")\n",
        "\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ASK _ask_cb ERROR: {e}\")\n",
        "                return f\"❌ Error while answering question: {e}\"\n",
        "\n",
        "\n",
        "        def _load_docs_for_cohort(session_user, cohort_name: str):\n",
        "            \"\"\"Show documents for the selected cohort (login required).\"\"\"\n",
        "            try:\n",
        "                su = require_login(session_user, \"view cohort documents\")\n",
        "            except PermissionError:\n",
        "                return \"❌ Login required to view cohort documents.\"\n",
        "            if not cohort_name:\n",
        "                return \"_No cohort selected._\"\n",
        "            # Authorization: user must have visibility to this cohort\n",
        "            if cohort_name not in set(get_cohorts_for_user(su.username)):\n",
        "                return \"❌ Not authorized to view this cohort.\"\n",
        "            try:\n",
        "                conn = get_db_conn()\n",
        "                cur = conn.cursor()\n",
        "                cur.execute(\n",
        "                    \"\"\"\n",
        "                    SELECT doc_name, created_at\n",
        "                    FROM documents\n",
        "                    WHERE cohort_name = ?\n",
        "                    ORDER BY created_at\n",
        "                    \"\"\",\n",
        "                    (cohort_name,),\n",
        "                )\n",
        "                rows = cur.fetchall()\n",
        "                conn.close()\n",
        "\n",
        "                if not rows:\n",
        "                    return f\"_No documents found for cohort `{cohort_name}`._\"\n",
        "\n",
        "                lines = [f\"**Documents in cohort `{cohort_name}`:**\"]\n",
        "                for doc_name, created_at in rows:\n",
        "                    if created_at:\n",
        "                        lines.append(f\"- `{doc_name}` (added {created_at})\")\n",
        "                    else:\n",
        "                        lines.append(f\"- `{doc_name}`\")\n",
        "                return \"\\n\".join(lines)\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ASK _load_docs_for_cohort ERROR: {e}\")\n",
        "                return f\"❌ Error loading documents for cohort `{cohort_name}`.\"\n",
        "\n",
        "        # Wire buttons\n",
        "        refresh_cohorts_btn.click(\n",
        "            _refresh_cohorts,\n",
        "            inputs=[session_state],\n",
        "            outputs=[cohort_dropdown],\n",
        "        )\n",
        "\n",
        "        improve_btn.click(\n",
        "            _improve_query_cb,\n",
        "            inputs=[question_box, api_key_state],\n",
        "            outputs=[improved_box],\n",
        "        )\n",
        "\n",
        "        ask_btn.click(\n",
        "            _ask_cb,\n",
        "            inputs=[\n",
        "                cohort_dropdown,\n",
        "                question_box,\n",
        "                improved_box,\n",
        "                model_dropdown,\n",
        "                session_state,\n",
        "                api_key_state,\n",
        "            ],\n",
        "            outputs=[answer_md],\n",
        "        )\n",
        "\n",
        "        cohort_dropdown.change(\n",
        "            _load_docs_for_cohort,\n",
        "            inputs=[session_state, cohort_dropdown],\n",
        "            outputs=[docs_md],\n",
        "        )\n",
        "\n",
        "        cohort_dropdown.change(\n",
        "            _refresh_demo_prompts_ui,\n",
        "            inputs=[cohort_dropdown, session_state],\n",
        "            outputs=[demo_prompt_dropdown, question_box],\n",
        "        )\n",
        "\n",
        "        demo_prompt_dropdown.change(\n",
        "            _demo_prompt_pick_cb,\n",
        "            inputs=[demo_prompt_dropdown],\n",
        "            outputs=[question_box],\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"cohort_dropdown\": cohort_dropdown,\n",
        "            \"model_dropdown\": model_dropdown,\n",
        "            \"question_box\": question_box,\n",
        "            \"improved_box\": improved_box,\n",
        "            \"answer_markdown\": answer_md,\n",
        "            \"docs_markdown\": docs_md,\n",
        "        }\n",
        "\n",
        "\n",
        "    # -----------------------------\n",
        "    # History Tab\n",
        "    # -----------------------------\n",
        "    def build_history_tab(session_state):\n",
        "        \"\"\"\n",
        "        Simple history viewer using format_history_markdown.\n",
        "        \"\"\"\n",
        "        gr.Markdown(\"### Chat History (read-only)\")\n",
        "\n",
        "        with gr.Row():\n",
        "            history_user_filter = gr.Textbox(\n",
        "                label=\"Filter by User ID (optional)\",\n",
        "                placeholder=\"Leave blank for all users\",\n",
        "            )\n",
        "            history_cohort_filter = gr.Textbox(\n",
        "                label=\"Filter by Cohort (optional)\",\n",
        "                placeholder=\"Leave blank for all cohorts\",\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            use_current_user_btn = gr.Button(\"Use Current User\")\n",
        "            refresh_history_btn = gr.Button(\"Refresh History\")\n",
        "\n",
        "        history_md = gr.Markdown()\n",
        "\n",
        "        def _use_current_user(session_user):\n",
        "            return _extract_user_id(session_user) or \"\"\n",
        "\n",
        "        def _refresh_history(session_user, user_id: str, cohort_name: str):\n",
        "            try:\n",
        "                su = require_login(session_user, \"view chat history\")\n",
        "            except PermissionError as e:\n",
        "                return f\"❌ {e}\"\n",
        "\n",
        "            is_admin = su.is_admin\n",
        "\n",
        "            u_raw = (user_id or \"\").strip()\n",
        "            c_raw = (cohort_name or \"\").strip()\n",
        "\n",
        "            # Normalize common \"All\" sentinel values to None\n",
        "            if u_raw.lower() in (\"all users\", \"all\", \"*\"):\n",
        "                u_raw = \"\"\n",
        "            if c_raw.lower() in (\"all cohorts\", \"all\", \"*\"):\n",
        "                c_raw = \"\"\n",
        "\n",
        "            u = u_raw or None\n",
        "            c = c_raw or None\n",
        "\n",
        "            # Non-admins can only view their own history regardless of filter\n",
        "            if not is_admin:\n",
        "                u = su.username\n",
        "\n",
        "            try:\n",
        "                return format_history_markdown(u, c, limit=50)\n",
        "            except Exception as e:\n",
        "                trace_log(f\"HISTORY _refresh_history ERROR: {e}\")\n",
        "                return f\"❌ Error loading history: {e}\"\n",
        "\n",
        "\n",
        "        use_current_user_btn.click(\n",
        "            _use_current_user,\n",
        "            inputs=[session_state],\n",
        "            outputs=[history_user_filter],\n",
        "        )\n",
        "\n",
        "        refresh_history_btn.click(\n",
        "            _refresh_history,\n",
        "            inputs=[session_state, history_user_filter, history_cohort_filter],\n",
        "            outputs=[history_md],\n",
        "        )\n",
        "\n",
        "\n",
        "        return {\n",
        "            \"history_user_filter\": history_user_filter,\n",
        "            \"history_cohort_filter\": history_cohort_filter,\n",
        "            \"history_markdown\": history_md,\n",
        "        }\n",
        "\n",
        "\n",
        "    # -----------------------------\n",
        "    # Admin Tab\n",
        "    # -----------------------------\n",
        "    def build_admin_tab(session_state):\n",
        "        \"\"\"\n",
        "        Admin tab showing DB stats, users, cohorts, and audit log.\n",
        "        Fix 3.3: prevent cross-button \"stacking\" by updating all 4 panes each click.\n",
        "        \"\"\"\n",
        "        gr.Markdown(\"### Admin (requires admin role)\")\n",
        "        gr.Markdown(\"You must be logged in as an admin user to see details here.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            refresh_stats_btn = gr.Button(\"DB Stats\")\n",
        "            refresh_users_btn = gr.Button(\"List Users\")\n",
        "            refresh_cohorts_btn = gr.Button(\"List Cohorts\")\n",
        "            refresh_audit_btn = gr.Button(\"Audit Log (last 50)\")\n",
        "\n",
        "        admin_stats_md = gr.Markdown()\n",
        "        admin_users_md = gr.Markdown()\n",
        "        admin_cohorts_md = gr.Markdown()\n",
        "        admin_audit_md = gr.Markdown()\n",
        "\n",
        "        gr.Markdown(\"#### Delete Cohort (admin only)\")\n",
        "        admin_delete_cohort_dropdown = gr.Dropdown(\n",
        "            label=\"Select Cohort to Delete\",\n",
        "            choices=[],\n",
        "        )\n",
        "        admin_delete_btn = gr.Button(\"Delete Selected Cohort\")\n",
        "        admin_delete_status_md = gr.Markdown()\n",
        "\n",
        "        def _ensure_admin(session_user):\n",
        "            if not session_user:\n",
        "                return None, \"❌ Not logged in.\"\n",
        "            username = session_user.get(\"username\")\n",
        "            role = session_user.get(\"role\", \"user\")\n",
        "            su = SessionUser(username=username, role=role)\n",
        "            if not su.is_admin:\n",
        "                return None, \"❌ Admin privileges required.\"\n",
        "            return su, \"\"\n",
        "\n",
        "        # --- NEW helper: ensures only one admin pane is populated at a time ---\n",
        "        def _admin_pack(active: str, text: str):\n",
        "            \"\"\"\n",
        "            active in {\"stats\",\"users\",\"cohorts\",\"audit\"}\n",
        "            Returns 4 outputs in the order: stats, users, cohorts, audit\n",
        "            \"\"\"\n",
        "            stats = text if active == \"stats\" else \"\"\n",
        "            users = text if active == \"users\" else \"\"\n",
        "            cohorts = text if active == \"cohorts\" else \"\"\n",
        "            audit = text if active == \"audit\" else \"\"\n",
        "            return stats, users, cohorts, audit\n",
        "\n",
        "        def _refresh_stats(session_user):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return _admin_pack(\"stats\", msg)\n",
        "            try:\n",
        "                return _admin_pack(\"stats\", get_db_stats())\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ADMIN _refresh_stats ERROR: {e}\")\n",
        "                return _admin_pack(\"stats\", f\"❌ Error loading DB stats: {e}\")\n",
        "\n",
        "        def _refresh_users(session_user):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return _admin_pack(\"stats\", msg)\n",
        "            try:\n",
        "                return _admin_pack(\"users\", describe_users())\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ADMIN _refresh_users ERROR: {e}\")\n",
        "                return _admin_pack(\"users\", f\"❌ Error loading users: {e}\")\n",
        "\n",
        "        # Split cohorts refresh into:\n",
        "        #   (A) markdown panes (4 outputs)\n",
        "        #   (B) delete dropdown choices (1 output)\n",
        "        def _refresh_cohorts_admin_md(session_user):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return _admin_pack(\"stats\", msg)\n",
        "            try:\n",
        "                return _admin_pack(\"cohorts\", describe_cohorts())\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ADMIN _refresh_cohorts_admin_md ERROR: {e}\")\n",
        "                return _admin_pack(\"cohorts\", f\"❌ Error loading cohorts: {e}\")\n",
        "\n",
        "        def _refresh_cohorts_admin_dd(session_user):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return gr.update(choices=[], value=None)\n",
        "            try:\n",
        "                names = [row[0] for row in get_all_cohorts()]\n",
        "                return gr.update(choices=names, value=None)\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ADMIN _refresh_cohorts_admin_dd ERROR: {e}\")\n",
        "                return gr.update(choices=[], value=None)\n",
        "\n",
        "        def _refresh_audit(session_user):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return _admin_pack(\"stats\", msg)\n",
        "            try:\n",
        "                return _admin_pack(\"audit\", admin_view_audit_log(su, limit=50))\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ADMIN _refresh_audit ERROR: {e}\")\n",
        "                return _admin_pack(\"audit\", f\"❌ Error loading audit log: {e}\")\n",
        "\n",
        "        def _delete_cohort_cb(session_user, cohort_name: str):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return msg\n",
        "            if not cohort_name:\n",
        "                return \"❌ Please select a cohort.\"\n",
        "            try:\n",
        "                return admin_delete_cohort(su, cohort_name)\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ADMIN _delete_cohort_cb ERROR: {e}\")\n",
        "                return f\"❌ Error deleting cohort: {e}\"\n",
        "\n",
        "        # --- REWIRED: each button updates ALL FOUR panes ---\n",
        "        refresh_stats_btn.click(\n",
        "            _refresh_stats,\n",
        "            inputs=[session_state],\n",
        "            outputs=[admin_stats_md, admin_users_md, admin_cohorts_md, admin_audit_md],\n",
        "        )\n",
        "\n",
        "        refresh_users_btn.click(\n",
        "            _refresh_users,\n",
        "            inputs=[session_state],\n",
        "            outputs=[admin_stats_md, admin_users_md, admin_cohorts_md, admin_audit_md],\n",
        "        )\n",
        "\n",
        "        # Cohorts button: two handlers (panes + dropdown)\n",
        "        refresh_cohorts_btn.click(\n",
        "            _refresh_cohorts_admin_md,\n",
        "            inputs=[session_state],\n",
        "            outputs=[admin_stats_md, admin_users_md, admin_cohorts_md, admin_audit_md],\n",
        "        )\n",
        "\n",
        "        refresh_cohorts_btn.click(\n",
        "            _refresh_cohorts_admin_dd,\n",
        "            inputs=[session_state],\n",
        "            outputs=[admin_delete_cohort_dropdown],\n",
        "        )\n",
        "\n",
        "        refresh_audit_btn.click(\n",
        "            _refresh_audit,\n",
        "            inputs=[session_state],\n",
        "            outputs=[admin_stats_md, admin_users_md, admin_cohorts_md, admin_audit_md],\n",
        "        )\n",
        "\n",
        "        admin_delete_btn.click(\n",
        "            _delete_cohort_cb,\n",
        "            inputs=[session_state, admin_delete_cohort_dropdown],\n",
        "            outputs=[admin_delete_status_md],\n",
        "        )\n",
        "\n",
        "\n",
        "        # --- Demo Setup (v16.1) ---\n",
        "        gr.Markdown(\"### Demo Setup (admin)\")\n",
        "        gr.Markdown(\"Upload a prompt list to preload curated 'demo prompts' for a cohort. These appear in the Ask tab as a dropdown when that cohort is selected.\")\n",
        "\n",
        "        with gr.Row():\n",
        "            demo_cohort_dropdown = gr.Dropdown(label=\"Cohort for Demo Prompts\", choices=[], value=None)\n",
        "            demo_refresh_cohorts_btn = gr.Button(\"Refresh Cohorts\")\n",
        "\n",
        "        with gr.Row():\n",
        "            demo_prompts_file = gr.File(\n",
        "                label=\"Upload Demo Prompts File (.txt, .csv, .json)\",\n",
        "                file_count=\"single\",\n",
        "                type=\"filepath\",\n",
        "            )\n",
        "            demo_replace_checkbox = gr.Checkbox(label=\"Replace existing demo prompts\", value=True)\n",
        "\n",
        "        with gr.Row():\n",
        "            demo_load_btn = gr.Button(\"Load Demo Prompts\", variant=\"primary\")\n",
        "            demo_view_btn = gr.Button(\"View Demo Prompts\")\n",
        "            demo_clear_btn = gr.Button(\"Clear Demo Prompts\")\n",
        "\n",
        "        demo_prompts_status = gr.Markdown(\"\")\n",
        "        demo_prompts_preview = gr.Markdown(\"\")\n",
        "\n",
        "        def _demo_refresh_cohorts_dd(session_user):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return gr.update(choices=[], value=None)\n",
        "            try:\n",
        "                rows = get_all_cohorts()\n",
        "                names = [r[0] for r in rows if r and r[0]]\n",
        "                return gr.update(choices=names, value=None)\n",
        "            except Exception as e:\n",
        "                trace_log(f\"ADMIN demo _demo_refresh_cohorts_dd ERROR: {e}\")\n",
        "                return gr.update(choices=[], value=None)\n",
        "\n",
        "        def _demo_load_prompts_cb(session_user, cohort_name: str, file_path: str, replace: bool):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return msg or \"❌ Admin privileges required.\", \"\"\n",
        "            c = (cohort_name or \"\").strip()\n",
        "            if not c:\n",
        "                return \"❌ Please select a cohort.\", \"\"\n",
        "            if not file_path:\n",
        "                return \"❌ Please upload a .txt/.csv/.json prompt file.\", \"\"\n",
        "            prompts = parse_demo_prompts_file(file_path)\n",
        "            n = upsert_demo_prompts_for_cohort(c, prompts, replace=bool(replace))\n",
        "            try:\n",
        "                log_audit(su.username, su.role, \"demo_prompts_load\", f\"cohort={c} count={n} replace={bool(replace)}\")\n",
        "            except Exception as e:\n",
        "                trace_log(f\"log_audit demo_prompts_load ERROR: {e}\")\n",
        "            preview = list_demo_prompts_for_cohort(c)\n",
        "            preview_md = \"\\n\".join([f\"- {p}\" for p in preview[:50]]) if preview else \"_No demo prompts found._\"\n",
        "            return f\"✅ Loaded {n} demo prompt(s) into cohort `{c}`.\", preview_md\n",
        "\n",
        "        def _demo_view_prompts_cb(session_user, cohort_name: str):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return msg or \"❌ Admin privileges required.\", \"\"\n",
        "            c = (cohort_name or \"\").strip()\n",
        "            if not c:\n",
        "                return \"❌ Please select a cohort.\", \"\"\n",
        "            preview = list_demo_prompts_for_cohort(c)\n",
        "            if not preview:\n",
        "                return f\"_No demo prompts found for `{c}`._\", \"\"\n",
        "            md = \"\\n\".join([f\"- {p}\" for p in preview[:200]])\n",
        "            return f\"**Demo prompts for `{c}` ({len(preview)}):**\", md\n",
        "\n",
        "        def _demo_clear_prompts_cb(session_user, cohort_name: str):\n",
        "            su, msg = _ensure_admin(session_user)\n",
        "            if not su:\n",
        "                return msg or \"❌ Admin privileges required.\", \"\"\n",
        "            c = (cohort_name or \"\").strip()\n",
        "            if not c:\n",
        "                return \"❌ Please select a cohort.\", \"\"\n",
        "            clear_demo_prompts_for_cohort(c)\n",
        "            try:\n",
        "                log_audit(su.username, su.role, \"demo_prompts_clear\", f\"cohort={c}\")\n",
        "            except Exception as e:\n",
        "                trace_log(f\"log_audit demo_prompts_clear ERROR: {e}\")\n",
        "            return f\"✅ Cleared demo prompts for `{c}`.\", \"\"\n",
        "\n",
        "        demo_refresh_cohorts_btn.click(\n",
        "            _demo_refresh_cohorts_dd,\n",
        "            inputs=[session_state],\n",
        "            outputs=[demo_cohort_dropdown],\n",
        "        )\n",
        "\n",
        "        demo_load_btn.click(\n",
        "            _demo_load_prompts_cb,\n",
        "            inputs=[session_state, demo_cohort_dropdown, demo_prompts_file, demo_replace_checkbox],\n",
        "            outputs=[demo_prompts_status, demo_prompts_preview],\n",
        "        )\n",
        "\n",
        "        demo_view_btn.click(\n",
        "            _demo_view_prompts_cb,\n",
        "            inputs=[session_state, demo_cohort_dropdown],\n",
        "            outputs=[demo_prompts_status, demo_prompts_preview],\n",
        "        )\n",
        "\n",
        "        demo_clear_btn.click(\n",
        "            _demo_clear_prompts_cb,\n",
        "            inputs=[session_state, demo_cohort_dropdown],\n",
        "            outputs=[demo_prompts_status, demo_prompts_preview],\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"admin_stats_md\": admin_stats_md,\n",
        "            \"admin_users_md\": admin_users_md,\n",
        "            \"admin_cohorts_md\": admin_cohorts_md,\n",
        "            \"admin_audit_md\": admin_audit_md,\n",
        "            \"admin_delete_cohort_dropdown\": admin_delete_cohort_dropdown,\n",
        "            \"admin_delete_status_md\": admin_delete_status_md,\n",
        "        }\n",
        "\n",
        "    ACTION_CREATE = \"Create new cohort from files\"\n",
        "    ACTION_APPEND = \"Append files to existing cohort\"\n",
        "    ACTION_CLONE  = \"Clone an existing cohort\"\n",
        "\n",
        "    DEFAULT_ACTION = ACTION_CREATE\n",
        "\n",
        "\n",
        "\n",
        "    # -----------------------------\n",
        "    # Build Gradio Interface\n",
        "    # -----------------------------\n",
        "    def build_interface():\n",
        "        with gr.Blocks(title=\"Phase1 RAG MVP v16_1\") as demo:\n",
        "            gr.Markdown(\"## Phase1 RAG MVP v16_1\")\n",
        "\n",
        "            # Global session state\n",
        "            session_state = gr.State(value=None)       # {\"username\": ..., \"role\": ...} or None\n",
        "            role_state = gr.State(value=\"anonymous\")   # Optional, not heavily used yet\n",
        "            api_key_state = gr.State(value=\"\")         # Hidden backing store for API key\n",
        "\n",
        "            # ---- Login / Logout row ----\n",
        "            with gr.Row():\n",
        "                username_tb = gr.Textbox(label=\"Username\", scale=1)\n",
        "                password_tb = gr.Textbox(label=\"Password\", type=\"password\", scale=1)\n",
        "                api_key_tb = gr.Textbox(\n",
        "                    label=\"OpenAI API Key\",\n",
        "                    type=\"password\",\n",
        "                    placeholder=\"sk-...\",\n",
        "                    scale=2,\n",
        "                )\n",
        "\n",
        "            with gr.Row():\n",
        "                login_btn = gr.Button(\"Login\")\n",
        "                logout_btn = gr.Button(\"Logout\")\n",
        "\n",
        "            login_status = gr.Markdown(\"Not logged in.\")\n",
        "            current_user_label = gr.Markdown(\"**Current user:** (none)\")\n",
        "\n",
        "            # ---- Tabs ----\n",
        "            with gr.Tabs():\n",
        "                with gr.Tab(\"Setup & Cohorts\"):\n",
        "                    setup_handles = build_setup_tab(session_state, api_key_state)\n",
        "                with gr.Tab(\"Ask\"):\n",
        "                    ask_handles = build_ask_tab(session_state, api_key_state)\n",
        "                with gr.Tab(\"History\"):\n",
        "                    history_handles = build_history_tab(session_state)\n",
        "                # Admin tab: hidden by default\n",
        "                admin_tab = gr.Tab(\"Admin\", visible=False)\n",
        "                with admin_tab:\n",
        "                    admin_handles = build_admin_tab(session_state)\n",
        "            # ---- Ask tab enable / disable JS (Fix Set 1) ----\n",
        "            ASK_DISABLE_JS = \"\"\"\n",
        "            (session_state, role_state, api_key_state) => {\n",
        "              const setDisabled = (containerId, disabled) => {\n",
        "                const container = document.getElementById(containerId);\n",
        "                if (!container) return;\n",
        "                const el = container.querySelector(\"textarea, input, button, select\");\n",
        "                if (!el) return;\n",
        "                el.disabled = disabled;\n",
        "              };\n",
        "\n",
        "              setDisabled(\"ask_cohort_dropdown\", true);\n",
        "              setDisabled(\"ask_model_dropdown\", true);\n",
        "              setDisabled(\"ask_question_box\", true);\n",
        "              setDisabled(\"ask_improved_box\", true);\n",
        "              setDisabled(\"ask_improve_btn\", true);\n",
        "              setDisabled(\"ask_ask_btn\", true);\n",
        "              setDisabled(\"ask_refresh_btn\", true);\n",
        "\n",
        "              // CRITICAL: return inputs unchanged\n",
        "              return [session_state, role_state, api_key_state];\n",
        "            }\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "            ASK_ENABLE_JS = \"\"\"\n",
        "            (username, password, api_key, session_state, role_state, api_key_state) => {\n",
        "              const setDisabled = (containerId, disabled) => {\n",
        "                const container = document.getElementById(containerId);\n",
        "                if (!container) return;\n",
        "                const el = container.querySelector(\"textarea, input, button, select\");\n",
        "                if (!el) return;\n",
        "                el.disabled = disabled;\n",
        "              };\n",
        "\n",
        "              setDisabled(\"ask_cohort_dropdown\", false);\n",
        "              setDisabled(\"ask_model_dropdown\", false);\n",
        "              setDisabled(\"ask_question_box\", false);\n",
        "              setDisabled(\"ask_improved_box\", false);\n",
        "              setDisabled(\"ask_improve_btn\", false);\n",
        "              setDisabled(\"ask_ask_btn\", false);\n",
        "              setDisabled(\"ask_refresh_btn\", false);\n",
        "\n",
        "              // CRITICAL: return inputs unchanged so Python receives them\n",
        "              return [username, password, api_key, session_state, role_state, api_key_state];\n",
        "            }\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # ---- Login / Logout Callbacks ----\n",
        "            # ---- Login / Logout Callbacks ----\n",
        "\n",
        "            def _login_cb(username, password, api_key, current_session, current_role, current_api_key):\n",
        "                \"\"\"\n",
        "                Authenticate user and store session + API key in state.\n",
        "                Also auto-populates cohort dropdowns for this user.\n",
        "\n",
        "                POLICY:\n",
        "                  - API key is stored only in api_key_state (memory), never left in a textbox.\n",
        "                  - On ANY login attempt (success or failure), clear:\n",
        "                      Username, Password, API Key textbox, Question, Improved Prompt\n",
        "                \"\"\"\n",
        "                # print(\"LOGIN RAW:\", repr(username), repr(password), repr(api_key))\n",
        "\n",
        "                #print(\"DEBUG: login clicked\")\n",
        "\n",
        "                # Normalize inputs\n",
        "                username = (username or \"\").strip()\n",
        "                password = password or \"\"\n",
        "                api_key = (api_key or \"\").strip()\n",
        "\n",
        "                # Always-clear values for UI textboxes (return plain strings for reliability)\n",
        "                CLEAR = \"\"\n",
        "                clear_username = CLEAR\n",
        "                clear_password = CLEAR\n",
        "                clear_api_key_tb = CLEAR\n",
        "                clear_question = CLEAR\n",
        "                clear_improved = CLEAR\n",
        "\n",
        "                # Basic validation\n",
        "                if not username or not password:\n",
        "                    return (\n",
        "                        \"❌ Username and password are required.\",  # login_status\n",
        "                        None,                                     # session_state\n",
        "                        \"anonymous\",                               # role_state\n",
        "                        \"\",                                       # api_key_state\n",
        "                        clear_username,                            # username_tb\n",
        "                        clear_password,                            # password_tb\n",
        "                        clear_api_key_tb,                          # api_key_tb\n",
        "                        \"**Current user:** (none)\",                # current_user_label\n",
        "                        gr.update(choices=[], value=None),         # setup existing cohort dropdown\n",
        "                        gr.update(choices=[], value=None),         # ask cohort dropdown\n",
        "                        clear_question,                            # ask question_box\n",
        "                        clear_improved,                            # ask improved_box\n",
        "                    )\n",
        "\n",
        "                user_dict = authenticate_credentials(username, password)\n",
        "                if not user_dict:\n",
        "                    return (\n",
        "                        \"❌ Invalid username or password.\",         # login_status\n",
        "                        None,                                     # session_state\n",
        "                        \"anonymous\",                               # role_state\n",
        "                        \"\",                                       # api_key_state\n",
        "                        clear_username,                            # username_tb\n",
        "                        clear_password,                            # password_tb\n",
        "                        clear_api_key_tb,                          # api_key_tb\n",
        "                        \"**Current user:** (none)\",                # current_user_label\n",
        "                        gr.update(choices=[], value=None),         # setup existing cohort dropdown\n",
        "                        gr.update(choices=[], value=None),         # ask cohort dropdown\n",
        "                        clear_question,                            # ask question_box\n",
        "                        clear_improved,                            # ask improved_box\n",
        "                        gr.update(visible=False)   # admin_tab\n",
        "\n",
        "                    )\n",
        "\n",
        "                role = user_dict.get(\"role\", \"user\")\n",
        "                status = f\"✅ Logged in as `{username}` (role: `{role}`)\"\n",
        "                label = f\"**Current user:** `{username}` (role: `{role}`)\"\n",
        "\n",
        "                # Store API key ONLY in state (memory); do not leave it in textbox\n",
        "                new_api_key_state = api_key\n",
        "\n",
        "                # Populate cohorts for this user (respects sharing rules)\n",
        "                try:\n",
        "                    cohort_names = get_cohorts_for_user(username)\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"LOGIN get_cohorts_for_user ERROR: {e}\")\n",
        "                    try:\n",
        "                        cohort_names = list_cohorts()\n",
        "                    except Exception:\n",
        "                        cohort_names = []\n",
        "\n",
        "                # Build \"name/owner\" labels for the Setup tab dropdown\n",
        "                try:\n",
        "                    rows = get_all_cohorts()  # (cohort_name, owner_user_id, ...)\n",
        "                    owner_by_name = {row[0]: (row[1] if len(row) > 1 else None) for row in rows}\n",
        "                    setup_labels = []\n",
        "                    for name in cohort_names:\n",
        "                        owner = owner_by_name.get(name)\n",
        "                        setup_labels.append(f\"{name}/{owner}\" if owner else name)\n",
        "                except Exception as e:\n",
        "                    trace_log(f\"LOGIN building setup_labels ERROR: {e}\")\n",
        "                    setup_labels = cohort_names\n",
        "\n",
        "                setup_existing_dd = gr.update(choices=setup_labels, value=None)\n",
        "                ask_cohort_dd = gr.update(choices=cohort_names, value=None)\n",
        "\n",
        "                return (\n",
        "                    status,                 # login_status\n",
        "                    user_dict,              # session_state\n",
        "                    role,                   # role_state\n",
        "                    new_api_key_state,      # api_key_state\n",
        "                    clear_username,         # username_tb (cleared after login)\n",
        "                    clear_password,         # password_tb (cleared after login)\n",
        "                    clear_api_key_tb,       # api_key_tb (cleared after login)\n",
        "                    label,                  # current_user_label\n",
        "                    setup_existing_dd,      # setup existing cohort dropdown\n",
        "                    ask_cohort_dd,          # ask cohort dropdown\n",
        "                    clear_question,         # ask question_box (cleared after login)\n",
        "                    clear_improved,# ask improved_box (cleared after login)\n",
        "                    gr.update(visible=(role == \"admin\")),  # NEW admin_tab visibility\n",
        "                )\n",
        "\n",
        "\n",
        "            login_btn.click(\n",
        "                _login_cb,\n",
        "                inputs=[\n",
        "                    username_tb,\n",
        "                    password_tb,\n",
        "                    api_key_tb,\n",
        "                    session_state,\n",
        "                    role_state,\n",
        "                    api_key_state,\n",
        "                ],\n",
        "                queue=False,\n",
        "                js=ASK_ENABLE_JS,\n",
        "\n",
        "                outputs=[\n",
        "                    login_status,\n",
        "                    session_state,\n",
        "                    role_state,\n",
        "                    api_key_state,\n",
        "                    username_tb,\n",
        "                    password_tb,\n",
        "                    api_key_tb,\n",
        "                    current_user_label,\n",
        "                    setup_handles[\"existing_cohort_dropdown\"],\n",
        "                    ask_handles[\"cohort_dropdown\"],\n",
        "                    ask_handles[\"question_box\"],\n",
        "                    ask_handles[\"improved_box\"],\n",
        "                    admin_tab,   # NEW\n",
        "                ],\n",
        "\n",
        "            )\n",
        "\n",
        "            def _logout_cb(_session, _role, _api_key):\n",
        "                # Reset in-memory state\n",
        "                new_session = SessionUser(username=None, role=\"guest\")\n",
        "                new_role = \"guest\"\n",
        "                new_api_key = \"\"\n",
        "\n",
        "                # Use plain strings for Textbox clearing (more reliable than gr.update for Textbox values)\n",
        "                CLEAR = \"\"\n",
        "\n",
        "                reset_files = gr.update(value=None)\n",
        "                reset_radio = gr.update(value=None)\n",
        "                reset_dd_empty = gr.update(value=None, choices=[])\n",
        "\n",
        "                # IMPORTANT: model dropdown must keep valid choices\n",
        "                reset_model_dd = gr.update(choices=list_chat_models(), value=None)\n",
        "\n",
        "                # History filters (keep simple defaults; prevents stale selections)\n",
        "                reset_history_user = gr.update(value=\"\")\n",
        "                reset_history_cohort = gr.update(value=\"\")\n",
        "\n",
        "\n",
        "                return (\n",
        "                    \"🔒 Logged out.\",           # login_status\n",
        "                    new_session,               # session_state\n",
        "                    new_role,                  # role_state\n",
        "                    new_api_key,               # api_key_state\n",
        "\n",
        "                    CLEAR,                     # username_tb\n",
        "                    CLEAR,                     # password_tb\n",
        "                    CLEAR,                     # api_key_tb\n",
        "                    \"Not logged in\",           # current_user_label\n",
        "\n",
        "                    reset_radio,               # setup action_radio\n",
        "                    CLEAR,                     # setup new_cohort_name\n",
        "                    gr.update(value=False),    # setup share_checkbox\n",
        "                    reset_dd_empty,            # setup existing_cohort_dropdown\n",
        "                    reset_files,               # setup file_uploader\n",
        "                    CLEAR,                     # setup build_status (markdown/text is fine as \"\")\n",
        "\n",
        "                    reset_dd_empty,            # ask cohort_dropdown\n",
        "                    reset_model_dd,            # ask model_dropdown  (DO NOT empty choices)\n",
        "                    CLEAR,                     # ask question_box\n",
        "                    CLEAR,                     # ask improved_box\n",
        "                    CLEAR,                     # ask answer_markdown\n",
        "                    CLEAR,                     # ask docs_markdown\n",
        "\n",
        "                    reset_history_user,        # history_user_filter\n",
        "                    reset_history_cohort,      # history_cohort_filter\n",
        "                    CLEAR,                     # history_markdown\n",
        "\n",
        "                    CLEAR,                     # admin_stats_md\n",
        "                    CLEAR,                     # admin_users_md\n",
        "                    CLEAR,                     # admin_cohorts_md\n",
        "                    CLEAR,                     # admin_audit_md\n",
        "                    reset_dd_empty,            # admin_delete_cohort_dropdown\n",
        "                    CLEAR,                      # admin_delete_status_md\n",
        "                    gr.update(visible=False)   # admin_tab hidden after logout\n",
        "\n",
        "                )\n",
        "\n",
        "\n",
        "\n",
        "            logout_btn.click(\n",
        "                _logout_cb,\n",
        "                inputs=[session_state, role_state, api_key_state],\n",
        "                outputs=[\n",
        "                    login_status,\n",
        "                    session_state,\n",
        "                    role_state,\n",
        "                    api_key_state,\n",
        "                    username_tb,\n",
        "                    password_tb,\n",
        "                    api_key_tb,\n",
        "                    current_user_label,\n",
        "\n",
        "                    setup_handles[\"action_radio\"],\n",
        "                    setup_handles[\"new_cohort_name\"],\n",
        "                    setup_handles[\"share_checkbox\"],\n",
        "                    setup_handles[\"existing_cohort_dropdown\"],\n",
        "                    setup_handles[\"file_uploader\"],\n",
        "                    setup_handles[\"build_status\"],\n",
        "\n",
        "                    ask_handles[\"cohort_dropdown\"],\n",
        "                    ask_handles[\"model_dropdown\"],\n",
        "                    ask_handles[\"question_box\"],\n",
        "                    ask_handles[\"improved_box\"],\n",
        "                    ask_handles[\"answer_markdown\"],\n",
        "                    ask_handles[\"docs_markdown\"],\n",
        "\n",
        "                    history_handles[\"history_user_filter\"],\n",
        "                    history_handles[\"history_cohort_filter\"],\n",
        "                    history_handles[\"history_markdown\"],\n",
        "\n",
        "                    admin_handles[\"admin_stats_md\"],\n",
        "                    admin_handles[\"admin_users_md\"],\n",
        "                    admin_handles[\"admin_cohorts_md\"],\n",
        "                    admin_handles[\"admin_audit_md\"],\n",
        "                    admin_handles[\"admin_delete_cohort_dropdown\"],\n",
        "                    admin_handles[\"admin_delete_status_md\"],\n",
        "                    admin_tab,   # NEW\n",
        "                ],\n",
        "                queue=False,\n",
        "                js=ASK_DISABLE_JS,\n",
        "\n",
        "            )\n",
        "\n",
        "        return demo\n",
        "\n",
        "    # ---- Create & Launch the App ----\n",
        "    if __name__ == \"__main__\":\n",
        "        demo = build_interface()\n",
        "        # In Colab: share=False is usually fine; set to True if you want a public link.\n",
        "        demo.launch(share=False, debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}